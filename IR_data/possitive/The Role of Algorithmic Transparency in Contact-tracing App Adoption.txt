See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/354780889

The Role of Algorithmic Transparency in Contact-tracing App Adoption
Conference Paper · December 2021

CITATIONS

READS

0

273

3 authors:
Tobias Bitzer

Martin Wiener

Technische Universität Dresden

Technische Universität Dresden

3 PUBLICATIONS 2 CITATIONS

126 PUBLICATIONS 1,282 CITATIONS

SEE PROFILE

Stefan Morana
Universität des Saarlandes
88 PUBLICATIONS 1,666 CITATIONS
SEE PROFILE

Some of the authors of this publication are also working on these related projects:

Data-driven business models View project

IS project control View project

All content following this page was uploaded by Martin Wiener on 23 September 2021.
The user has requested enhancement of the downloaded file.

SEE PROFILE

Algorithmic Transparency and Contact-tracing App Adoption

The Role of Algorithmic Transparency in
Contact-tracing App Adoption
Completed Research Paper

Tobias Bitzer
TU Dresden
Dresden, Germany
tobias.bitzer@mailbox.tu-dresden.de

Martin Wiener
TU Dresden
Dresden, Germany
martin.wiener@tu-dresden.de

Stefan Morana
Saarland University
Saarbrücken, Germany
stefan.morana@uni-saarland.de
Abstract
Contact-tracing apps represent an algorithm-based technology with significant potential
to help address the COVID-19 pandemic by facilitating swift case isolation. However, low
adoption rates have prevented these apps from tapping their full potential. A key barrier
to adoption has been citizens’ uncertainty surrounding contact-tracing apps. In this
regard, algorithmic transparency may be a critical factor in fostering app adoption. In
this study, we focus on one central aspect of algorithmic transparency — namely,
transformation algorithmic transparency in terms of information disclosure on the app’s
inner workings (TAT disclosure). Using an online experiment with 206 participants, we
find no significant direct relationship between TAT disclosure and individuals’
installation decision; still, we do find a significant indirect relationship, mediated by
actual comprehension of the app’s inner workings and trust into the app. Two
moderating factors (benefit appeal and Coronavirus anxiety) did not show any
significant effects. Theoretical and practical implications are discussed.
Keywords: COVID-19, contact-tracing apps, algorithmic transparency, mobile app
adoption, context factors, online experiment

Introduction
Over one year after its outbreak, the COVID-19 pandemic continues to bring major disruptions to the lives
and livelihoods of billions of people. Globally, as of April 2021, over 131 million have been infected and 2.9
million died (ECDC 2021), while millions more are being hospitalized or suffer from long term health
consequences. Beyond the health impact, the economic and societal effects of the pandemic are material,
as governments worldwide try to curb the spread of the virus through strict lockdown measures. For 2020,
the World Bank estimates an economic loss of 4.3% in the global Gross Domestic Product (GDP); for 2021,
additional losses can be expected (The World Bank 2021). In addition, severe repercussions are
documented on socio-economic areas as diverse as food safety, education, and family dynamics (Nicola et
al. 2020). Despite the latest progress of vaccination campaigns, the financial and organizational challenges
accompanying them and the potential risk of mutants making vaccinations (partially) ineffective underline
the need for complimentary solutions (Gozzi et al. 2021). Even more, COVID-19 demonstrated humanity’s
general vulnerability to pandemics and underscored the importance of being prepared for new plagues.

Forty-Second International Conference on Information Systems, Austin 2021
1

Algorithmic Transparency and Contact-tracing App Adoption

Contact-tracing apps were suggested early by researchers as a technology for addressing the pandemic
(Ferretti et al. 2020). These smartphone-based tools use algorithms to calculate individuals’ infection risk
based on past encounters and prompt users to self-isolate quickly if they have a high risk. Thereby, the apps
help reduce infectious contacts, which is arguably most effective against the virus. Meanwhile, as contacts
are reduced in a smart, targeted way, ‘traditional’ lockdowns and their negative side-effects can be avoided.
Based on this promise, many countries rolled out such apps on a voluntary basis in 2020. However, contacttracing apps have so far fallen short of expectations: Despite the apps’ apparent advantages, many health
authorities still depend on traditional, manual contact-tracing (Braithwaite et al. 2020), mainly due to low
adoption rates well below the postulated threshold of 60% of a country’s population (Fraser 2020). As such,
it becomes important to understand the factors that influence citizens’ decision to use contact-tracing apps.
In this regard, extant technology adoption literature only provides partial guidance: Theories, such as the
Technology Acceptance Model (TAM) (Davis et al. 1989) or the Unified Theory of Technology Acceptance
(UTAUT) (Venkatesh et al. 2003), implicitly foreground individual benefits (e.g., performance expectancy).
Contact-tracing apps, however, provide self-benefits (i.e., protecting oneself) and societal benefits (i.e.,
protecting others) that appeal to users to differing extents (Trang et al. 2020). Accordingly, initial studies
on contact-tracing apps find a broader range of adoption factors, including user benefits, privacy design,
convenience design, perceived barriers, cues to action, and self-efficacy (Trang et al. 2020; Walrave et al.
2020). Several of these factors can be directly or indirectly influenced by algorithmic transparency (AT),
which is the focus of our study: In particular, AT facilitates learning, builds trust, and reduces uncertainty
(Bernstein 2017) and can thus reveal benefits of and reduce fears about the app. This is of special relevance
in the electronic health context, which is characterized by the processing of sensitive data (e.g., in terms of
privacy and security) and may thus be disproportionally affected by user uncertainty.
AT can be defined as “the disclosure of information about algorithms to enable monitoring, checking,
criticism, or intervention by interested parties” (Diakopoulos and Koliska 2017, p. 811). While AT generally
considers the entire process of input to, transformation by, and output of an algorithm, transformation
algorithmic transparency (TAT) is arguably the most relevant aspect in the present context: Through TAT,
information on the inner workings of an algorithm-enabled technology are disclosed to potential users
(hereafter referred to as “TAT disclosure”), which allows users to open the “black box” (Castelvecchi 2016)
that often surrounds algorithm-based technology, such as contact-tracing apps, and increases users’
willingness to adopt new technology (Cramer et al. 2008; Kizilcec 2016). In addition, extant technology
adoption research has found context factors, such as voluntary vs. mandatory use, to be of high importance
as they may moderate the direct relationships of technology adoption and its antecedents (Venkatesh et al.
2003). This may be particularly true for the relatively unique contact-tracing technology, where moderating
factors such as self- vs. societal benefit appeal and Coronavirus anxiety have been found to play a relevant
role (Trang et al. 2020). Building on these findings, our study addresses the following research questions:
RQ1:

How does TAT disclosure influence contact-tracing app adoption?

RQ2:

How do context factors moderate the relationship between TAT disclosure and app adoption?

The answers to these questions have multiple implications for theory and practice: First, they imply that
extant technology adoption theory only partially applies to the specific context of contact-tracing apps, as
users may install the app due to a duality of personal and societal benefits (Trang et al. 2020; Walrave et
al. 2020). Second, they imply that TAT disclosure is of particular relevance, as it can help address user
uncertainty, a factor of disproportionate importance in the sensitive personal health context. Finally, they
have concrete practical suggestions on how to promote installation decisions by means of TAT disclosure.
In the remainder of this paper, we first review the research background and conceptual foundations. Next,
we develop our research model and hypotheses and describe our research design. We then report our
results, followed by a discussion of their theoretical and practical implications, as well as their limitations.

Research Background and Conceptual Foundations
Contact-tracing Apps
In simple technical terms, contact-tracing apps are mobile phone-based logs of close encounters combined
with a database of infected cases. Their functionality is based on algorithms that determine app users’ risk

Forty-Second International Conference on Information Systems, Austin 2021
2

Algorithmic Transparency and Contact-tracing App Adoption

of being infected based on the history of their encounters. On this basis, the app informs individual users
regularly about their risk status. When a user is determined to have a high risk of being infected, the app
prompts her or him to take further action (e.g., to quarantine). As such, contact-tracing apps support two
of the most effective mechanisms for controlling pandemics: case isolation and quarantining. Individuals
who are (suspected to be) infected with the virus are isolated to avoid that they further spread the infection.
In the case of COVID-19, the success of this approach is, however, severely impaired by the fact that an
estimated 46% of infections are caused by pre-symptomatic transmissions, i.e., by individuals who have not
yet noticed their infection (Ferretti et al. 2020). Consequently, individuals have to preventively self-isolate
as soon as they have been in contact with a confirmed or suspected case, even before they show symptoms
themselves. Accordingly, fast and reliable contact-tracing is required to inform individuals as soon as
possible when they are at risk of being infected and should quarantine. Traditional manual contact-tracing
has been found to be too slow to allow an effective control of the virus and hence epidemiologists advocated
for a technical solution using contact-tracing apps. Through (nearly) real-time notification such apps were
considered an effective tool to help stop the pandemic, provided that a sufficiently large share of the
population were to use them (Ferretti et al. 2020).
Following scientific advice, numerous governments worldwide rolled out contact-tracing apps. While some
of these apps (e.g., the one in Germany) reached adoption rates of over 30% (RKI 2021), they have not (yet)
met the initially high expectations. The reasons are manifold, ranging from excessive expectations to design
errors (Rowe et al. 2020). Still, one of the key problems continues to be insufficient adoption rates; that is,
the app is not downloaded by enough people, or it is not used to its full extent by those who did download
it. For example, in Germany, which has one of the highest adoption rates in Europe, almost 40% of the
theoretically shareable infections are not reported in the country’s official COVID-19 app (RKI 2021),
rendering the app partially ineffective. Thus, the question of how to motivate the adoption of contact-tracing
apps and their sustained correct use is of continued high relevance, as the app’s positive network effects can
only be captured through widespread use (Blasimme and Vayena 2020; Farronato et al. 2020).

App Adoption Factors
As indicated above, recent developments further underscore the importance of promoting the adoption of
contact-tracing apps. Although extant research provides deviating views on target adoption rates, 60% of a
country’s population has become a widely accepted threshold for app effectiveness (Fraser 2020). Reaching
such a high adoption rate constitutes a major challenge, which is only met by a few popular social media
apps (e.g., YouTube). Consequently, it is of high importance to understand the factors that influence app
adoption in the specific case of contact-tracing apps. Generally, corresponding factors can be grouped into
two broad categories, namely: direct determinants of adoption, including access, ability, and willingness
(Blom et al. 2021), as well as moderating (context) factors, such as benefit appeal and Coronavirus anxiety
(Trang et al. 2020; Venkatesh et al. 2003).
Direct determinants of adoption
On the direct side, access and ability refer to structural and knowledge factors, such as smartphone use,
compatibility of the smartphone operating system, and the ability to install apps and activate Bluetooth
(Blom et al. 2021). Even in developed countries such as Germany, these factors alone limit the share of the
population that can adopt a contact-tracing app to about 70% to 80%. As well, they are largely beyond the
control of the app developers/publishers and thus constitute substantial barriers as material investments
into new smartphones or upskilling are required. Consequently, the willingness factors that hold back those
citizens who do have the necessary access and abilities are arguably of even higher importance. This position
is reiterated by initial estimates that only 35% of the total population, i.e., less than half of the above
mentioned 70 to 80%, are also willing to install and use the app (Blom et al. 2021), which creates a large
untapped potential. Here, one can argue that relevant willingness factors are only partially covered by
prominent technology adoption frameworks, such as TAM (Davis et al. 1989) and UTAUT (Venkatesh et al.
2003). While these models may offer some initial guidance, they implicitly foreground individual user
benefits (e.g., effort expectancy and performance expectancy). However, such individual user benefits seem
to cover only one ‘dimension’ of contact-tracing apps. In this regard, initial research indicates that of equal,
if not greater importance, are the app’s societal benefits; i.e., informing others of their risk of being infected

Forty-Second International Conference on Information Systems, Austin 2021
3

Algorithmic Transparency and Contact-tracing App Adoption

(Trang et al. 2020; Walrave et al. 2020). Given this duality of benefit appeals, we expect that existing
adoption frameworks do not easily translate to the specific context of contact-tracing apps.
Existing studies on contact-tracing app adoption find user benefits, privacy design, convenience design,
perceived barriers, cues to action, and self-efficacy to be significant willingness factors (Trang et al. 2020;
Walrave et al. 2020). These findings fit into the broader context of technology adoption research, which
finds (adoption) decisions to be driven by users’ perceptions (e.g., if there is a high or low privacy risk) and
underlying attitudes (e.g., importance of privacy). Several of these factors can be directly or indirectly
influenced by transparency. Most notably, transparency has been described as a facilitator for learning,
building trust, and reducing uncertainty (Bernstein 2017), and can thus reveal benefits of and reduce fears
about the app. This is of particular relevance for contact-tracing apps, for three reasons: First, being
deployed in the e-health context, corresponding apps are characterized by the processing of sensitive data
(e.g., in terms of privacy and security) and may therefore be disproportionally affected by user uncertainty.
Second, the underlying technology (e.g., proximity-based tracking) is complex and ensuring privacy with
this technology is an issue requiring profound technical expertise. Third, contact-tracing apps are a new
phenomenon and have been introduced in a very short timeframe; as such, they are new to most users and
their effectiveness has still to be proven in practice, contributing to additional uncertainty.
Moderating factors
Most information technologies, including contact-tracing apps, provide benefits for the respective users
themselves. Some technologies, however, provide benefits also, or primarily, for others than the respective
user. Prior research points to the concepts of self-benefit versus societal benefit appeal to distinguish these
two cases. This distinction is of high relevance for contact-tracing apps, where users may perceive the
technology to either benefit themselves by protecting them from an infection (i.e., self-benefit appeal) or to
benefit others by promoting (self-)isolation and thus reducing the infection risk for society as a whole (i.e.,
societal benefit appeal) (Trang et al. 2020). As such, benefit appeal is a central moderating factor that may
shape citizens’ decision to install a contact-tracing app, as well as their individual transparency demands.
In particular, while adoption decisions motivated by self-benefit appeal may be explained with concepts
from TAM and UTAUT (e.g., performance expectancy and effort expectancy) (Davis et al. 1989; Venkatesh
et al. 2003), adoption decisions motivated by societal benefit appeal appear to prevail for contact-tracing
apps (Trang et al. 2020). Given their primarily altruistic purpose, contact-tracing apps are a somewhat
unique technology, which implies that further analysis of the role of different benefit appeals in moderating
the adoption of contact-tracing apps is needed.
In extant research, emotional affects like anxiety play a key role as heuristics in dual models of human
decision making that consider both rational and emotional factors. Affects are often the first reaction to
external stimuli, prior to any cognitive information processing (Zajonc 1980). Consequently, there are
varied interplays between affects and other predictors of behavior where in a given situation affects may
alter individuals’ perceptions of risks and benefits and cause a decision change, even without rational cause
(Finucane et al. 2000). Anxiety and fear have been found to be particularly powerful under conditions
where users lack prior knowledge, often prompting counterintuitive and counterproductive reactions
(Averbeck et al. 2011). Initial studies have also found this to be the case for the COVID-19 pandemic:
Researchers investigating the impact of individuals’ fear of COVID-19 (“Coronavirus anxiety”) have found
Coronavirus anxiety to be linked to depression, general anxiety, and even fear of death (Lee et al. 2020).
Accordingly, initial research by Trang et al. (2020) also finds Coronavirus anxiety to play an important role
in contact-tracing app adoption. Based on these findings, Coronavirus anxiety may be another important
moderating factor in adoption decisions. Yet, its interplay with other adoption factors, and especially with
cognitive information processing tasks, such as the assessment of TAT disclosure, remains understudied.

Algorithmic Transparency
Given the critical role of algorithms in contact-tracing apps and the importance of transparency as an
adoption factor, the concept of AT is well-suited to advance our understanding of the factors that influence
individuals’ willingness to install contact-tracing apps. Coined in the context of internet journalism, AT is
defined as “disclosure of information about algorithms to enable monitoring, checking, criticism, or
intervention by interested parties” (Diakopoulos and Koliska 2017, p. 811). Despite a recent uptick of
research using the concept of AT in areas such as hiring (Datta et al. 2016), criminal intelligence (Zouave
Forty-Second International Conference on Information Systems, Austin 2021
4

Algorithmic Transparency and Contact-tracing App Adoption

and Marquenie 2017), and forecasting (Lehmann et al. 2020), most studies to date remain focused on online
journalism and related areas, such as online advertising (Eslami et al. 2018). Also, the vast majority of these
studies deploy AT in an empirical setting while theoretical accounts are scarce (Watson and Nations 2019).
To extend our conceptual understanding of AT, we draw on prior literature to present a more nuanced
conceptualization of this construct, thereby also facilitating application in new contexts (including the
context of contact-tracing apps). In particular, earlier studies point to different meanings of the term
transparency in general and distinguish among three distinct process steps relevant to the notion of AT.
First, the term transparency itself is a relatively recent addition to the management vocabulary, whose
frequent usage only dates back about 30 years. Over this relatively short time period, however, the concept
has gained increasingly in popularity and is now among the most used terms in academia and business alike
(Bernstein 2017, pp. 239-242). More specifically, transparency has come to be considered a key ‘ingredient’
to modern management and politics, and its importance has been further amplified by the emergence of
new technologies such as social networks, big data, and artificial intelligence, which are profoundly altering
the way information is collected, analyzed, and used (Gierlich-Joas et al. 2020). Due to the multi-faceted
nature of the term transparency, it seems less surprising that researchers attach different meanings to this
term. Here, at least four meanings of transparency can be differentiated: (1) monitoring, which influences
performance, knowledge sharing and learning; (2) process visibility, which shows a workflow or group of
activities; (3) surveillance, which represents (managerial) oversight over any action taken by the individual
(employee); and (4) disclosure, which is the provisioning of new or previously unknown information
(Bernstein 2017, p. 220). The latter understanding of the term transparency (i.e., in terms of disclosure) is
in line with the above-provided definition of AT and is considered to be generally desirable as it reduces
uncertainty and promotes favorable user reactions, understanding, and trust. In this regard, recent research
emphasizes the importance of “disclosure devices” (Hansen and Flyverbom 2015) as technological
mediators of transparency, thereby underscoring the particular relevance of this ‘type’ of transparency in
IS contexts. Accordingly, our research focuses on AT in terms of disclosure. Here, it should be added that,
besides disclosure, transparency in terms of comprehension plays a central role in the current discourse as
well, given that the “primary components of transparency are accessibility and comprehensibility of
information” (Mittelstadt et al. 2016, 6; emphasis in original). We therefore also consider this aspect of
citizens gaining a deeper understanding of technology (hereafter referred to as “TAT comprehension”).
Second, viewing AT through a process lens, earlier studies point to three process steps relevant to AT. More
specifically, algorithms can be described as “encoded procedures for transforming input data into a desired
output based on specified calculations” (Gillespie 2014, p. 167; emphasis added). Consequently, AT, too,
can refer to the input, transformation, and output of an algorithm. Consider the example of a contacttracing app, where input AT relates to information on what data are used and how they are collected and
retained (e.g., Bluetooth keys); transformation AT concerns information on the app’s inner workings, such
as the question of how the actual risk assessment is done (e.g., what distance and duration of an encounter
defines a ‘close contact’); and output AT pertains to information on potential consequences for app users
(e.g., a request for COVID-19 testing). Of these three steps, transformation concerns the app’s technical
core (i.e., the functioning of the underlying algorithms) and is thus of particular interest. For example, the
impact of insufficient access to information on the app’s transformational aspects can be particularly
problematic, as it will increase uncertainty by reinforcing citizens’ perceptions of a given contact-tracing
app as a “black box” (Castelvecchi 2016). Hence, in this study, we focus on TAT disclosure.

Hypothesis Development and Research Model
Influence of TAT Disclosure on Contact-tracing App Adoption
We operationalize app adoption in terms of individuals’ installation decision for a contact-tracing app,
which represents the dependent variable of our study (see Xu et al. 2016 for a similar approach). Below, we
follow a variance theory logic to develop our research model and accompanying hypotheses. Our model is
based on the notion that – in the specific context of (free) contact-tracing apps, where users’ main ‘cost’ is
the risk of losing privacy – other factors than those included in traditional adoption models play a key role
as well. For example, while our research model suggests that trust in the technology continues to be of
central importance, it also suggests that trust is directly and indirectly influenced by TAT disclosure.

Forty-Second International Conference on Information Systems, Austin 2021
5

Algorithmic Transparency and Contact-tracing App Adoption

Prior research (Bitzer et al. 2021; Cramer et al. 2008; Diakopoulos and Koliska 2017; Eslami et al. 2018)
and practical experiences suggest that TAT disclosure—i.e., the disclosure of information about the inner
workings of a given contact-tracing app—may be positively related to individuals’ installation decision. This
is because TAT disclosure fosters several willingness drivers, while reducing key adoption barriers. In
particular, TAT disclosure can reduce uncertainty about new, previously unknown technologies (Bernstein
2017), such as contact-tracing apps. As individuals learn about the (algorithm-based) inner workings of the
technology, their uncertainty is reduced, they are assured that the technology is working properly, and their
fears and negative perceptions may diminish. In addition, TAT disclosure indicates a general openness of
the technology provider and designer, which may contribute to a positive perception by potential future
users, even if the provided information does not increase understanding, as demonstrated by Lai and Tan
(2019) in their study on humans’ usage of AI predictions. This line of reasoning is also supported by the
experiences with the introduction of contact-tracing apps in different countries: Contact-tracing apps were
especially well-received in those countries that invested heavily into initial communications to acquaint
users with the technology (e.g., Germany). Relatedly, recent research provides initial evidence that AT can
promote the legitimacy of algorithmic decision making (Goad and Gal 2018). We thus hypothesize:
H 1:

TAT disclosure is positively related to individuals’ installation decision

Besides TAT disclosure, TAT comprehension—i.e., individuals’ actual understanding of the inner workings
of the technology—may play a key role in users’ adoption decision as a mediator of the positive relationship
between TAT disclosure and installation decision (see Mittelstadt et al. 2016 for a distinction of disclosure
and comprehension). While TAT disclosure can be directly influenced by the provider of the contact-tracing
app, TAT comprehension can be seen as a function of the information provided through TAT disclosure.
Accordingly, the mediating effect of TAT comprehension can be explained as follows: First, information is
provided (i.e., TAT disclosure); individuals then process the provided information cognitively and construct
their own mental model of the app’s functioning (i.e., TAT comprehension); once TAT comprehension,
including an understanding of the app’s benefits and privacy safeguards, has been reached, people’s
willingness to install the app can be expected to increase (see Cramer et al. 2008 for a related example in
the context of recommender systems).
Although some authors have cautioned that disclosure does not necessarily increase comprehension due to
peoples’ inability, or their unwillingness, to engage with the information disclosed (Burrell 2016), we expect
a positive relationship in the specific case of contact-tracing apps: As COVID-19 puts individuals’ personal
health at stake, we expect that people will place special emphasis on taking thorough decisions to best
protect their health. Hence, individuals will not only want to receive information about the relevant
technology and its inner workings (i.e., TAT disclosure) but also want to develop a solid understanding of
this technology (i.e., TAT comprehension). We therefore posit the following hypothesis:
H 2:

The relationship of TAT disclosure and installation decision is mediated by TAT comprehension,
i.e.: (a) TAT disclosure is positively related to TAT comprehension and (b) TAT comprehension
is positively related to individuals’ installation decision

Trust is another key factor in adoption decisions (Kramer 1999; Lee and See 2004). As such, we expect trust
to mediate the positive relationship between TAT disclosure and installation decision. Similar to TAT
comprehension (see above), the mediation follows a three-step process: with increasing levels of TAT
disclosure, trust increases, and in turn the likelihood of an installation decision increases, as well. The
positive relationship of TAT disclosure with trust is driven by people’s perception that the provider of the
algorithm-based technology has ‘nothing to hide’, follows good intentions, and invites individuals to apply
their own judgement and scrutiny to the algorithm. This line of reasoning finds some support in extant
research, yet, the observed relationships are rather complex: For professional settings, some studies even
find a negative effect of transparency (e.g., Lehmann et al. 2020 in the case of demand forecasting). For
non-professional settings, however, multiple studies find the expected positive effect of transparency on
trust; e.g., in the case of recommendation agents for music (Sinha and Swearingen 2002), art (Cramer et
al. 2008), and online shopping (Wang and Benbasat 2007). Different explanations have been offered for
this apparent contradiction, ranging from algorithm complexity (Lehmann et al. 2020) to confounding
effects of transparency on the user experience (Springer and Whittaker 2019). In the specific case of contacttracing apps, we expect that people are willing to engage with more complex explanations given the novelty
of the tool and the importance of the subject matter (i.e., personal health in a pandemic). Hence, we still
expect a positive relationship of TAT disclosure and trust. The positive effect of trust on technology adoption
Forty-Second International Conference on Information Systems, Austin 2021
6

Algorithmic Transparency and Contact-tracing App Adoption

has already been documented multiple times in extant research—see Lee and See (2004) for a
comprehensive discussion. It is driven by citizens becoming more comfortable with the technology in
question as they develop a sense of trust for the providers of the technology, as well as for the technology
itself. Trust thus works as a positive affect that, to some extent, becomes a social decision heuristic (Kramer
1999) in the decision for a technology. This effect is illustrated by numerous examples of recent technologies
and holds both for simple low-stake contexts, such as online recommendation agents (Wang and Benbasat
2007), and for complex high-stake contexts, such as autonomous driving (Choi and Ji 2015). We thus posit:
H 3:

The relationship of TAT disclosure and installation decision is mediated by trust, i.e.: (a) TAT
disclosure is positively related to trust and (b) trust is positively related to installation decision.

In line with our conceptual distinction between TAT disclosure and TAT comprehension and based on the
aforementioned finding in extant literature that transparency in general has a positive relationship with
trust, we also expect TAT comprehension to be positively related to trust. As individuals develop a more
thorough understanding of the technology (i.e., TAT comprehension), they can rely on their own judgement
how the technology works rather than on hearsay from third parties. A reiterating virtuous circle emerges
that furthers the initial trust that individuals have developed through TAT disclosure (Wang and Benbasat
2016). Past literature on trust supports the importance of TAT comprehension as it argues that the
formation of trust not only relies on an affective process, which can be influenced by TAT disclosure, but
also on analytical and analogical processes (i.e., assessing category memberships), which can only be
influenced by TAT comprehension (Lee and See 2004, p. 61). We therefore hypothesize:
H 4:

TAT comprehension is positively related to trust.

Moderating Influence of Context Factors on Contact-tracing App Adoption
Based on prior research and practical examples, we expect high self-benefit appeal to weaken the positive
relationship of TAT disclosure and installation decision. Contact-tracing apps constitute a special use case
that deviates from many previously studied scenarios as they mainly benefit others instead of the app users
themselves (i.e., societal benefit appeal). For this quite unique scenario, extant research (Trang et al. 2020)
and experiences from practice indicate a case distinction based on whom people consider to be the primary
beneficiary of the contact-tracing app: For people perceiving a low self-benefit appeal (i.e., for people
expecting the contact-tracing app to mainly benefit others), TAT disclosure will increase installation
decision as outlined above. However, for people perceiving a high self-benefit appeal, the impact of TAT
disclosure will be weakened; that is, for them, TAT disclosure can be expected to be less relevant, whereas
individual benefits of app adoption, such as effort expectancy and performance expectancy (Venkatesh et
al. 2003), are likely to increase in relative relevance.
Similar observations can be made, for example, for donations, where donors want to be confident that their
contribution helps others. For that, they ask for transparency on the use of funds, expect clear explanations
on how their donation creates impact, and search for cues (e.g., seals or audit reports). We thus hypothesize:
H 5:

Self-benefit appeal weakens the positive relationship of TAT disclosure and installation decision.

Finally, based on existing research on human behavior, we expect citizens’ Coronavirus anxiety to moderate
the effects of other adoption drivers by replacing rational with emotional decision criteria. In other words,
we expect Coronavirus anxiety to weaken the positive relationship of TAT disclosure and installation
decision. People with high Coronavirus anxiety will be less interested in TAT disclosure, as they will more
likely ignore this (rational) aspect of the contact-tracing app, and rather decide based on emotions.
Meanwhile, less anxious individuals will apply rational judgement and TAT disclosure can thus be expected
to have the above-hypothesized relationship with installation decision. This argument draws on extant
research, which demonstrates that anxiety and fear have a central influence on human decision-making and
let humans switch from rational, fact-based decision-making to emotional, feeling-based decision making.
As such, anxiety serves as an affect heuristic, short-cutting rational decision-making (Finucane et al. 2000).
Similar effects of fear appeal were observed, for example, when humans resorted to more simplistic
promises during dire situations and ignored the (underlying or even contradicting) logics behind these
promises. Further, the essentially same effects have been found for other health-related topics where people
lacked prior knowledge (Averbeck et al. 2011) and can also be seen for other aspects of the Coronavirus
pandemic, where individuals follow all types of promises for cures. Thus, we hypothesize:
Forty-Second International Conference on Information Systems, Austin 2021
7

Algorithmic Transparency and Contact-tracing App Adoption

H 6:

Coronavirus anxiety weakens the positive relationship of TAT disclosure and installation decision

Figure 1 summarizes our research model and hypotheses, which we test through an online experiment.

Figure 1. Research model with hypothesized relationships

Research Method
Setting and Data Collection
We tested our hypotheses using a quantitative between-subject online experiment with 206 participants.
Using an adapted vignette design (Finch 1987), we constructed a (fictitious) real-life scenario by asking
participants to imagine themselves in an online app-store and randomly presenting them one of three
contact-tracing app alternatives with a low, medium, or high level of TAT disclosure. To increase realism,
all visuals were modeled closely after real-life app-stores and participants had to take an actual installation
decision. While they were presented the app screenshot and description (Figure 2), participants were asked
multiple questions on the app; subsequently, further control questions were asked. This setting was chosen
to closely mimic an actual app adoption decision and thus increase the external validity of the study.

Figure 2. Treatments for low, medium, high TAT disclosure (translated from German)
We collected data from German-speaking participants residing in Germany. This group was selected to keep
our data sample as homogeneous as possible and to facilitate comparability with past research (Bitzer et al.
2021; Trang et al. 2020). The data were collected in January and February 2021. During this period, COVID19 infections in Germany were at consistently high levels and despite first vaccinations becoming available,
the slow start of the campaign highlighted the importance of continued social distancing and wellfunctioning contact-tracing. Arguably, this led to a high category need for contact-tracing apps and a basic
motivation of participants to engage with the topic, thereby also increasing the external validity (i.e., realism
and relevance) of the experiment and its results.

Forty-Second International Conference on Information Systems, Austin 2021
8

Algorithmic Transparency and Contact-tracing App Adoption

To recruit experiment participants, we used the online platform Prolific Academic (Palan and Schitter
2018). This enabled us to collect high-quality data in a comparatively short time of four weeks. In addition,
past research has found participants on Prolific to be less acquainted with survey-based research (Peer et
al. 2017), which supported our objective of creating a realistic environment of an app installation, rather
than a ‘pure’ survey setting. In total, we collected 230 completed responses. 24 participants were eliminated
due to failed attention checks, resulting in a final sample of 206 valid responses. It took participants 13
minutes on average (standard deviation [SD]: 6.1) to complete the experiment and they were paid 1.75
Euros. To ensure high data quality, we used procedural safeguards. For example, we checked for outliers
and excessively short response times; unique response IDs; and high Prolific confidence ratings (a platformspecific quality measure of participants’ responses). The mean age was 27.5 years (SD: 7.2) and almost all
participants had a high school (42%) or university (52%) degree. Participants’ gender (46% female), average
household size (2.4 people), and income (<1,500€: 58 responses; 1,501-3,500€: 89; >3,500€: 43) are
indicative of the sample’s representativeness. Also, the sample demographics match the demographics of
real-life contact-tracing app users (e.g., young to medium age, medium to well educated).

Experimental Design
Participants took part in the experiment through an online survey. At the beginning, they were briefed on
the context and duration of the experiment and informed that anonymized results would be published. The
participants were then asked to imagine that they were searching an online app-store for contact-tracing
apps and randomly presented one of three app options with a low, medium, or high level of TAT disclosure
(manipulation) as the outcome of this search. Next, participants were asked to fill in a survey with the
following constructs: TAT disclosure (independent variable) was assessed using a construct that considers
the three aspects of how, why, and provision of additional information (Diakopoulos and Koliska 2017;
Wang and Benbasat 2007; Zhao et al. 2019); TAT comprehension was assessed using the seven-item
perceived transparency construct by Wang and Benbasat (2016); trust was assessed using the three-item
construct from Cyr et al. (2009); installation decision was measured with a simple yes/no question. Benefit
appeal and Coronavirus anxiety were measured using constructs adapted from an earlier study on contacttracing app adoption by Trang et al. (2020).
Our survey instrument included several control variables. To ensure comparability, the measures and items
for these were also adopted from the study by Trang et al. (2020): general privacy concern (Malhotra et al.
2004), IT self-efficacy (Heinssen et al. 1987), gender, age, and education. In addition, we controlled for
effort expectancy and performance expectancy (Venkatesh et al. 2003), personal innovativeness in IT
(Agarwal and Prasad 1998), the use of the German contact-tracing app (“Corona app use”), net income, and
household size. All latent variables (e.g., general privacy concern, IT self-efficacy) were rated with multiple
items on seven-point Likert scales ranging from “fully disagree” to “fully agree”. To assess construct
reliability and validity, we assessed item loadings, Cronbach’s Alpha, and average variance extracted (AVE),
all of which were found to be above the critical thresholds of 0.6, 0.8, and 0.5, respectively (for details, see
Appendix A). Further, to test for discriminant validity, we compared the square root of each construct’s
AVE to its correlations with other constructs following the approach used by Wang and Benbasat (2016).
The respective AVE square roots were found to be consistently greater than the relevant correlations,
indicating discriminant validity.
As local languages are typically used in an app store, we provided all questions and descriptions in German.
While the features in the description were in line with the official German app (e.g., decentral data storage,
use of Bluetooth), the app name (“Pandemie-Warn-App”) and its visual appearance were fictitious to reduce
the risk of biases from the original. Also, given the uncertainty surrounding the official app, we did not want
to increase the insecurity through exhibits that are very close to the original. The visualization of the three
app alternatives was intentionally identical. The app description differed only in the level of TAT disclosure
provided. We manipulated TAT disclosure based on three elements mentioned in extant literature: How
does the app work? (Wang and Benbasat 2007); Why is the approach justified? (Zhao et al. 2019); and the
provision of additional information (Diakopoulos and Koliska 2017). The low TAT disclosure treatment did
not include any of this information, whereas the medium TAT disclosure treatment included qualitative
how-information only, and the high TAT disclosure treatment included both qualitative and quantitative
how-information, why-information, as well as additional information. To ensure comprehensibility, we pretested the survey with 60 participants on Prolific, resulting in some minor adjustments (e.g., in wording).

Forty-Second International Conference on Information Systems, Austin 2021
9

Algorithmic Transparency and Contact-tracing App Adoption

Item
Please evaluate the following aspect of the
app description above: …

Mean (standard deviation)
Low
Medium
High
(N=75)
(N=63)
(N=68)
… Amount of information
3.87 (1.36)* 5.05 (1.00)* 5.84 (.96)*
… Complexity of information
3.60 (1.44)* 4.90 (1.03)* 5.75 (1.06)*
… Variety of information
3.68 (1.34)* 4.46 (1.15)* 5.26 (1.12)*
* The mean difference is significant at the .05 level; *** p<.001

F (2,203)
54.973***
58.084***
30.598***

Table 1. Results of manipulation test for low, medium and high TAT disclosure
To ensure that the random assignment of the three treatment conditions led to demographically uniform
samples, we compared the sample demographics. There is no significant difference in age (F (2, 203) = .353,
p=.703)) and household size (F (2, 203) = 1.048, p = .352). Also, Pearson’s chi-squared test indicates no
significant difference in the distribution of gender (p=.500), education (p=.822), and Corona app use
(p=.128), and only a marginally significant difference (p=.046) in income-class distribution across the three
treatments, yet without indicating particular tendencies. To ensure external validity, we measured realism,
using a four-item construct from Green (2004) (Cronbach’s Alpha =.779). The result (MRealism=5.61) exceeds
thresholds from comparable research (Trang et al. 2020)(MRealism=5.29), suggesting participants perceived
the mock app-store scenario as realistic. Further, to ensure that the three treatment conditions yielded the
intended effect, we conducted a pre-test and a confirmatory manipulation check at the start of the
experiment. For the pre-test, we randomly presented one of the descriptions to a total of 226 participants
and asked them to indicate the level of TAT disclosure. The results showed that TAT disclosure was
perceived significantly different for the three descriptions (F (2,223) = 126.798, p <.001, ω = .73; MLow =
2.45, MMedium = 3.46, MHigh = 5.35). For the manipulation check, we asked participants to rate the amount,
complexity, and variety of the shown information on a scale from 1 to 7. The comparison of the means (Table
1) suggests that the treatments were processed as intended and that significant differences were perceived.
This was also confirmed by the results of Tukey’s HSD post-hoc test (p<.001) (Tukey 1977).

Results
Variables included

B (95% CIa)

S.E.
p
95% CI for Exp(B)a
b
B
Lower
Exp(B) Upper
TAT disclosure
-.13 (-.71, .29)
.31
.478
.61
.88
1.26
TAT comprehension
.14 (-.79, 1.15)
.44
.618
.67
1.15
1.95
Trust
1.26 (.23, 6.4)
.69
<.001
1.79
3.53
6.96
-.78 (-2.88, .47)
2.21
.375
.08
.46
2.56
Self-benefitc
Coronavirus anxiety
.19 (-.52, 1.15)
.34
.445
.74
1.21
1.97
Effort expectancy
.06 (-1.38, 1.23)
.55
.855
.54
1.07
2.11
Performance expectancy
.36 (-.29, 1.58)
.31
.098
.94
1.43
2.18
General privacy concern
-.12 (-.82, .56)
.34
.606
.56
.89
1.41
IT self-efficacy
.02 (-.86, .93)
.50
.963
.53
1.02
1.96
Personal innovativeness
.58 (-.51, 2.78)
.52
.107
.88
1.78
3.58
Female
.41 (-1.27, 1.93)
.83
.460
.51
1.50
4.39
Age
.00 (-.12, .14)
.06
.916
.93
1.00
1.08
Household size
.09 (-.43, .75)
.28
.679
.72
1.09
1.67
Tertiary educationd
-.30 (-1.74, .75)
.77
.569
.26
.74
2.08
Net income lowe
1.01 (-.65, 3.61)
.80
.071
.92
2.75
8.24
Net income highe
1.68 (-1.72, 24.05)
6.56
.156
.53
5.37
54.75
Corona app use
2.51
.93
<.001
4.30
12.28
35.03
Constant
-12.94 (-17.53, -14.06)
4.85
<.001
.00
R² = .51 (Hosmer-Lemeshow), .49 (Cox-Snell), .67 (Nagelkerke). Model χ²(17) = 135.38, p <.001.
a 95% confidence interval, bias corrected and accelerated based on 1,000 bootstrap samples b Based on
1,000 bootstrap samples. c Reference: Societal b. d Reference: High-school ed. e Reference: Medium inc.
Table 2. Results of binary logistic regression (dependent variable: installation decision)

Forty-Second International Conference on Information Systems, Austin 2021
10

Algorithmic Transparency and Contact-tracing App Adoption

To answer our first research question, we conducted binary logistic regression to test H1, H2b, and H3b,
which suggest that TAT disclosure, TAT comprehension, and trust are positively related to the decision to
install the contact-tracing app. While we do not find a significant direct effect of TAT disclosure (p=.48)
and TAT comprehension (p=.62), we do find a significant, positive effect for trust on installation decision
(Exp(B)=3.53, p<.001), supporting H3b (see Table 2). Control variables are not significant (p>.05), except
for Corona app use, which has a positive relationship with installation decision (Exp(B) = 12.28, p <.001).
To test H2a, H3a, and H4, we conducted mediation analyses using Process for SPSS (Hayes 2018) (Table
3). We find a positive relationship of TAT disclosure with TAT comprehension (b=.42, p<.001) and trust
(b=.23, p<.001), confirming H2a and H3a. We also find a positive relationship of TAT comprehension with
trust (b=.46, p<.001), supporting H4. Combined with the positive relationship of TAT disclosure and TAT
comprehension, this suggests a significant indirect effect of TAT disclosure on trust via TAT comprehension
(b = .19, 95% BCa CI [.12, .27], R²=.29). As H2b had to be rejected (see above), we find no significant,
mediated effect of TAT disclosure on installation decision via TAT comprehension (b=.07, 95% BCa CI [.14, .29]). However, we do find a significant serial mediated effect of TAT disclosure on installation decision
via TAT comprehension and trust (b= .25, 95% BCa CI [.14, .46]), offering partial support for H2. Finally,
based on the positive relationship between trust and installation decision, we find a significant indirect
effect of TAT disclosure on installation decision via trust (b=.30, 95% BCa CI [.14,.57]), confirming H3.
Independent
variables
TAT disc. (X)
TAT comp. (M1)
Trust (M2)
Cor.-app use (C)
Constant

Dependent variables
TAT comp. (M1)
Trust (M2)
Coeff. SE
p
Coeff. SE
p
.42
.05 <.001
.23
.05 <.001
.46
.06 <.001
-.02
.16
.90
.68
.15 <.001
3.73
.22 <.001
1.27
.03
.001
R²=.29,
R²=.44,
F(2,201)=40.52,
F(3,200)=51.82,
p<.001
p<.001

Installation decision (Y)
Coeff. SE
p
Exp(B)
-.08
.16 .6297
.92
.16
.22 .4858
1.17
1.31
.27 <.001
3.71
2.70
.47 <.001
14.88
-7.86 <.001
1.24
.00
R²= .44 (McFadden),
.45 (Cox-Snell),
.61 (Nagelkerke)

Table 3. Results of serial mediation analysis
Regarding our second research question, we conducted moderated mediation analysis using Process for
SPSS to test H5 and H6, which suggest that self-benefit appeal and high Coronavirus anxiety weaken the
positive relationship of TAT disclosure and installation decision. We find no significant interaction effect
on the (direct) link between TAT disclosure and installation decision for neither benefit appeal (p= .9330),
nor Coronavirus anxiety (p= .5965). Thus, H5 and H6 are not supported. We also tested for the moderated
indirect effect of TAT disclosure on installation decision through TAT comprehension and trust: since all
bootstrapped 95% confidence intervals for the indices of moderated mediation (Hayes 2015) include zero,
the possibility of no indirect effect cannot be excluded. Figure 3 summarizes the analysis results.

Figure 3. Completed research model with identified relationships

Forty-Second International Conference on Information Systems, Austin 2021
11

Algorithmic Transparency and Contact-tracing App Adoption

Discussion
In this study, we conducted an online experiment on contact-tracing apps to advance our understanding of
how TAT disclosure influences app adoption and to shed light on the role of moderating factors. We find
empirical evidence for a positive, indirect relationship of TAT disclosure and installation decision, fully
mediated by TAT comprehension and trust, as well as for a partially mediated effect of TAT comprehension
on trust. Yet, we find no evidence for a moderating role of self-benefit appeal and Coronavirus anxiety. In
the following, we discuss our study’s implications, as well as limitations and avenues for future research.

Theoretical Implications
The contributions of our study to IS research are of both conceptual and empirical nature, as the arguments
put forward conceptualize the theoretical links between TAT disclosure and contact-tracing app adoption,
as well as because the study results provide an empirical basis for developing a nuanced understanding of
the partly complex relationships between these concepts and also explore the role of moderating factors.
By providing a theoretically well-founded model of the relationships between TAT disclosure and adoption
behavior, our study helps explain previous findings (Cramer et al. 2008; Wang and Benbasat 2007) and
solidifies TAT disclosure as an antecedent of trust and as an indirect adoption factor. In that, our study not
only extends extant adoption literature to the novel context of algorithm-enabled technologies, specifically
contact-tracing apps; rather, and arguably more importantly, by empirically studying the effects of different
TAT disclosure levels, it also sheds light on the question of how algorithms should be made more
transparent (Watson and Nations 2019) – a topic that is increasingly gaining interest among IS scholars
under a range of different terms, such as explainable AI (Goebel et al. 2018), ethics of algorithms (Ananny
2016), and algorithmic accountability (Martin 2019). Of particular relevance for this discussion is the
finding that TAT disclosure needs to be considered in combination with other adoption factors, such as TAT
comprehension and trust, to determine the ‘right’ amount and contents of the provided information.
On the empirical side, our finding that TAT disclosure is positively related to installation decision through
a ‘two-step’ indirect relationship via TAT comprehension and trust extends prior research with a nuanced
view on the mechanisms leading to user adoption through trust. The finding that trust fully mediates the
effects of TAT disclosure and TAT comprehension on adoption differs from prior research (Bitzer et al.
2021), which finds a direct effect of TAT disclosure on app selection (i.e., a situation where users are forced
to choose one of multiple app options) and underscores the role of trust. One explanation for this difference
may be the single-choice setting in the present study, i.e., participants were asked to decide whether they
would like to install the app or not, while in prior research they were given multiple options to choose from
but did not have the ‘no installation’ option. This distinction (selection vs. adoption) is important, as in a
‘selection’ setting with multiple alternatives, a relatively higher or lower level of TAT disclosure is instantly
visible and thus a direct decision criterion. Meanwhile, in the present study, the level of a given app’s TAT
disclosure cannot be compared and may thus have (only) an indirect influence via trust. This implies that
trust may play an even more prominent role in single choice settings as users cannot compare alternatives
themselves. Future studies could further explore this potentially interesting difference across settings.
As well, our findings that TAT disclosure, TAT comprehension, and trust are connected through multiple
indirect relationships provide evidence that the decision what and how much to disclose will have inevitable
implications on the comprehension and trust of potential users. Although such relationships had been
suspected previously, prior research did not distinguish between TAT disclosure and TAT comprehension,
leading to contradicting findings: For example, while Cramer et al. (2008) find a linear positive
relationship, Lehmann et al. (2020) find a linear negative relationship and Kizilcec (2016) finds a bellshaped curve. By distinguishing TAT disclosure and comprehension and by showing that TAT disclosure
has both a direct effect on trust and an indirect effect through TAT comprehension, our study provides an
explanation that integrates prior arguments regarding confounding effects (e.g., algorithm complexity)
(Lehmann et al. 2020). For example, antecedents of TAT comprehension, such as complexity and
information overload, may lead to a decrease in TAT comprehension and trust, even as TAT disclosure
increases. The same may happen when other antecedents, such as individuals’ disposition to trust, decrease
trust. Our findings thus contribute to a more comprehensive assessment of trust and its antecedents.

Forty-Second International Conference on Information Systems, Austin 2021
12

Algorithmic Transparency and Contact-tracing App Adoption

Finally, our findings that neither self-benefit appeal nor Coronavirus anxiety have a moderating effect on
the positive relationship of TAT disclosure with installation decision raise some interesting questions. For
example, these findings seem to contrast the results by Trang et al. (2020), who find differing direct effects
of self and societal benefit appeal on installation intention. The (moderating) influence of these and other
context factors thus appears to be more complex than anticipated, requiring further research.

Practical Implications
In practical terms, our findings have implications for health authorities and policy-makers, application
developers, and user rights advocates, as they not only underscore the possibility to promote installation
decisions through TAT disclosure, but also reiterate the importance of trust, and the distinction of selection
and adoption settings. First, as health authorities aim for (mass) acceptance of contact-tracing apps, they
must acknowledge the importance of disclosing sufficient information, as well as of building trust. In this
regard, our results indicate that TAT disclosure is a necessary but not a sufficient condition for promoting
contact-tracing app adoption. This distinction is important, as recent research and public opinion tends to
view transparency as a magic ‘potion’ that convinces people to adopt a given (algorithm-based) technology.
This notion, however, seems to be erroneous and may even further public frustration about the limited
effectiveness of contact-tracing apps in general. Indeed, one may argue that by creating a material level of
transparency, health authorities increased public expectations about a novel, unproven technology, while
neglecting other potential measures for building public trust, such as early demonstrating a positive impact
of the technology in practice and ensuring proper governance and oversight (Blasimme and Vayena 2020).
Second, there are important takeaways for application developers interested to promote algorithm-based
apps. First, developers as well require both TAT disclosure and other trust-building measures, such as a
positive developer brand. Another learning stems from the finding that TAT disclosure alone, without TAT
comprehension, affects trust. Thus, depending on the specific context, developers may consciously forego
TAT comprehension and try to drive trust and adoption through TAT disclosure only. While transparency
without understanding seems paradoxical, it may be justified for complex or proprietary apps. Further,
given that people seem to react differently to TAT disclosure in selection and adoption settings, developers
must be aware of the concrete decision setting to accordingly tailor the level of TAT disclosure of their apps.
Finally, our findings also come with important implications for user rights advocates, calling for improved
information about algorithm-enabled technologies. Our research offers arguments for investing into TAT
disclosure, as this will not only increase clarity and trust for individuals, but also ‘reward’ app providers
with higher adoption rates. However, our findings also add a note of caution, since they suggest that just
the provision of a high amount of information can prompt individuals to trust and ultimately to install an
app, without them having actually understood the technology. Accordingly, close scrutiny is required to
determine if high levels of TAT disclosure are indeed provided with prospective users’ best interests in
mind.

Limitations and Avenues for Future Research
As with any research, our study comes with some limitations, which also point toward promising areas of
future research. First, our study focuses on the specific context of contact-tracing app adoption. Due to the
current pandemic situation (with extensive media coverage), citizens may be comparatively betterinformed than in a typical adoption situation. In our view, the importance and urgency of investigating this
context, outweighs this limitation. Still, future research on the links between AT and technology adoption
should also study other algorithm-based technologies in ‘regular’ contexts (e.g., algorithm-based decision
support tools in business organizations) to broaden and examine the generalizability of our findings. Also,
focusing on app adoption, our study does not investigate long-term usage. Here, future research involving
the collection of longitudinal data is needed. Second, from a methodological stance, structured equation
modeling might offer additional insights on the studied relationships. However, given the characteristics of
our dataset (e.g., no missing data points), we expect such additional insights to be marginal (Hayes et al.
2017). Furthermore, in our study, participants indicated their intention to install the app by clicking on an
“install” button; however, the installation of an actual app was not part of the study. As such, the results of
our study might be affected by an action-intention gap (Bélanger and Crossler 2011). Another potential
methodological shortcoming pertains to the risk of common method bias (CMB) arising from social
desirability of high TAT comprehension. In line with the remedies proposed by Podsakoff et al. (2003), we

Forty-Second International Conference on Information Systems, Austin 2021
13

Algorithmic Transparency and Contact-tracing App Adoption

measured social desirability and found no significant effects. Still, we cannot fully rule out CMB. Also, our
data sample leans toward younger, better educated participants, which is common for online experiments
(Peer et al. 2017) and in tune with the ‘average’ German smartphone user. While we did not find any effects
of age or education in our analyses, future studies may benefit from a more diverse sample. Finally, given
that our sample is drawn from an online research platform (Prolific Academic), the survey environment is
less controlled than in lab experiments and platform participants’ naivety may be less pronounced, as they
are likely to be more acquainted with survey-based research (Palan and Schitter 2018). It may thus be
worthwhile to conduct replication studies in the form of lab experiments involving regular citizens.

Conclusion
Shedding light on the relationships between TAT disclosure and contact-tracing app adoption, our study
provides several theoretically and practically relevant findings. First, while we find no significant direct link
between TAT disclosure and individuals’ installation decision; still, we do find a significant indirect
relationship, mediated by TAT comprehension and trust into the app. Second, our analyses suggest that
these findings hold regardless of individuals’ benefit appeal and Coronavirus anxiety. As such, our study
offers empirical evidence for the general relevance of TAT disclosure in adoption decisions. From a practical
perspective, this implies that TAT disclosure is an effective means in driving trust, and thus in driving the
adoption of contact-tracing apps and potentially of algorithm-based technologies in general.

References
Agarwal, R., and Prasad, J. 1998. “A Conceptual and Operational Definition of Personal Innovativeness in
the Domain of Information Technology,” Information Systems Research (9:2), pp. 204-215.
Ananny, M. 2016. “Toward an Ethics of Algorithms,” Science, Technology, & Human Values (41:1), pp.
93-117 (doi: 10.1177/0162243915606523).
Averbeck, J. M., Jones, A., and Robertson, K. 2011. “Prior Knowledge and Health Messages: An
Examination of Affect as Heuristics and Information as Systematic Processing for Fear Appeals,”
Southern Communication Journal (76:1), pp. 35-54 (doi: 10.1080/10417940902951824).
Bélanger, and Crossler 2011. “Privacy in the Digital Age: A Review of Information Privacy Research in
Information Systems,” MIS Quarterly (35:4), pp. 1017-1041 (doi: 10.2307/41409971).
Bernstein, E. S. 2017. “Making Transparency Transparent: The Evolution of Observation in Management
Theory,” Academy of Management Annals (11:1), pp. 217-266 (doi: 10.5465/annals.2014.0076).
Bitzer, T., Wiener, M., and Morana, S. 2021. “Algorithmic Transparency and Contact-tracing Apps – An
Empirical Investigation,” in AMCIS 2021 Proceedings, Association of Information Systems 2021 (ed.).
Blasimme, A., and Vayena, E. 2020. “What’s next for COVID-19 apps? Governance and oversight,” Science
(370:6518), pp. 760-762 (doi: 10.1126/science.abd9006).
Blom, A. G., Wenz, A., Cornesse, C., Rettig, T., Fikel, M., Friedel, S., Möhring, K., Naumann, E.,
Reifenscheid, M., and Krieger, U. 2021. “Barriers to the Large-Scale Adoption of a COVID-19 Contact
Tracing App in Germany: Survey Study,” Journal of Medical Internet Research (23:3), e23362.
Braithwaite, I., Callender, T., Bullock, M., and Aldridge, R. W. 2020. “Automated and partly automated
contact tracing: a systematic review to inform the control of COVID-19,” The Lancet Digital Health
(2:11), e607-e621 (doi: 10.1016/S2589-7500(20)30184-9).
Burrell, J. 2016. “How the machine ‘thinks’: Understanding opacity in machine learning algorithms,” Big
Data & Society (3:1), 1-12 (doi: 10.1177/2053951715622512).
Castelvecchi, D. 2016. “Can we open the black box of AI?” Nature (538:7623), pp. 20-23.
Choi, J. K., and Ji, Y. G. 2015. “Investigating the Importance of Trust on Adopting an Autonomous
Vehicle,” International Journal of Human-Computer Interaction (31:10), pp. 692-702.
Cramer, H., Evers, V., Ramlal, S., van Someren, M., Rutledge, L., Stash, N., Aroyo, L., and Wielinga, B.
2008. “The effects of transparency on trust in and acceptance of a content-based art recommender,”
User Modeling and User-Adapted Interaction (18:5), pp. 455-496 (doi: 10.1007/s11257-008-9051-3).
Datta, A., Sen, S., and Zick, Y. 2016. “Algorithmic Transparency via Quantitative Input Influence: Theory
and Experiments with Learning Systems,” in 2016 IEEE Symposium on Security and Privacy, pp.
598-617.
Davis, F. D., Bagozzi, R. P., and Warshaw, P. R. 1989. “User Acceptance of Computer Technology: A
Comparison of Two Theoretical Models,” Management Science (35:8), pp. 982-1003.

Forty-Second International Conference on Information Systems, Austin 2021
14

Algorithmic Transparency and Contact-tracing App Adoption

Diakopoulos, N., and Koliska, M. 2017. “Algorithmic Transparency in the News Media,” Digital
Journalism (5:7), pp. 809-828 (doi: 10.1080/21670811.2016.1208053).
ECDC 2021. COVID-19 situation update worldwide, as of week 13 2021.
https://www.ecdc.europa.eu/en/geographical-distribution-2019-ncov-cases. Accessed 13 April 2021.
Eslami, M., Krishna Kumaran, S. R., Sandvig, C., and Karahalios, K. 2018. “Communicating Algorithmic
Process in Online Behavioral Advertising,” in Proceedings of the 2018 Conference on Human Factors
in Computing Systems, R. Mandryk, M. Hancock, M. Perry and A. Cox (eds.), New York, NY, pp. 1-13.
Farronato, C., Iansiti, M., Bartosiak, M., Denicolai, S., Ferretti, L., and Fontana, R. 2020. “How to Get
People to Actually Use Contact-Tracing Apps,” Harvard Business Review Digital Articles.
Ferretti, L., Wymant, C., Kendall, M., Zhao, L., Nurtay, A., Abeler-Dörner, L., Parker, M., Bonsall, D., and
Fraser, C. 2020. “Quantifying SARS-CoV-2 transmission suggests epidemic control with digital
contact tracing,” Science (New York, N.Y.) (368:6491) (doi: 10.1126/science.abb6936).
Finch, J. 1987. “The Vignette Technique in Survey Research,” Sociology (21:1), pp. 105-114.
Finucane, M. L., Alhakami, A., Slovic, P., and Johnson, S. M. 2000. “The affect heuristic in judgments of
risks and benefits,” Journal of Behavioral Decision Making (13:1), pp. 1-17.
Fraser, C. 2020. Digital contact tracing can slow or even stop coronavirus transmission and ease us out
of lockdown. https://www.research.ox.ac.uk/Article/2020-04-16-digital-contact-tracing-can-slow-oreven-stop-coronavirus-transmission-and-ease-us-out-of-lockdown. Accessed 6 January 2020.
Gierlich-Joas, M., Hess, T., and Neuburger, R. 2020. “More self-organization, more control—or even
both? Inverse transparency as a digital leadership concept,” Business Research (13:3), pp. 921-947.
Gillespie, T. 2014. “The relevance of algorithms,” in Media Technologies: Essays on Communication,
Materiality, and Society, T. Gillespie, P. J. Boczkowski and K. A. Foot (eds.), Cambridge: MIT Press,
pp. 167-193.
Goad, D., and Gal, U. 2018. “Understanding the Impact of Transparency on Algorithmic Decision Making
Legitimacy,” in Living with Monsters?: Social Implications of Algorithmic Phenomena, Hybrid
Agency, and the Performativity of Technology, U. Schultze, M. Aanestad, M. Mähring, C. Østerlund
and K. Riemer (eds.), Cham, Switzerland: Springer, pp. 64-79.
Goebel, R., Chander, A., Holzinger, K., Lecue, F., Akata, Z., Stumpf, S., Kieseberg, P., and Holzinger, A.
2018. “Explainable AI: The New 42?” in Machine Learning and Knowledge Extraction, A. Holzinger,
P. Kieseberg, A. M. Tjoa and E. Weippl (eds.), Cham, Switzerland: Springer, pp. 295-303.
Gozzi, N., Bajardi, P., and Perra, N. 2021. “The importance of non-pharmaceutical interventions during
the COVID-19 vaccine rollout,” medRxiv 2021.01.09.21249480 (doi: 10.1101/2021.01.09.21249480).
Green, M. C. 2004. “Transportation Into Narrative Worlds: The Role of Prior Knowledge and Perceived
Realism,” Discourse Processes (38:2), pp. 247-266 (doi: 10.1207/s15326950dp3802_5).
Hansen, H. K., and Flyverbom, M. 2015. “The politics of transparency and the calibration of knowledge in
the digital age,” Organization (22:6), pp. 872-889 (doi: 10.1177/1350508414522315).
Hayes, A. F. 2015. “An Index and Test of Linear Moderated Mediation,” Multivariate behavioral research
(50:1), pp. 1-22 (doi: 10.1080/00273171.2014.962683).
Hayes, A. F. 2018. Introduction to mediation, moderation, and conditional process analysis: A
regression-based approach, New York: The Guilford Press.
Hayes, A. F., Montoya, A. K., and Rockwood, N. J. 2017. “The Analysis of Mechanisms and Their
Contingencies: PROCESS versus Structural Equation Modeling,” Australasian Marketing Journal
(25:1), pp. 76-81 (doi: 10.1016/j.ausmj.2017.02.001).
Heinssen, R. K., Glass, C. R., and Knight, L. A. 1987. “Assessing computer anxiety: Development and
validation of the Computer Anxiety Rating Scale,” Computers in Human Behavior (3:1), pp. 49-59.
Kizilcec, R. F. 2016. “How much information? Effects of transparency on trust in an algorithmic
interface,” 2016 CHI Conference on Human Factors in Computing Systems, pp. 2390-2395.
Kramer, R. M. 1999. “Trust and distrust in organizations: emerging perspectives, enduring questions,”
Annual Review of Psychology (50:1), pp. 569-598 (doi: 10.1146/ANNUREV.PSYCH.50.1.569).
Lai, V., and Tan, C. 2019. “On Human Predictions with Explanations and Predictions of Machine Learning
Models,” in Proceedings of the 2019 Conference on FAT, pp. 29-38.
Lee, J. D., and See, K. A. 2004. “Trust in automation: designing for appropriate reliance,” Human Factors
(46:1), pp. 50-80 (doi: 10.1518/hfes.46.1.50_30392).
Lee, S. A., Jobe, M. C., Mathis, A. A., and Gibbons, J. A. 2020. “Incremental validity of coronaphobia:
Coronavirus anxiety explains depression, generalized anxiety, and death anxiety,” Journal of Anxiety
Disorders (74), p. 102268 (doi: 10.1016/j.janxdis.2020.102268).

Forty-Second International Conference on Information Systems, Austin 2021
15

Algorithmic Transparency and Contact-tracing App Adoption

Lehmann, C. A., Haubitz, C., Fuegener, A., and Thonemann, U. 2020. “Keep It Mystic? – The Effects of
Algorithm Transparency on the Use of Advice,” in ICIS 2020 Proceedings.
Malhotra, N. K., Sung, S. K., and Agarwal, J. 2004. “Internet Users’ Information Privacy Concerns: The
Construct, the Scale, and a Causal Model,” Information Systems Research (15:4), pp. 336-355.
Martin, K. 2019. “Ethical Implications and Accountability of Algorithms,” Journal of Business Ethics
(160:4), pp. 835-850 (doi: 10.1007/s10551-018-3921-3).
Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., and Floridi, L. 2016. “The ethics of algorithms:
Mapping the debate,” Big Data & Society (3:2), 1-21 (doi: 10.1177/2053951716679679).
Nicola, M., Alsafi, Z., Sohrabi, C., Kerwan, A., Al-Jabir, A., Iosifidis, C., Agha, M., and Agha, R. 2020. “The
socio-economic implications of the coronavirus pandemic (COVID-19): A review,” International
Journal of Surgery (London, England) (78), pp. 185-193 (doi: 10.1016/j.ijsu.2020.04.018).
Palan, S., and Schitter, C. 2018. “Prolific.ac—A subject pool for online experiments,” Journal of
Behavioral and Experimental Finance (17), pp. 22-27 (doi: 10.1016/j.jbef.2017.12.004).
Peer, E., Brandimarte, L., Samat, S., and Acquisti, A. 2017. “Beyond the Turk: Alternative platforms for
crowdsourcing behavioral research,” Journal of Experimental Social Psychology (70), pp. 153-163.
Podsakoff, P. M., MacKenzie, S. B., Lee, J.-Y., and Podsakoff, N. P. 2003. “Common method biases in
behavioral research: a critical review of the literature and recommended remedies,” The Journal of
Applied Psychology (88:5), pp. 879-903 (doi: 10.1037/0021-9010.88.5.879).
RKI 2021. Kennzahlen zur Corona-Warn-App.
https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/WarnApp/Archiv_Kennzahlen/
Kennzahlen_01042021.pdf. Accessed 3 April 2021.
Rowe, F., Ngwenyama, O., and Richet, J.-L. 2020. “Contact-tracing apps and alienation in the age of
COVID-19,” European Journal of Information Systems (29:5), pp. 545-562.
Sinha, R., and Swearingen, K. 2002. “The role of transparency in recommender systems,” in CHI 2002
Extended Abstracts on Human Factors in Computing Systems, L. Terveen (ed.), New York, NY.
Springer, A., and Whittaker, S. 2019. “Making Transparency Clear: The Dual Importance of Explainability
and Auditability,” in Joint Proceedings of the ACM IUI 2019 Workshops, Los Angeles, CA. March 20.
The World Bank 2021. “Global Economic Prospects, January 2021,” Washington, D.C.: The World Bank.
Trang, S., Trenz, M., Weiger, W. H., Tarafdar, M., and Cheung, C. M. 2020. “One app to trace them all?
Examining app specifications for mass acceptance of contact-tracing apps,” European Journal of
Information Systems (29:4), pp. 1-14 (doi: 10.1080/0960085X.2020.1784046).
Tukey, J. W. 1977. Exploratory Data Analysis, Reading, Mass.: Addison Wesley.
Venkatesh, Morris, and Davis 2003. “User Acceptance of Information Technology: Toward a Unified
View,” MIS Quarterly (27:3), pp. 425-478 (doi: 10.2307/30036540).
Walrave, M., Waeterloos, C., and Ponnet, K. 2020. “Adoption of a Contact Tracing App for Containing
COVID-19: A Health Belief Model Approach,” JMIR Public Health and Surveillance (6:3), e20572.
Wang, W., and Benbasat, I. 2007. “Recommendation Agents for Electronic Commerce: Effects of
Explanation Facilities on Trusting Beliefs,” Journal of Management Information Systems (23:4), pp.
217-246 (doi: 10.2753/MIS0742-1222230410).
Wang, W., and Benbasat, I. 2016. “Empirical Assessment of Alternative Designs for Enhancing Different
Types of Trusting Beliefs in Online Recommendation Agents,” Journal of Management Information
Systems (33:3), pp. 744-775 (doi: 10.1080/07421222.2016.1243949).
Watson, H. J., and Nations, C. 2019. “Addressing the Growing Need for Algorithmic Transparency,”
Communications of the Association for Information Systems (45:1), pp. 488-510.
Xu, R., Frey, R. M., Fleisch, E., and Ilic, A. 2016. “Understanding the impact of personality traits on
mobile app adoption – Insights from a large-scale field study,” Computers in Human Behavior (62),
pp. 244-256 (doi: 10.1016/j.chb.2016.04.011).
Zajonc, R. B. 1980. “Feeling and thinking: Preferences need no inferences,” American Psychologist (35:2),
pp. 151-175 (doi: 10.1037/0003-066X.35.2.151).
Zhao, R., Benbasat, I., and Cavusoglu, H. 2019. “Do users always want to know more? Investigating the
relationship between system transparency and users’ trust in advice-giving systems,” in ECIS
Proceedings.
Zouave, E. T., and Marquenie, T. 2017. “An Inconvenient Truth: Algorithmic Transparency &
Accountability in Criminal Intelligence Profiling,” in EISIC Proceedings, IEEE, pp. 17-23.

Forty-Second International Conference on Information Systems, Austin 2021
16

Algorithmic Transparency and Contact-tracing App Adoption

Appendix A: Constructs and measurement items
Item
FL*
TAT Disclosure (α=.941; AVE=.684; M=3.31; SD=1.62)
(Based on Diakopoulos and Koliska 2017; Wang and Benbasat 2007; Zhao et al. 2019)
The app description contains much information explaining how the app’s process steps & calculation work
.651
The app description provides me with information on the app’s qualitative & quantitative decision criteria
.678
The app description explains where and how information are processed and stored
.759
In the app description I am informed why the app approach was selected and is better than alternatives
.923
The app description explains the reasons why the approach in the app was selected
.916
The app description explains the reasons why the approach in the app is better than other alternatives
.894
The app description informs me about additional sources of information (e.g., code, … documentation)
.891
In the app description I am informed where I can obtain additional information on the app source code
.842
In the app description I am informed where I can obtain additional technical documentation
.836
TAT Comprehension (α=.933; AVE=.753; M=5.11; SD=1.28) (Adapted from Wang and Benbasat (2016))
This App made its reasoning process clear to me.
.844
It was readily apparent to me how this App generates its recommendations.
.888
I could easily understand this App’s reasoning process
.860
It was easy for me to understand the inner workings of this App.
.882
I could understand why and how this App produces its results.
.906
The App’s logic in determining the risk of being infected was clear to me.
.824
Trust (α=.922; AVE=.865; M=4.81; SD=1.30) (Adapted from Cyr et al. (2009))
I can trust this app
.935
I trust the information presented in this app
.925
I trust the process in this app
.930
Benefit appeal (Based on Trang et al. (2020)): Please indicate the statement that you agree with most:
a) “I’d install the app to protect myself against a virus (e.g., the Coronavirus)”
b) “I’d install the app to protect others against a virus.”
c) “I’d install the app to protect myself and others against a virus.”
Effort expectancy(α=.886; AVE=.756; M=5.94; SD=.91) (Venkatesh et al. 2003)
My interaction with the app would be clear and understandable.
.818
It would be easy for me to become skillful at using the app.
.874
I would find the app easy to use.
.890
Learning to operate the app is easy for me
.893
Performance expectancy (α=.927; AVE=.821; M=4.54; SD=1.41) (Venkatesh et al. 2003)
I would find the app useful to protect myself against a virus (e.g., the Coronavirus)
.908
Using the app would enable me to protect myself more quickly against a virus (e.g., the Coronavirus)
.892
Using the app would help me protect myself better against a virus (e.g., the Coronavirus)
.946
If I use the app, I will increase my chances of being protected against a virus (e.g., the Coronavirus)
.878
General privacy concern (α=.846; AVE=.616; M=4.62; SD=1.11) (Malhotra et al. 2004)
All things considered, the Internet would cause serious privacy problems. (dropped due to low factor loading)
.450
Compared to others, I am more sensitive about how online companies handle my personal information
.772
To me, it is the most important thing to keep my privacy intact
.832
I believe other people are not sufficiently concerned with online privacy issues
.692
Compared with other subjects on my mind, personal privacy is very important.
.854
I am concerned about threats to my personal privacy.
.765
IT self-efficacy (α=.806; AVE=.843; M=5.76; SD=1.08) (Heinssen et al. 1987)
I feel comfortable learning new technologies
.918
I have a good understanding of technology and IT
.918
Personal innovativeness in IT (α=.886; AVE=.769; M=5.14; SD=1.14) (Agarwal and Prasad 1998)
If I heard about a new information technology, I would look for ways to experiment with it
.894
In general, I am open to try out new information technologies
.850
Among my peers, I am usually the first to try out new information technologies
.846
I like to experiment with new information technologies
.915
Coronavirus anxiety (α=.854; AVE=.696; M=3.10; SD=1.20) (Trang et al. 2020)
I spend a lot of time worrying about Coronavirus infections
.849
I often worry about getting infected with the COVID-19 virus
.887
When I hear about the Coronavirus, I often think that I could have been infected
.806
My family/friends would say I worry too much about a Coronavirus infection
.792
*FL=factor loading, α = Cronbach’s alpha, AVE = Average variance extracted, M = Mean, SD = Standard deviation

Forty-Second International Conference on Information Systems, Austin 2021
17

View publication stats

