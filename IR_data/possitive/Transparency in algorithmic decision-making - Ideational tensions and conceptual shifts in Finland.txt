https://helda.helsinki.fi

Transparency in algorithmic decision-making : Ideational
tensions and conceptual shifts in Finland
Ahonen, Pertti
2020-11-28

Ahonen , P & Erkkilä , T 2020 , ' Transparency in algorithmic decision-making : Ideational
tensions and conceptual shifts in Finland ' , Information Polity , vol. 25 , no. 4 , pp. 419-432 . https://doi.org/10.3233/IP
http://hdl.handle.net/10138/324369
https://doi.org/10.3233/IP-200259
acceptedVersion
Downloaded from Helda, University of Helsinki institutional repository.
This is an electronic reprint of the original article.
This reprint may differ from the original in pagination and typographic detail.
Please cite the original version.

Transparency in algorithmic decision-making: Ideational tensions and
conceptual shifts in Finland

Manuscript for an article appeared in Information Polity, 25 (4), pp. 419-432

Pertti Ahonen* and Tero Erkkilä
Political Science, Faculty of the Social Sciences, 00014 University of Helsinki, Finland

*Corresponding author: Pertti Ahonen, Political Science, Faculty of the Social Sciences, 00014
University of Helsinki, Finland. Tel. +358 400 735 760. Email pertti.ahonen@helsinki.fi.

Abstract. This article uses a theoretical and methodological framework derived from the political
theorist Quentin Skinner and the conceptual historian Reinhart Koselleck to examine ideational and
conceptual tensions and shifts related to the transparency of algorithmic and other automatic
governmental decision-making in Finland. Most of the research material comprises national and
international official documents and semi-structured expert interviews. In Finland, the concepts of
‘algorithmic transparency’ and other ‘transparency of automatic decision-making’ are situated amongst a
complex array of legal, ethical, political, policy-oriented, managerial, and technical semantic fields. From
2016 to 2019 Finland’s Deputy Ombudsman of Parliament and the Constitutional Committee of
Parliament pinpointed issues in algorithmic and other automatic decision-making with the consequence
that at the turn of 2019 and 2020, the Ministry of Justice started moving towards the preparation of
new legislation to resolve these issues. In conclusion and as expected, Finland’s version of the Nordic
tradition of the public sphere with established legal guarantees of public access to government
documents indeed has both important enabling and constraining effects upon resolving the
transparency issues.

2

Keywords: Transparency, algorithmic transparency, semantic fields, public sphere, publicness,
responsibility, democracy, openness

Key points for practitioners:
- Solid democracies have different traditions to maintain a functioning public sphere. Therefore, one
can expect different national approaches to transparency as concerns algorithmic and other
automatic government decision-making.
- Each national tradition may have both enabling and constraining effects to meet the transparency
challenges, which makes it necessary to know in depth both types of effects in each country.
- Comparative studies between countries are needed for the proper understanding of algorithmic
and related transparency and the generalizability of conclusions concerning any individual country
even where the countries in question share important aspects of transparency traditions.

1. Introduction

This article was written in response to a call to a journal issue on ‘algorithmic transparency’, which
the editors understand to combine sufficient access of the decision-making addressees to the
algorithms, and the reasonable intelligibility of the decision outcomes to these addressees (Giest &
Grimmelikhuijsen, 2020, 1). The focus of the article lies in governmental ‘algorithmic and other
automatic decision-making’, and as to algorithms, covers both those with artificial intelligence and
those without. It was also necessary to cover some other relevant aspects of digitalization (see, for
instance, Hofmann, 2019). During the study process it soon became evident that the Finnish Ministry
of Justice had taken preliminary steps possibly to launch the preparation of new legislation that would
resolve the outstanding issues with the transparency of algorithmic and other automatic decision-

3
making. This study by and large shares the empirical framing and focusing of the legislation preparation
project.
It is our choice to examine transparency in governmental algorithmic and other automatic decisionmaking, putting the focus on ideational and conceptual tensions and shifts (for an example of a
suggested analogous although not identical approach, see Dear & Jasanoff, 2010). Our choices also led
to selecting as our most general theoretical and methodological starting points the work of the two
foremost researchers of ideational and conceptual shifts, namely the British political theorist Quentin
Skinner (see, for instance, Skinner, 2002), and the German theoretically oriented historian Reinhart
Koselleck (see, for instance, Koselleck, 2004). We ask the following research question:

What ideational and conceptual tensions and shifts characterize the transparency of algorithmic and other automatic
governmental decision-making in Finland’s version of the Nordic model of the public sphere and its publicness?

In this article we develop the main argument that boils down to our conclusions on Finland’s
version of the Nordic tradition of the public sphere with legally guaranteed public access to
government documents. This tradition has both enabling and constraining effects upon resolving the
transparency issues of algorithmic and other automatic decision-making. On the enabling side, the
tradition offers a kind of a roadmap. According to this roadmap, (1) algorithms and other rules of
automatic decision-making can be understood in analogous terms as traditional public governmental
documents; (2) a responsible individual civil servant has to be found behind each decision made in the
name of the government; (3) hearings of the addressees are obligatory before given types of
government decisions are made; and (4) the grounds of the decisions have to be explained to the
addressees within the limits of real possibilities. However, in some respects this roadmap works less
well in the service of policymakers. It constrains, for example, neoliberal, new public management and
other economy-, efficiency- and effectiveness-oriented rationalization in government. It also limits the

4
possibility of deploying artificial intelligence and other information technologies in government
decision-making.

2. A theoretical approach to ideational and conceptual shifts and tensions

Theoretically and methodologically, the general framework of this article is derived from the work
of Quentin Skinner and Reinhart Koselleck with the aim of grasping ideational and conceptual tensions
and shifts related to the transparency of algorithmic and other automatic decision-making in
government. Skinner has suggested that shifts in the prevalence and influence of ideas and concepts
occur through the mediation of performatives, meaning acts that language users carry out in or by means
of language in specific contexts while trying to accomplish their ends (Skinner 2002, 103-127). In such
performative activity the actors may either win, lose, or preserve shares of political or other power
(Palonen 2004, 163-173). Moreover, according to Skinner, the actors may more or less successfully use
rhetorical devices to ratchet up the popularity and acceptance of their favored ideas and concepts, and
to ratchet down the value of ideas and concepts they oppose (Skinner 2002, 145-157).
Koselleck has emphasized the proliferation of semantic fields within which either different concepts
find their place, or within which concepts spontaneously or after semantic struggles receive meanings
which differ from those that these concepts have in other fields (Koselleck 2004, 75-92). Koselleck has
separated a ‘horizon of expectations’ (Erwartungshorizont) and a ‘space of experience’ (Erfahrungsraum),
suggesting that if gaps widen between the horizon and the space, conceptual change becomes likely and
quite new concepts or concepts originating from elsewhere possibly fill these gaps (Koselleck, 2004,
255-275; Palonen 2004, 263-264). Koselleck has also paid attention to what he calls counter-concepts,
and has suggested that many counter-concepts may be asymmetrical rather than symmetrical. This
means that the juxtaposition between the two types of concepts is partial rather than complete, which
indicates that further gaps open up in semantic fields and may possibly be filled (Koselleck 2004, 155192).

5

3. Methodology

Because this article relies theoretically upon the work of Skinner and Koselleck, in its methodology
the article represents interpretive approaches with their origins in the human sciences rather than using
any of the many more recently evolved qualitative methods. We could not envisage a better way to
demarcate our research material than to accept the empirical framing of the Finnish Ministry of Justice
pre-preparation of new legislation on the transparency of algorithmic and other automatic
governmental decision-making, especially as this pre-preparation coincided with our study period.
Our data acquisition procedures had characteristics of ‘data triangulation’ with reliance upon not
only one but two principal types of research material (Natow, 2020) supplementing each other (Fusch
& Ness, 2015). One main part of the research material was composed of documents, including those of
the EU and the Council of Europe, Finland’s Parliament, ministries, and agencies. The other main part
was acquired by means of twelve semi-structured interviews carried out from April to June, 2020
(Appendix).
Our decisions on the people to interview built upon the available documentation indicating
individuals who are knowledgeable in our topic of examination. To a minor extent we were also
snowballing from one interviewee to another by asking about possible further interviewees. Moreover,
we included among the interviewees two researchers who were independent of the government as well
as a representative of a civil society organization in the domain of data activism. The interviewees
comprised three civil servants of legal overseer organizations; two civil servants of policy and legal
preparation in key coordinating ministries; four civil servants in the foremost government agencies in
which issues of the transparency of algorithmic or other automatic decision-making had arisen; two
independent academic researchers; and one representative of a civil society organization. We prepared a
semi-structured interview question sheet with prompts concerning five themes: (1) the background of
the interviewee; (2) the interviewee’s experiences of promising and problematic cases of transparency in

6
algorithmic or other automatic decision-making; (3) the interviewee’s assessment of the fit of
algorithmic and other automatic decision-making to Finland’s Nordic traditions of the public sphere;
(4) the interviewee’s points for and against algorithmic and other automatic decision-making; and (5)
the interviewee’s opinions on increasing, stabilizing or decreasing algorithmic and other automatic
decision-making. The research team worked under its promise to each interviewee that his or her
anonymity would be protected, meaning that no interviewee is connected to any specific answers
received (Lancaster, 2017).

4. A general empirical consideration on the transparency of algorithmic and other automatic
governmental decision-making in Finland

Finland’s version of the Nordic tradition of the public sphere emphasizes citizen access to
documents prepared or otherwise held by public authorities (viranomaisten asiakirjat), and maintaining the
respective ‘public sphere’ (in Finnish, julkisuus, literally ‘publicness’ resembling the German
Öffentlichkeit). The history of this tradition extends from Sweden’s early legislation in 1766 during a
period that Finland was still part of Sweden (Carlsson & Goldberg, 2017). Finland’s concepts of the
public sphere have long-time counter-concepts (on this notion, see Koselleck 2004, 165-192) that tend
to be asymmetric (which is Koselleck’s staple case), such as the following counter-concepts to ‘public’
(julkinen): ‘secret’ (salainen), ‘confidential’ (luottamuksellinen), ‘not yet public’ (ei vielä julkinen), ‘private’
(yksityinen), and ‘proprietary’ (yksityisomisteinen, ‘under private ownership’). Equally as in other solid
democracies (Hölscher, 1978), in Finland a carefully delineated and well-functioning public sphere
comprises the rule, and declaring government dealings secret or postponing their publicness remain
exceptions.
Finland has gone through a particularly active period in elaborating its public sphere after the
country joined the European Union and increasingly embraced global markets (Erkkilä, 2012). In
political and policy language in Finland but not at least thus far in texts of legal norms actually passed,

7
the newer developments have supplemented the long-established legal concepts of ‘official documents’
and the ‘public sphere’ with such new concepts as ‘transparency’ (läpinäkyvyys or transparenssi in Finnish),
‘openness’ (avoimuus) or ‘accountability’ (tilivelvollisuus; official legal language only knows the concept of
vastuu, ‘responsibility’). Evidence of the absence of the newer concepts from texts of law can be
acquired from Finland’s public legislation database (Finlex, 2020a). The unofficial English translation of
julkisuus as ‘openness’ rather than ‘publicness’ at the Finnish Ministry of Justice (Finlex, 2020b) has
most probably come out by chance. In the present circumstances researchers examining the
transparency of algorithmic and other automatic decision-making in Finland’s government have to gain
a sufficient mastery over several different semantic fields in Koselleck’s sense (Koselleck, 2004, 75-92).
These include the semantic field of the language of texts of law, and the fields of politics, policymaking, management, business, artificial intelligence, and others. Further, in Koselleck’s terms
(Koselleck, 2004, 255-275), the rise of new concepts thus far unknown in texts of law actually passed in
the Finnish language – including ‘transparency’, ‘openness’ and ‘accountability’ – suggests gaps between
horizons of expectation and spaces of experience. This is evidenced by non-legal concepts flowing in
to fill conceptual gaps in Finland’s political and policy-making practice and also in generally accessible
daily and other media contexts. Next, using Skinner’s terms, one can pinpoint successful actors using
newer non-legal concepts and ratcheting up the popularity of these concepts with the results that these
actors have won power shares, although not as strong shares as to make their favored concepts enter
texts of law at least thus far (Skinner 2002, 145-157).
How may concepts become rooted in some semantic fields rather than others, and how may
resilient concepts end up being used for new objects rather new concepts being introduced for the new
objects? Concerning the rooting aspect, evidence is available that such concepts, although unknown in
texts of legal norms actually passed in the Finnish language, as ‘transparency’, ‘accountability’,
‘openness’ and also ‘governance’ and ‘good governance’ may certainly proliferate in certain semantic
fields. For instance, it is not ruled out that these concepts are used in texts of legal policy-making
preceding the ultimate formulation of texts of legal norms (Ananny & Crawford, 2018). It can also be

8
seen as possible that such concepts as those indicated find use in the semantic field of the promotion
of democratic deliberation (Schmidt & Wood, 2019; König & Wenzelburger, 2020). However, the
concepts may also find their way into such semantic fields as those of the globalization of commercial
markets and business companies, governmental neo-liberal governance, and public and general
management and various technical expertise domains (Blomgren & Sahlin, 2007; Erkkilä, 2012; Peters
et al. 2012). One can also envisage that the concept of ‘transparency’ of algorithmic and other
automatic governmental decision-making may be situated in one or more semantic fields at the same
time (for the notion, see Koselleck 2004, 75-92). Such fields may include, for instance, the field of legal
policy-making, the field of ethical concepts, the field of democratic deliberation, the field of proprietary
rights, and, last but not least, the field of the technical and professional facilitation of mass decisionmaking by means of artificial intelligence and other means (Koivisto, 2016; Wachter et al., 2017a;
Wachter et al., 2017b; Mittelstadt et al,. 2016). For the latter aspect on the possible resilience of
concepts one can envisage such possibilities as those of long-established legal concepts the numbers
and types of their referents while new phenomena appear (Larsson, 2013).

5. The empirical issues of the transparency of algorithmic and other automatic decisionmaking in the national government in Finland

5.1. Reception of Council of Europe and European Union concepts related to algorithmic transparency in Finland

Finland’s membership in the Council of Europe and the European Union make conceptualizations
evolved in the semantic fields of these two institutions relevant in Finland as concerns algorithmic
transparency and related topics. Despite the fact that the Council of Europe lacks formal powers in
respect to its members, it is relevant that it has formulated a European Charter on Artificial Intelligence
(Council of Europe 2018a; 2018b; 2019). It is also notable that Finland’s foremost legal overseer, the

9
Chancellor of Justice, has made an analogous public statement for human-centric and fair artificial
intelligence that should be used with due observance of the rule of law (Chancellor of Justice, 2019).
The European Union and the official Finnish legal and other regulative concepts are intertwined in
complex ways. While EU regulations become binding towards the members states at their passing, such
as the General Data Protection Regulation (GDPR) did in 2018 (GDPR, 2016; von der Leyen 2019, 9;
European Commission, 2019c, 4, 13, 17), EU directives may allow leeway to the member states in their
national transposition of the directives. Moreover, intricate interactions prevail between non-binding
EU proclamations, policies and aims and the member states.
While it is useful to give references to important EU statements (European Commission 2018a, b,
2019a-d, 2020a, b, European Council 2018), for our study a key point is the European Commission’s
admission that despite the GDPR and other binding and softer EU norms a unitary EU framework
concerning artificial intelligence and related themes including algorithmic transparency has been lacking
thus far (European Commission, 2020b, 10). The Commission proposals to introduce a centralized,
hierarchical – and hard-to-implement – approach to the mandatory testing and certification of
algorithms and data for artificial intelligence applications (European Commission, 2020b, 23; 2019d;
2020a) have not led to legislation and implementation, either. Therefore Finland’s government has
considerably free hands in defining or revising policies, or in passing or amending legislation to fix
issues of algorithmic transparency and related issues.

5.2. Algorithmic and other automatic decision-making in policies, programs, reports, and government agency statements

In its December 2018 report to Parliament on Information Policy and Artificial Intelligence the
government of Finland stressed the importance of the proper use of AI systems, the transparency of
algorithms and related devices, the accomplishment of workable regulatory mechanisms, and
international agreements on algorithmic transparency (MF, 2018). In a round of opinions requested by
the Ministry concerning its report, numerous stakeholders agreed on the importance of algorithmic

10
transparency, which some stakeholders connected with the concept of ‘open licensing’ with the implicit
asymmetric counter-concept of ‘proprietary licensing’ (on counter-concepts, see Koselleck 2004, 155192). There were also other stakeholders who inserted this transparency into semantic fields of ethics,
and still others who put the transparency in connection with the concept of the ‘privacy’ of individual
citizens.
There have been projects, many of which have been commissioned or organized by the Finnish
government alone or together with partners, with attention to issues of algorithmic transparency. The
proposed solutions have ranged from introducing assurance practices for the intelligibility of AI
algorithms to people (MF, 2019, p. 23); to establishing the systematic ex ante and ex post impact
assessment of government AI (VN TEAS, 2019a); to elaborating frameworks to assess the ethics and
acceptability of government AI (VN TEAS, 2019b); and to elaborating rules to communicate to the
citizens on AI in government (Espoo, 2020). Further projects have been under way, such as on ethical
AI for the governance of society (Etairos, 2020), or, quite explicitly, algorithmic transparency in legal
decision-making (UH, 2020).
Independent measures by government agencies can also mentioned. Finland’s Tax Administration
has published its ethical AI guidelines (FNTA, 2020); Finland’s Social Security Institution has made
public the sampling code it used in its capacity as the implementing agency of the Finnish national basic
income experiment (SSIF, 2016); and the Data Protection Ombudsman has commented on automatic
decision-making with or without profiling humans, whether taking place in the commercial, the private
non-profit, or the public sector (DAPO, 2020).

5.3. Four key cases with issues in algorithmic and other automatic decision-making in Finland’s government, 2016 to
2019

From 2016 to 2019 four cases of transparency issues in algorithmic and other automatic decision
making in Finland’s government have become crucial, received precedent value, and have come to

11
comprise an important part of the basis for the 2019 start of the Ministry of Justice pre-preparation of
new legislation on transparency. The first issue had to do with Finland’s basic income experiment (CC,
2016). The experiment presupposed a random sample of 2 000 people who would be offered the
experimental basic income. The Constitutional Committee of Parliament requested new legislation to
be passed on the fundamentals of the sampling and on the details of publishing the program code. The
committee returned to the basic income experiment its report on another proposal for new legislation
(CC, 2018a). It insisted that whenever legislation is passed on publishing a program code, the code type
should be specified given that while the source code (in a common computer language) is intelligible to
the expert, the object code (in a computer-specific language after the compilation of the program written
in a source code) may be opaque for all others than its authors.
Another issue arose when the Constitutional Committee was considering a government proposal for
legislation on processing airline passenger registry data (CC, 2018b). The committee referred to the
Finnish Constitution, Art. 12 para. 2 on the public character of documents held by public authorities,
and the Constitution Art. 21 para. 2: ‘Provisions concerning the publicness of proceedings, the right to
be heard, the right to receive a reasoned decision and the right of appeal, as well as the other guarantees
of a fair trial and good governance shall be laid down by an Act’ (Finlex 2020c). The Committee
concluded that the specialized standing parliamentary committee considering the proposal should
further acknowledge the relationship of the proposed algorithms to current legislation on the public
character of the dealings of government authorities (Finlex, 2020b) and also ensure that the need for
new legislation be investigated.
In 2018 and 2019, the Constitutional Committee of Parliament passed two opinions on government
proposals for legislation on immigration governance (CC, 2018a, 2019). In Skinner’s terms (Skinner
2002, 145-157) the committee effectively ratcheted up the urgency of new legislation, and in
Koselleck’s terms argued that the gap between a given ‘horizon of expectations’ and the respective
‘space of experience’ had become unacceptably wide (Koselleck 2004, 255-275). The Constitutional
Committee also drew the government’s attention to issues of automatic decision-making that were not

12
covered by valid general legislation (CC, 2018a), indicating that the absence of legislation ran into
conflict with Art. 2 para. 3 of the Finnish Constitution: ‘The exercise of public power shall be based on
an Act. In all public activity, the laws shall be strictly observed’ (Finlex, 2020c; Interview, 2020). In the
other, 2019 case, the committee concluded that on the request of an applicant, the Immigration Service
should reveal the algorithm behind the decision on a work permit or its extension (CC, 2019). The
Committee underlined that one must always find an individual civil servant who has made the decision
and is responsible for it, and that in the absence of such identification, the Immigration Service’s plans
to automatize its decision-making gave rise to further issues.
On 12 September 2019 the government submitted a proposal to Parliament for new legislation on
person-level data in the Immigration Administration (Government, 2019). According to an interview,
the processing of the proposal was stopped and articles on automatic decision-making were removed
(Interview, 2020). According to another interview, this incident left the Immigration Service into limbo
given that its plans and budget had been built assuming expanding automation in its decision-making
(Interview, 2020). The Immigration Service tried to argue its way out, albeit in vain, indicating that it
would only let decisions made with full automation pass if these decisions were positive for the
applicant. Moreover, all decisions requiring human discretion, such as those concerning asylum, would
have been made by identifiable civil servants.
The Immigration Administration was also criticized by the Deputy Parliamentary Ombudsman for
not having provided for the hearings of the addressees in some cases in which the service had not
deemed this to be necessary, contrary to the ex post assessment of the Ombudsman (DPO, 2019a, 3–
4). The Deputy Ombudsman declined to accept that hearings of persons could be compensated for by
such means as publishing decision-making algorithms.
The Deputy Ombudsman has come forward with a strong opinion on automatic decision-making in
Tax Administration (DPO, 2019b). Referring to GDPR, the Deputy Ombudsman has contested the
Tax Administration opinion that its automatic decision-making would not have legal effects upon
taxpayers (GDPR, 2016). After all, in automatic procedures supplements to taxes from 5 or 25 percent

13
may be imposed in certain cases of noncompliance. Moreover, the supervision and collection of taxes
are substantially automated, and have consequences for those liable to pay taxes (Interview, 2020).
The Deputy Ombudsman has also concluded while considering individual cases that the Tax
Administration had failed to report to a given taxpayer that the taxation decision had been made by an
algorithm (DPO, 2019c; 2019d). This highlights combined issues of specifying decision-makers and
decision-making grounds. The Deputy Ombudsman held that the procedures of the Tax
Administration had not satisfied the relevant articles of the Finnish Constitution, and also joined the
2018 Constitutional Committee opinion calling for the preparation, passing and implementation of new
general legislation on all automatic government decision-making (DPO, 2019b). From the viewpoint of
theoretical interpretation (Skinner 2002, 145-157), the Deputy Ombudsman joining the Constitutional
Committee further ratcheted up the urgency of new legislation to resolve the issues that had arisen.
Our interview results suggest ideational and conceptual struggles for power shares (Palonen 2004,
163-174; see also Skinner 2002, 103-127) in Finland’s government on the interpretation of legislation
concerning algorithmic and other automatic decision-making in government. There is also a felt need
for new legislation on the transparency. For example, the Tax Administration had expected that the
civil servants in charge of automated decision-making processes could be seen as legally responsible for
the individual decisions made in these processes. However, the opinion that there is no adequate legal
basis for this conclusion voiced by the Deputy Ombudsman gained the upper hand, indicating that the
dyad of the Constitutional Committee of Parliament and the function of the Parliamentary
Ombudsman acquired a winning power share in this performative struggle (Skinner 2002, 103-127;
Palonen 2004, 163-173). The Immigration Service, in its turn, had expected in the proposal discussed
above that the Service’s Director General could be held responsible for all automatic decisions made in
the service (Government, 2019, p. 52). However, the Constitutional Committee of Parliament
dismissed this proposal (CC, 2019).
According to the interviewee, it would be simple to publish government decision-making rules –
such as those that derive from specific articles of legislation – of simpler types of automatic decision-

14
making (Interview, 2020). At least those from among the machine learning program codes that are not
protected by the proprietary rights of commercial companies could also be easily published. Moreover,
it would not be technically too difficult to publish machine learning parameters those concerning cutoff values that are used to distinguish which cases to examine and which to leave unexamined for such
reasons as their fiscal negligibility. However, in the interviews concerns came up that were the codes
and the cut-off points published, some addressees of government decision-making, such as automated
taxation, might game the system and possible harm system credibility. Yet there were also interviewee
opinions according to which independent and critical external scrutiny of the algorithms might be
possible by such means as stakeholder panels on the condition of strict non-disclosure agreements.
Another proposal that came up in the interviews comprises establishing a general advisory board on
governmental algorithmic governance (Interview, 2020). Another possibility envisaged comprises
increasing supervision, oversight and control by means of allocating new responsibilities to the legal
overseers, importantly the Chancellor of Justice and the function of the Parliamentary Ombudsman
(Interview, 2020). There was also the more free-floating proposal to use intensively the affordances of
algorithms with or without artificial intelligence and other automatic decision-making to tackle the very
same issues to which these technologies gave rise (Interview, 2020).

6. Towards new general legislation on algorithmic and other automatic decision-making in
Finland’s national government since 2019

In 2019 Finland’s Ministry of Justice started considering the preparation of new general legislation
on algorithmic transparency and automatic decision-making in the national government. Importantly
from the point of view of the theoretical approach of this study, the preparation very explicitly used
concepts that have not found their way into the language of laws actually passed in Finland at least thus
far. Using Koselleck’s theoretical notions (Koselleck, 2004, 75-92), at the start of the legal preparation,
concepts of semantic fields other than the field of law texts actually passed were introduced, but it was

15
not clear if these concepts would soon enter the actual legal texts. Further using notions elaborated by
Koselleck, one may propose that the Ministry built on the assumption of a widely enough experienced
mismatch between the ‘space of experience’ and the ‘horizon of expectations’ (Koselleck 2004, 255275). Our study could not advance as far as to find out if the government would share the Ministry’s
experience of this gap, and if parliament would agree at least in all respects with the proposal for new
legislation that the government would possibly present.
A preliminary report prepared by the Ministry of Justice moved in the established semantic field of
texts of law actually passed in the Finnish language in Finland with special reference to the established
core concept of ‘publicity’ (julkisuus) (MJ, 2020a). However, the Ministry also used the concept of
‘transparency’ (läpinäkyvyys) in a few places despite this concept not being present in law texts at least
thus far, whereas the concept of ‘openness’ (avoimuus) was used only once in a marginal passage of the
report. According to the authors of the ministry report, the concept of ‘publicity’ comprises a
characteristic of documents by means of reading which citizens can access government information,
including computer-coded algorithms, as the Ministry sees it. Envisaging nothing but an innovation in
the language of legal preparation, according to the Ministry the concept of ‘transparency’ refers to
characteristics that give clarity to the process so that information becomes automatically available to
those concerned when their case has been decided and a justification has been given for the decision
(MJ, 2020a, 8–10). However, according to an interview, in the very same context of preparing new
legislation ‘transparency’ could alternatively be understood in the stronger sense of the true
intelligibility of decisions, the grounds and the rules used to make these decisions to the addressees of
the decisions (Interview, 2020).
In February 2020 the Ministry of Justice announced the continuation of the pre-preparation with a
project focused on the needs for general administrative legislation on automatic decision-making in
Finland’s national government (MJ, 2020b). The project was given the task to prepare an assessment
memo on the acknowledgement of principles of the legality of public administration, the good
principles of public administration, due process, the principle of the publicity of government activities,

16
and civil servant responsibility. By September 2020, about one hundred opinions had reached the
Ministry from various stakeholders, most of which were government ministries and government
agencies. These opinions became available only during the finalization of this article and therefore
could not be examined.
The purpose of the project the Ministry started in February 2020 has been to lay the foundations for
a legal preparation project proper. Our interviews also revealed the broader context that the current
general act on the publicness of the activities of public authorities of 1999 is seen by some influential
experts to be outdated and in need of reform (Finlex, 2020b). However, elaborating this issue falls
outside the scope of this article.

7. Conclusions and discussion

Our foremost conclusions and our foremost answer to our research question derive from the main
results of our study. Our findings suggest that Finland’s version of the Nordic tradition of the public
sphere has both enabling and constraining properties for resolving issues concerning the transparency
of algorithmic and other automatic decision-making in government, and we have therefore examined
both two types of properties in our study.
In respect to the transparency we have examined, Finland’s tradition of the public sphere offers a
roadmap that enables movement in certain directions but constrains movement in certain other
directions. At the beginning of this article we distinguished four characteristics of this roadmap. (1) It
inserts algorithms and other rules of automatic decision-making in the same semantic field (for the
notion, see Koselleck 2004, 75-92) as traditional written or printed governmental documents or
contents of voice, film or video tapes (Finlex, 2020b). (2) The roadmap includes the norm of the
government having to find an individual civil servant responsible for making any decision made in the
name of the government. (3) The roadmap requires hearings of the addressees before governmental

17
decisions are made in issues concerning which such a requirement has been written in law. (4) The
roadmap calls for the explication of the grounds of governmental decisions for the addressees.
With reference to its last two characteristics – the hearings, and the necessity of explication – it is
our assessment that the roadmap works well in principle as concerns the semantic field of democratic
deliberation, within which hearing those concerned and ensuring that the addressees understand the
grounds of governmental decisions comprise important principles. However, there are respects in
which the roadmap works less well. We find that all four characteristics of the roadmap indicate
tensions with the semantic field of neoliberal policy-making that is frequent in Finland, meaning the
prioritization of commercial markets, favoring economic globalization, and carrying out deregulation.
We also find tensions between the same roadmap characteristics and the semantic field of rationalistic
organization and management doctrines, including those of new public management. Last but not least,
it is our conclusion that the four roadmap characteristics have tensions with the ample implementation
of the semantic field of the affordances of algorithmic and other automatic decision making. We find
that, as confirmed in some of our interviews, the expansion of algorithmic and other governmental
decision-making has both enabling and constraining characteristics in the everyday practices of
government administration. In this respect our results agree with those that Aurelién Buffat has
received (Buffat, 2015).
Our results pinpoint the Finnish Constitutional Committee of Parliament and the function of the
Finnish Parliamentary Ombudsman as the strongest actors in actions carried out in the performative
way in language and by means of language (see Skinner 2002, 103-127) as concerns algorithmic and
other automatic decision-making in government. In comparison to these two actors the other actors
pale. We argue that this constellation with two strong actors and several weaker actors together with a
rigid legal regulation of the public sphere helps explain why, using Quentin Skinner’s terms (Skinner
2002, 145-157), those who have offered new concepts, such as ‘transparency’ (läpinäkyvyys or
transparenssi), ‘openness’ (avoimuus), or ‘accountability’ (tilivelvollisuus) have thus far failed to ratchet up
the popularity and acceptance of these concepts as far as making them enter texts of legal norms

18
actually passed. Indeed, the semantic field of current laws in Finland only includes such concepts as
‘publicness’ (julkisuus) and ‘responsibility’ (vastuu), but none of the three concepts mentioned first. In
Koselleck’s terms (Koselleck 2004, 255-275), the aspirations of the modernizers to close the gap
between their ‘horizon of expectations’ and their actual ‘space of experience’ by means of making new
concepts enter the language of laws passed on the transparency examined have thus far been frustrated.
We further conclude that the semantic field (for the notion, see again Koselleck 2004, 75-92)
organized by means of the 2016 EU GDPR and its national implementation by means of Finland’s
2018 Data Protection Act (GDPR, 2016; for the latter, Finnish act, see Finlex, 2020d) has not sufficed
to offer concepts enabling the resolution of tensions concerning ideas and concepts and mastering
conceptual shifts concerning algorithmic and other automatic decision-making in the Finnish
government. More specifically, one finds well-argued research suggesting that what the authors call for
a ‘right of explanation’ of those concerned is lacking in the GDPR contrary to what may have been
claimed, and that something substantially less is only provided, called a ‘right to be informed’ in a scale
that is limited (Wachter et al., 2017a).
We can also formulate conclusions concerning more technical issues of algorithmic and other
automatic decision making. We argue that these issues become more serious when one moves from
simpler ruled-based decision-making to elementary algorithmic decision-making to such common
varieties of artificial intelligence with algorithms as machine learning and even beyond (Veale et al.,
2018). In this domain, conceptual clarity is a general more than desirable precondition of all
improvement. Moreover, our research results bring into the open such proposals as setting up
stakeholder panels working under strict non-disclosure agreements to critically consider machine
learning program codes and, possibly, also machine learning parameters, and maybe establishing in
addition a general national advisory board on governmental algorithmic governance. The proposal of
using the affordances of algorithms with or without artificial intelligence and other automatic decisionmaking to tackle the very same issues to which these technologies give rise is also worth repeating here.
Last but not least, the possibilities of using other available intellectual technologies are worth

19
mentioning. For instance, to our mind with good reason counterfactual reasoning has been seen to
offer opportunities to deal with the ‘black box’ of decision-making algorithms and rules (Wachter et al.,
2017b).
Our main line of argument indicates seeing Finland’s version of the Nordic tradition of the public
sphere with legally guaranteed public access to government documents to have both enabling and
constraining effects upon resolving transparency issues of algorithmic and other automatic decisionmaking in government. We expect important ideational and conceptual shifts to occur in this tradition
if and only if tensions grow so strong that frustrating experiences of the constraining effects overwhelm
the satisfaction of the expectations because of what the tradition enables. However, having considered
the current circumstances in Finland with two strong actors in interpreting legislation concerning the
transparency issues – the Constitutional Committee of Parliament and the Parliamentary Ombudsman
– and a rigid tradition of a legally guaranteed public sphere, we shy away from expecting imminent
rapid changes. However, despite the legal rigidity we find little reason to see Finland as a particularly
adverse case. It is globally common to use the first tools that come to hand to resolve issues with new
technologies, including using existing rather than new or considerably amended legislation, or using
pre-existing rather than brand new concepts in new or amended articles of law (see, for instance, Stokes
& Bowman, 2012).
We find that to answer questions on the possible generalizability of our results, we should have
available results from comparative studies between Sweden, Denmark, Norway and Finland. In this
way one could gain capacity to take an informed look at the transparency of algorithmic and other
automatic decision-making in the government of each of these countries with Nordic traditions of the
public sphere and its publicness. However, to do so requires the meticulous acknowledgment of each
specific national context, which one cannot suppose to be alike for such reasons as the fully separate
national histories of the four countries ever since the 1905 dissolution of the Swedish-Norwegian
union.

20
References

Ananny, M. & Crawford, K. (2018). Seeing without knowing: Limitations of the ideal of transparency
and its application to algorithmic transparency. New Media & Society, 20(3), 973-989.
Aurora (2020). Lausuntopyyntö kansallisen tekoälyohjelma AuroraAI:n kehittämis- ja toimintasuunnitelmasta
vuosille 2019-2023 (Opinion request concerning the development and operation plan of the national
AI program AuroraAI; includes the AuroraAI program, see below, MF, 2019). Available at:
https://www.lausuntopalvelu.fi/FI/Proposal/ShowAllProposalAnswers?/prooposalIId=6bca7323c799-4956-192e-7965deed5f6
Blomgren, M., & Sahlin, K. (2007). Quests for transparency – Signs of a new institutional era? In T.
Christensen, & P. Laegreid (Eds.), Transcending New Public Management: The Transformation of Public
Sector Reforms (pp. 155-177). Aldershot: Ashgate Publishing.
Buffat, A. (2015), Street-level bureaucracy and e-government. Public Management Review, 17(1),
149-161.
Carlsson, U., Goldberg, D. (Eds.) (2017). The Legacy of Peter Forsskål: 250 Years of Freedom of Expression.
Gothenburg; University of Gothenburg & Nordicom. Available at:
http://www.nordicom.gu.se/en/publikationer/legacy-peterforsskal.
CC (2016). Perustulokokeilua koskeva lainsäädäntö (Legislation on the basic income experiment).
Finland, Parliament, Constitutional Committee, PeVL 51/2016 vp. Available at:
https://www.eduskunta.fi/FI/vaski/Lausunto/Sivut/PeVL_51+2016.aspx
CC (2018a). Maahanmuuttolainsäädäntöä koskeva lausunto (Report on immigration legislation).
Finland, Parliament, Constitutional Committee, PeVL 62/2018 vp. Available at:
https://www.eduskunta.fi/FI/vaski/Lausunto/Sivut/PeVL_62+2018.aspx.
CC (2018b). Lentoliikenteen matkustajarekisteritietojen käyttöä koskevaan lainnsäädäntöön liittyvä
lausunto (Report related to legislation on the use of air traffic passenger registry data). Finland,

21
Parliament, Constitutional Committee, PeVL 29/2018 vp. Available at:
https://www.eduskunta.fi/FI/vaski/Lausunto/Sivut/PeVL_29+2018.aspx
CC (2019). Maahanmuuttoviraston tiedonkäyttöä koskeva lainsäädäntö (Legislation on the use of
information by the Immigration Service). Finland, Parliament, Constitutional Committee, PeVL
7/2019). Available at: https://www.eduskunta.fi/FI/vaski/Lausunto/Sivut/PeVL:7+2918.aspx.
Chancellor of Justice. (2019). Tuomas Pöysti: Towards human-centric and fair AI with the rule of law.
February 27, 2019. Finland: Chancellor of Justice. Available at: https://www.okv.fi/en/tiedotteet-japuheenvuorot/500/tuomas-poysti-towards-human-centric-and-fair-ai-rule-law/.
Council of Europe. (2018a). Study on the human rights dimensions of automated data processing
techniques (in particular algorithms) and possible regulatory implications. DGI(2017)12. Available
at: https://rm.coe.int/algorithms-and-human-rights-en-rev/16807956b5.
Council of Europe. (2018b). CEPEJ European Ethical Charter on the use of Artificial Intelligence (AI) in
Judicial Systems and Their Environment. Council of Europe. Available at:
https://www.coe.int/en/web/cepej/cepej-european-ethical-charter-on-the-use-of-artificialintelligence-ai-in-judicial-systems-and-their-environment
Council of Europe (2019) Conclusions from the conference governing the game changer – Impacts of
artificial intelligence development on human rights, democracy and the rule of law. Available at:
https://rm.coe.int/conclusions-helsinki-conference-26-27-02-2019/168093bfca
DAPO (2020). Automaattinen päätöksenteko ja profilointi (Automatic decision-making and profiling).
Helsinki: Data Protection Ombudsman. Available at: https://tietosuoja.fi/automaattinenpaatoksenteko-profilointi
Dear, P., & Jasanoff, S. (2010). Dismantling boundaries in science and technology studies. Isis 101 (4),
759-774.
DPO (2019a). Maahanmuuttoviraston tiedonkäyttöä koskeva lainsäädäntö, lausunto eduskunnan
perustuslakivaliokunnalle, EOAK/5341/2019 (Legislation on the use of information by the
Immigration Service, statement of the Deputy Parliamentary Ombudsman before the Constitutional

22
Committee of Parliament). Available at:
https://www.eduskunta.fi/FI/vaski/JulkaisuMetatieto/Documents/EDK-2019-AK-262304.pdf
DPO (2019b). Verohallinnon automatisoitu päätöksenteko ei täytä perustuslain vaatimuksia,
EOAK/3379/2018 (The automatic decision-making of the tax administration does not satisfy the
requirements of the Constitution, statement of the Deputy Parliamentary Ombudsman on the
DPO’s own initiative). Available at: https://www.oikeusasiamies.fi/r/fi/ratkaisut//eoar/3379/2018
DPO (2019c). Verohallinnon automatisoitu maksujärjestely, EOAK/2216/2018. (Deputy
Parliamentary Ombudsman’s decision on automated fees in Tax Administration). Available at:
https://www.oikeusasiamies.fi/r/fi/ratkaisut/-/eoar/2216/2018
DPO. (2019d). Verohallinnon päätös laiminlyöntimaksusta, EOAK/2898/2018. (Deputy Parliamentary
Ombudsman’s decision on neglected payments in Tax Administration). Available at:
https://www.oikeusasiamies.fi/r/fi/ratkaisut/-/eoar/2898/2018
Erkkilä, T. (2012). Government Transparency: Impacts and Unintended Consequences. Basingstoke: Palgrave
Macmillan.
Espoo (2020). Yhteiset pelisäännöt työn alla: Kuinka viestiä kansalaisille tekoälyn käytöstä (Common
rules under preparation: How to communicate to the citizens on AI use). Espoo: City of Espoo.
Available at: https://www.espoo.fi/fi-FI/Yhteiset_pelisaannot_tyon_alla_Kuinka_vi(167193)
Etairos (2020). Ethical AI for the governance of the society. Research project, funded by the Finnish
Strategic Research Council. Available at: https://etairos.fi/etairos/
European Commission (2018a). Artificial intelligence for Europe. Available at:
https://ec.europa.eu/digital-single-market/en/news/communication-artificial-intelligence-europe
European Commission (2018b). Coordinated plan on artificial intelligence. Available at:
https://ec.europa.eu/knowledge4policy/publication/coordinated-plan-artificial-intelligencecom2018-795-final_en

23
European Commission (2019a). Building trust in human-centric artificial intelligence. Available at:
https://ec.europa.eu/digital-single-market/en/news/communication-building-trust-human-centricartificial-intelligence
European Commission (2019b). Mission letter: Executive Vice-President-designate for a Europe fit for
the digital age. Available at: https://ec.europa.eu/commission/sites/beta-political/files/missionletter-margrethe-vestager_2019_en.pdf
European Commission (2019c). A Union that strives for more: My agenda for Europe. Political
guidelines for the next European Commission 2019-2024. Available at:
https://ec.europa.eu/commission/sites/beta-political/files/political-guidelines-nextcommission_en.pdf
European Commission (2019d). Digital innovation hubs: Helping companies across the economy make
the most of digital opportunities. Available at: https://ec.europa.eu/digital-singlemarket/en/news/digital-innovation-hubs-helping-companies-across-economy-make-most-digitalopportunities.
European Commission (2020a). Smart specialisation platform: Digital innovation hubs catalogue.
Available at: https://s3platform.jrc.ec.europa.eu/digital-innovation-hubs-catalogue.
European Commission (2020b). White Paper on artificial intelligence: A European approach to
excellence and trust. Available at: https://ec.europa.eu/info/publications/white-paper-artificialintelligence-european-approach-excellence-and-trust_en
European Council. 2018. Declaration of cooperation on artificial intelligence. Available at:
https://ec.europa.eu/jrc/communities/en/community/digitranscope/document/eu-declarationcooperation-artificial-intelligence.
Finlex (1999). Henkilötietolaki (Act on data concerning persons, 22 April 1999, repealed since 1
January 2019. Available at: https://www.finlex.fi/fi/laki/ajantasa/kumotut/1999/19990523

24
Finlex (2020a) Search in Finland’s law database with the keywords ‘publicness’ (julkisuus),
‘responsibility’ (vastuu), ‘accountability’ (tilivelvollisuus), ‘transparency’ (läpinäkyvyys and transparenssi),
and ‘openness’ (avoimuus). The database is available at https://www.finlex.fi
Finlex (2020b). Laki viranomaisten toiminnan julkisuudesta, literally Act on the publicness of the action of
public authorities, in unofficial translation under the title Act on the openness of government
activities (621/1999, amendments until 907/2015 included), a legally non-binding translation made
at the Finnish Ministry of Justice. Available at:
https://www.finlex.fi/en/laki/kaannokset/1999/en19990621_20150907.pdf
Finlex (2020c). The Constitution of Finland, 11 June 1999 (731/1999; amendments up to 817/2018
included), a legally non-binding translation made at the Finnish Ministry of Justice. Available at:
https://www.finlex.fi/fi/laki/kaannokset/1999/en19990731.pdf.
Finlex (2020d). Data protection act (1050/2018), a legally non-binding translation made at the Finnish
Ministry of Justice. Available at: https://www.finlex.fi/en/laki/kaannokset/2018/en20181050.pdf
Flyvbjerg, B. (2006). Five misunderstandings about case-study research. Qualitative Inquiry, 12(2), 219245.
FNTA (2020). Tekoälyn eettiset periaatteet verohallinnossa (The ethical principles of AI in tax
administration). Helsinki: Finnish National Tax Administration. Available at:
https://www.vero.fi/tietoaverohallinnosta/verohallinnon_esittely/toiminta/vastuullisuus/tekoälyn-eettiset-periaatteetverohallinnossa/
Fusch, P.I., & Ness, L.R. 2015. Are we there yet? Data saturation in qualitative research. The Qualitative
Report 20(9), 1408–1416.
GDPR (2016). General Data Protection Regulation. Available at: https://gdpr-info.eu
Giest, S., & Grimmelikhuijsen, S. 2020. Call for papers: Special issue on Algorithmic Transparency in
Government, Information Polity. Available at: https://www.iospress.nl/wpcontent/uploads/2019/11/Special_issue_IP_Algorithmic_transparency_def.pdf

25
Government (2019). Hallituksen esitys eduskunnalle laiksi henkilötietojen käsittelystä
maahanmuuttohallinnossa ja eräiksi siihen liittyviksi laeiksi (Government proposal to Parliament for
an act on processing person-level data in the immigration administration and certain other, related
acts). Available at: https://www.eduskunta.fi/FI/vaski/HallituksenEsitys/Sivut/HE_18+2019.aspx
Hofmann, J., Kersting, N., Ritzi, C., & Schünemann W.J. (Eds.), Politik in der digitalen Gesellschaft: Zentrale
Problemfelder und Forschungsperspektiven. Bielefeld: Transcript Verlag.
Hölscher, L. (1978). Öffentlichkeit. In O. Brunner, W. Conze, & R. Koselleck (Eds.), Geschichtliche
Grundbegriffe, Vol. 4 (pp. 413-467). Stuttgart: Klett-Cotta.
Interview. (2020). Any of the interviews carried out for this article. On the interviewees see the
Appendix.
Koivisto, I. (2016). The anatomy of transparency: The concept and its multifarious implications. EUI
Working Paper MWP 2016/9. Badia Fiesolana: EUI.
König, P.D., & Wenzelburger, G. (2020). Opportunity for renewal of disruptive force? How artificial
intelligence alters democratic politics. Government Information Quarterly 37(3), 1-11.
Koselleck, R. (2004). Futures Past: On the Semantics of Historical Time. New York: Columbia University
Press.
Lancaster, K. (2017). Confidentiality, anonymity and power relations in elite interviewing: conducting
qualitative policy research in a politicised domain. International Journal of Social Research
Methodology 20(1), 93-103.
Larsson, S. (2013). Metaphors, law and digital phenomena: The Swedish pirate bay court case.
International Journal of Law and Information Technology 21(4), 254-379.
MF (2018). Government Report on Information Policy and Artificial Intelligence. Helsinki: Ministry of Finance.
Available at:
https://vm.fi/documents/10623/7768305/VM_Tiepo_selonteko_070219_ENG_WEB.pdf/89b99
a8e-01a3-91e3-6ada-

26
38056451ad3f/VM_Tiepo_selonteko_070219_ENG_WEB.pdf.pdf/VM_Tiepo_selonteko_070219
_ENG_WEB.pdf
MF (2019). AuroraAI – kohti ihmiskeskeistä yhteiskuntaa: Kansallisen tekoälyohjelma Auroran
esiselvityshankkeessa tuotettu kehittämis- ja toimeenpanosuunnitelma 2019-2023 (AuroraAI – Towards a
human-centered society: The development and implementation plan 2019-2023, produced in the
pre-examination project of the national AI program Aurora). Available at:
https://vm.fi/documents/10623/1464506/AuroraAI+kehittämis+ja+toimeenpanosuunnitelma+2019+–+2023.pdf/7c4e746d-e83f-cc83-97d9f4322405255f/AuroraAI+kehittämis-+ja+toimeenpanosuunnitelma+2019+–+2023.pdf
Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms:
Mapping the debate. Big Data & Society 3(2): 1-21.
MJ (2020a). Automaattiseen päätöksentekoon liittyvät yleislainsäädännön sääntelytarpeet (Regulatory
needs in general legislation related to automatic decision-making). Helsinki: Ministry of Justice.
Available at: https://api.hankeikkuna.fi/asiakirjat/ff3444f4-24c9-4ee8-8c9d7bc581c0021a/796dac3f-4527-45c0-a7b8-d63024345ac8/JULKAISU_20200214084153.pdf
MJ (2020b). Automaattista päätöksentekoa koskevan hallinnon yleislainsäädännön valmistelu (Project
to consider general administrative legislation regulating automatic decision-making in government).
Helsinki: Ministry of Justice. Available at:
https://oikeusministerio.fi/hanke?tunnus=OM021:00/2020
Natow, R. (2020). The use of triangulation in qualitative studies employing elite interviews. Qualitative
Research, 20(2), 160–173.
Palonen, K. 2004. Die Enzauberung der Begriffe: Das Umschreiben der politischen Begriffe bei Quentin Skinner and
Reinhart Koselleck. Münster: LIT Verlag.
Peters, M.A. (2012). Managerialism and the neoliberal university: Prospects for new forms of ‘open
management’ in higher education. Contemporary Readings in Law and Social Justice 5(1), 11-26.

27
Schmidt, V.A., & Wood. M. (2019). Conceptualizing throughput legitimacy: Procedural mechanisms of
accountability, transparency, inclusiveness and openness in EU governance. Public Administration
97(4), 727-740.
Skinner, Q. (2002). Visions of Politics. Vol. I. On Method. Cambridge: Cambridge University Press.
SSIF (2016). Perustulokokeilun otantakoodi (The sampling code of the basic income experiment).
Helsinki: Social Security Institution. Available at: https://www.kela.fi/perustulokokeilunotantakoodi
Stokes, E., & Bowman, D.M. (2012). Looking back to the future of regulating new technologies: The
cases of nanotechnologies and synthetic biology. European Journal of Risk Regulation 235(2), 235-241.
UH (2020). Algoritmisen läpinäkyvyyden mahdollisuudet ja rajoitukset (The possibilities and limitations
of algorithmic decision-making). Research project funded by the Academy of Finland. Helsinki:
University of Helsinki. Available at: https://researchportal.helsinki.fi/fi/projects/algoritmisenläpinäkyvyyden-mahdollisuudet-ja-rajoitukset
Veale, M., Van Kleek, M., & Binns, R. (2018). Fairness and accountability design needs for algorithmic
support in high-stakes public sector decision-making. In CHI 2018, April 21–26, 2018, Montréal, QC
(pp 1-14). Montréal: ACM Computer and Human Interaction.
VN TEAS (2019a). Algoritmi päätöksentekijänä? (Algorithm as a decision-maker?). Helsinki: Prime
Minister’s Office. Available at: https://julkaisut.valtioneuvosto.fi/handle/10024/161700
VN TEAS (2019b) Tekoäly viranomaistoiminnassa (AI in public authorities). Helsinki: Prime Minister’s
Office. Available at: https://julkaisut.valtioneuvosto.fi/handle/10024/161345
von der Leyen, U. 2019. Speech in the European Parliament Plenary Session. Available at:
https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_19_4230
Wachter, S., Mittelstadt, B., & Floridi, L. (2017a). Why a right to explanation of automated decisionmaking does not exist in the general data protection regulation. International Data Privacy Law 7(2),
76-99.

28
Wachter, S., Mittelstadt, B., & Floridi, L. (2017b). Counterfactual explanations without opening the black box:
Automated decisions and the GDPR. Oxford: Oxford Internet Institute.

29
Appendix. The interviewees, April to June 2020.
Reijo Aarnio, Finland’s Data Protection Ombudsman
Antti Hahto, Special Advisor for the national AI program Aurora, Finnish Ministry of Finance
Ida Koivisto, Assistant Professor, University of Helsinki; not representing her university but her
expertise
Viivi Lähteenoja, Deputy General Manager, My Data Global Finland
Katariina Lehtola, Chief Specialist, Finnish Immigration Service
Jarkko Levasma, Chief Development and Information Officer, Finnish Tax Administration
Matti Merisalo, Leading Legal Counsel, Finnish Tax Administration
Tuomas Pöysti, Finland’s Chancellor of Justice
Minna Ruckenstein, Associate Professor, University of Helsinki; not representing her university but her
own expertise
Maija Sakslin, Deputy Parliamentary Ombudsman of Finland’s Parliament
Niklas Vainio, Senior Councillor in Legal Affairs, Finnish Ministry of Justice
Jaana Vuorio, Director General, Finnish Immigration Service
.

