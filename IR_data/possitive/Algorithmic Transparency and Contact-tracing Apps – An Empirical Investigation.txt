See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/352539221

Algorithmic Transparency and Contact-tracing Apps – An Empirical
Investigation
Conference Paper · August 2021

CITATIONS

READS

2

351

3 authors:
Tobias Bitzer

Martin Wiener

Technische Universität Dresden

Technische Universität Dresden

3 PUBLICATIONS 2 CITATIONS

126 PUBLICATIONS 1,282 CITATIONS

SEE PROFILE

Stefan Morana
Universität des Saarlandes
88 PUBLICATIONS 1,666 CITATIONS
SEE PROFILE

Some of the authors of this publication are also working on these related projects:

Designing Process Guidance Systems View project

MyDesignProcess View project

All content following this page was uploaded by Martin Wiener on 19 June 2021.
The user has requested enhancement of the downloaded file.

SEE PROFILE

Algorithmic Transparency and Contact-tracing Apps

Algorithmic Transparency and Contacttracing Apps – An Empirical Investigation
Completed Research

Tobias Bitzer
Martin Wiener
TU Dresden
TU Dresden
tobias.bitzer@mailbox.tu-dresden.de
martin.wiener@tu-dresden.de
Stefan Morana
Saarland University
stefan.morana@uni-saarland.de
Abstract
Contact-tracing apps are considered one of the core information technologies to help contain the spread of
the COVID-19 pandemic. However, they need to be adopted broadly to be effective. In this study, we apply
the concept of algorithmic transparency (AT) to contact-tracing apps and hypothesize that users prefer apps
with a high level of disclosure of information about the app's inner workings (referred to as transformation
AT) and that disclosure increases user comprehension and trust. We empirically validate our hypotheses
through an online experiment with 116 participants. We find that the level of transformation AT of a
contact-tracing app is positively related to users' adoption behavior, comprehension, and trust.
Keywords
Algorithmic transparency, contact-tracing apps, mobile app adoption, COVID-19, online experiment.

Introduction
The COVID-19 pandemic has brought an unprecedented disruption of virtually all aspects of human life.
Beyond the serious health impact, with more than 80 million infections and 1.8 million deaths in 2020
(ECDC 2020), the economic repercussions are material: The crisis is estimated to have caused a loss of 4.3%
of global GDP in 2020, and significant future economic losses can be expected, depending on how long the
outbreak continues (The World Bank 2021). Despite recent progress in vaccine development, given the
logistic and financial challenges of providing vaccines for over 8 billion people worldwide, the virus will still
play a substantial role for 2021 and beyond and recovery is expected to take time and be interrupted by
local recurrences (McKinsey 2020). Against this backdrop, the need for complementary solutions is still
substantial; even more so as COVID-19 demonstrated the general vulnerability of humanity to pandemics.
Isolation has been one of the most effective countermeasures but has also led to major disruptions through
lock-downs (The World Bank 2021). To avoid the need for lock-downs until vaccines are widely available
and yet reduce the spread of the virus, contact-tracing apps have been suggested. These smartphone-based
tools use algorithms to calculate individuals' risk of being infected based on past encounters and prompt
users to self-isolate quickly if they have a high risk (Ferretti et al. 2020). Most countries have introduced
such apps on a voluntary basis and hence depend on the collaboration of the population to drive adoption
rates to meaningful levels (Trang et al. 2020). Existing models of technology adoption only partially address
this challenge, as they foreground individual user benefits (e.g., performance expectancy), as opposed to a
mix of individual and societal benefits (i.e., informing of infection risk). Based on this important difference,
we expect additional factors to be relevant for adoption. One core factor could be algorithmic transparency
(AT) (Diakopoulos and Koliska 2017) on the inner workings of contact-tracing apps.
AT refers to "the disclosure of information about algorithms to enable monitoring, checking, criticism, or
intervention by interested parties" (Diakopoulos and Koliska 2017, p. 811) and considers the entire process
of input to, transformation by, and output of an algorithm. Here, transformation algorithmic transparency

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

1

Algorithmic Transparency and Contact-tracing Apps

in terms of disclosure (referred to as "TAT disclosure") is of particular interest as a potential solution to
address the negative view of algorithms as a black box (Castelvecchi 2016). In this regard, initial
investigations indicate significant and complex relationships between transparency, user trust, and user
behavior (Cramer et al. 2008; Kizilcec 2016). Yet, these relationships are still under-researched and, to our
knowledge, the literature does not provide a comprehensive conceptualization of AT. Our study addresses
this gap and empirically analyzes the relationship of TAT disclosure in a contact-tracing app with app
selection, comprehension, and trust. In doing so, we contribute to the literature on technology adoption
and transparency by detailing the concept of AT, as well as by "unblackboxing" the link of TAT disclosure
and adoption behavior, as well as the relationships between TAT disclosure and both comprehension and
trust. In particular our study aims to answer the following research questions:
RQ1:

How does TAT disclosure influence user adoption decisions for a contact-tracing app?

RQ2:

How is TAT disclosure related to user comprehension and trust?

The paper is structured as follows: First, we provide the research background and conceptual foundations
on tracing apps, adoption factors, and AT. After developing our hypotheses, we describe the research design
and report the results. We conclude by discussing theoretical and practical implications and limitations.

Research Background and Conceptual Foundations
Contact-tracing Apps
To counter the spread of COVID-19, case isolation, manual contact-tracing, and quarantining were quickly
deployed. The success of these measures is, however, severely impaired by the fact that an estimated 46%
of infections are caused by pre-symptomatic transmissions, i.e. by individuals who have not yet noticed
their infection (Ferretti et al. 2020). This requires individuals to preventively self-isolate as quickly as
possible after one of their past contacts has been found infected. Therefore, a fast and reliable way of tracing
contacts and informing them to quarantine is critical. Epidemiological models indicate that traditional
manual contact-tracing is consistently too slow to curb the spread of the virus, while contact-tracing apps
with (nearly) real-time notification can help stop the epidemic if used by a sufficient share of the population
(Ferretti et al. 2020). Based on these findings, governments worldwide have rolled out such apps. While
technical details differ, these apps are essentially mobile phone-based logs of close encounters combined
with a database of infected cases and an algorithm determining individuals' risk of being infected based on
the history of their encounters. The app regularly informs individuals about their risk status and prompts
them to take further action, e.g., to quarantine, if they are determined to have a high risk of being infected.

Factors Influencing App Adoption
As indicated above, researchers have stressed that substantial adoption rates are required to make contacttracing apps a truly effective means for addressing the COVID-19 pandemic. Although views on what
constitutes a "substantial rate" differ, a minimum of 60% of a country's population has become an accepted
benchmark (Fraser 2020). Accordingly, the drivers of adoption are of high importance.
The technology acceptance model (TAM) (Davis et al. 1989) and the unified theory of acceptance and use
of technology (UTAUT) (Venkatesh et al. 2003) offer an initial view on these drivers. Yet, they (implicitly)
foreground individual user benefits, e.g., performance expectancy. Meanwhile, initial research on tracing
apps (Trang et al. 2020) emphasizes the dual benefit appeal of these apps for both individuals (self-benefit)
and society. In fact, informing others of a risk to be infected is the apps’ core purpose. Based on this
important difference, we expect additional factors to be relevant for user adoption in this context. However,
to the best of our knowledge, these factors have not yet been studied in depth or validated empirically.
Broadly speaking, the adoption of contact-tracing apps is determined by structural and mental factors. On
the structural side, users require a minimum level of technical infrastructure to use contact-tracing apps.
Most importantly, this means owning a smartphone that supports Bluetooth low energy (BLE). Despite the
growing popularity of smartphones, this significantly reduces the potential user base, as even in developed
countries like Germany ~30% of the population do not own a smartphone (Statista 2021). The remaining
~70% are further reduced by smartphone users whose phone does not support BLE or has insufficient
battery or memory. These adoption barriers are quite substantial, as a (major) additional investment in a

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

2

Algorithmic Transparency and Contact-tracing Apps

(new) smartphone is required to use the app. Hence, the mental factors that hold back those members of
the population who do have the technical means are arguably of even greater importance.
On the mental side, initial research finds benefit appeal (self- or societal), privacy design, and convenience
design to be of significant importance for the adoption of contact-tracing apps (Trang et al. 2020). The
degree to which these factors matter depends strongly on the category that citizens belong to; i.e., whether
they are critical, undecided, or in favor of tracing app use in general. These findings fit into the broader
context of technology adoption research, which finds (adoption) decisions to be driven by users’ perceptions
(e.g., if there is a high or low privacy risk) and underlying attitudes (e.g., importance of privacy).
Uncertainty may lead to many of the negative attitudes and negative cognitive perceptions causing low
adoption: Perceived privacy risks, doubts about effectiveness, and a presumed lack of oversight (Blasimme
and Vayena 2020), to only quote some of the concerns about contact-tracing apps, are ultimately all a result
of uncertainty. Transparency has been described as a facilitator for learning, generating trust, and reducing
uncertainty (Bernstein 2017) and can thus be considered a key adoption factor. This is especially relevant
in the electronic health context, which faces particular challenges due to the privacy and security-sensitive
nature of this context. However, to our knowledge, the potential of transparency to address these challenges
has not yet been explored in detail, which is a key aim of our study.

Algorithmic Transparency
Following the above line of argument, the concept of AT seems well-suited to approach the question how
uncertainty can be reduced through disclosing information. This concept has been coined in the internet
journalism context by Diakopoulos and Koliska (2017) who define AT as "disclosure of information about
algorithms to enable monitoring, checking, criticism, or intervention by interested parties" (p. 811).
Some of the positive effects that make AT important for a broader context are: "[t]rust, credibility,
reputation, and legitimacy" (Diakopoulos and Koliska 2017, p. 821). Despite these benefits, the concept of
AT has largely remained focused on internet journalism and adjacent areas, such as social media (Rader et
al. 2018) and online advertising (Eslami et al. 2018). Two exceptions are Zouave and Marquenie's (2017)
work on AT in criminal intelligence and Lehmann et al.'s (2020) work on AT in forecasting. We thus suggest
an expanded and more nuanced conceptualization of AT grounded in literature as a first step towards
broader application. Based on extant research on transparency and algorithms, AT can be viewed from two
different perspectives. On the one hand, there are different meanings to the term transparency itself; on
the other hand, algorithms can be viewed from a process perspective, which can also be applied to AT.
Research emphasizes the multi-faceted nature of transparency and differentiates four (sub)constructs: (1)
monitoring, which influences performance, knowledge sharing and learning; (2) process visibility, which
shows a workflow or group of activities; (3) surveillance, which represents (managerial) oversight over any
action taken by the individual (employee); and (4) disclosure, which is "the act of making new or previously
secret information known" (Bernstein 2017, p. 220). This last construct (i.e., disclosure) is also used by the
definition of AT and is considered to be generally desirable as it reduces uncertainty and promotes favorable
user reactions, understanding, and trust. As such, our study focuses on AT in terms of disclosure.
From a process perspective, algorithms are defined as "encoded procedures for transforming input data
into a desired output based on specified calculations" (Gillespie 2014, p. 167). Accordingly, AT can concern
the input, transformation, and output of an algorithm. For example, for a contact-tracing app, input AT
provides information on the data used, how it is collected and retained (e.g., displaying Bluetooth keys);
transformation AT (TAT) explains how data is used to calculate a risk assessment (e.g., rules on the
frequency and duration of contacts with infected individuals); and output AT provides information on the
consequences for the user (e.g., a request for COVID-19 testing). In the context of contact-tracing apps the
transformation aspect of AT is of particular interest, as users react particularly sensitive to (in)sufficient
information on transformation and may develop the sensation of the contact-tracing app as a black box
(Castelvecchi 2016). Hence, in this study, we focus on TAT in terms of disclosure (hereafter referred to as
"TAT disclosure") and aim to make a contribution to the question how to address the black box problem of
algorithms that can be used not only for contact-tracing apps, but also for other algorithm-based apps

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

3

Algorithmic Transparency and Contact-tracing Apps

Hypothesis Development
TAT Disclosure & App Selection
Uncertainty is the underlying factor leading to many of the negative attitudes and cognitive perceptions that
adversely affect adoption of contact-tracing apps. Prior research on technology adoption and transparency,
and specifically on disclosure, indicates that increasing TAT disclosure can serve as a means of reducing
uncertainty and thereby have a positive influence on app selection. Through TAT disclosure, users learn
about the algorithm-based inner workings of contact-tracing apps, are reassured about the analytical rigor
of the algorithmic transformation, and see fears about incorrect calculations and data misuse refuted.
This line of reasoning is echoed by extant research which argues for transparency as a way to promote
legitimacy of algorithmic decision making (Goad and Gal 2018). Also, the argument is illustrated by those
countries, which used a highly transparent approach to promote adoption of contact-tracing apps. For
example, Germany subjected its citizens to copious amounts of information provided before, during, and
after the installation of the country’s official contact-tracing app. The approach seems to be justified given
its relative success: 14 million downloads were reached in two weeks, and while growth then levelled off and
only 24 million (~29% of the population) were reached by the end of 2020 (RKI 2020), this figure is still
among the highest in Europe (Bashir 2020). We therefore hypothesize:
Hypothesis 1:

A contact-tracing app’s level of TAT disclosure is positively related to app
selection (i.e., citizens will tend to select the app with greater TAT disclosure).

TAT Disclosure & TAT Comprehension and Trust
Besides disclosure as the most common meaning/sub-construct of transparency, monitoring is also of
particular importance in the context of this study. Describing a contact-tracing app’s correct functioning,
inner workings, and background, monitoring reflects a different, more profound type of transparency: TAT
in terms of comprehension (hereafter referred to as "TAT comprehension"); i.e., the deeper understanding
of the app’s methodology, purpose, and objectives. This dual nature of transparency has also been
highlighted in previous IS research on algorithms: "The primary components of transparency are
accessibility and comprehensibility of information" (Mittelstadt et al. 2016, 6, emphasis in original).
Although authors have cautioned that disclosure does not necessarily increase comprehension due to users’
inability or their unwillingness to engage with the information disclosed (e.g., Burrell 2016), we do believe
this to be the case in the present context of contact-tracing apps: As COVID-19 puts their personal health
at stake, users are willing to deeply engage with potential solutions and are prepared to cognitively process,
and thus comprehend, information about these solutions. We thus propose:
Hypothesis 2:

The level of TAT disclosure is positively related to TAT comprehension.

In addition to TAT comprehension, trust is also closely, and positively, related with TAT disclosure. As TAT
disclosure increases, users recognize that there is ‘nothing to hide’ about the algorithm in question and that
the authors of the algorithm have positive intentions to make relevant information available to interested
parties such that they can apply their own judgement. As a consequence, users’ trust towards the algorithm
and its authors increases, which in return has a positive influence on adoption behavior.
The relationship of transparency and trust has been a subject of multiple studies already; their conflicting
findings indicate a complex, multi-faceted relationship. In a professional context (e.g., demand forecasting),
users appear to show lower acceptance towards more transparent systems (Lehmann et al. 2020). The
opposite seems to be true, however, in non-professional settings, like recommendation agents for music
(Sinha and Swearingen 2002), art (Cramer et al. 2008), and online shopping (Wang and Benbasat 2007),
where transparency increases trust. Finally, one study on grading (i.e., in a semi-professional context) finds
a bell-shaped relationship of trust and transparency (Kizilcec 2016). Various explanations have been offered
for this incongruity, ranging from differing levels of algorithm complexity (Lehmann et al. 2020) to
confounding side-effects of transparency on user experience (Springer and Whittaker, 2019). As contacttracing affects users’ health and the desire for protection outweighs considerations of complexity and user
experience, we consider the findings from non-professional settings most representative and thus suggest:
Hypothesis 3:

The level of TAT disclosure is positively related to trust.

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

4

Algorithmic Transparency and Contact-tracing Apps

Research Method
Setting and Data Collection
To test our hypotheses, we conducted a survey-based online experiment using real-life scenarios in an
adapted vignette technique (Finch 1987). In a within-subject design, we asked participants to imagine
themselves in an app-store and presented them three alternatives of a fictitious tracing app with differing
levels of TAT disclosure. Rather than measuring only ‘intention to install’, we asked participants to indicate
their app selection on a pane that was modeled closely after actual app stores (see Figure 1). This setting
was chosen to mimic an actual app selection decision and thus increase the external validity of the study.

Figure 1. Mock app-store design used in the online experiment (originally in German)
We collected data from German-speaking participants residing in Germany. This was done to keep our data
sample as homogeneous as possible and also to facilitate the comparability of our results with those of prior
studies (Trang et al. 2020). Data was collected in October and November 2020. This period coincided with
the rise of the second wave of COVID-19 infections but was prior to the announcement of substantive
progress in vaccine developments. Thus, the importance of a well-functioning contact-tracing technology
was widely known during our data collection. Arguably, this resulted in a high category need for contacttracing apps and a basic motivation of (potential) users to engage with such apps. Thus, the external validity
(i.e., realism and relevance) of the experiment and its results were substantially increased.
We used the crowdsourcing platform Prolific (Palan and Schitter 2018; Peer et al. 2017) to collect data in
exchange for a nominal payment. Using Prolific enabled us to collect high-quality data from a diverse set of
individuals in a relatively short period of time. A total of 127 completed responses were collected. 11
participants were eliminated because they failed attention tests, leaving the total of valid responses at 116.
To ensure data quality, we used procedural safeguards such as (multiple and varied) attention checks;
explanations on the importance and purpose of the study; detailed control for outliers, excessively short
response times, and straight-line responses; unique response IDs; as well as use of participants with a high
score on Prolific's confidence rating. Participants showed a background that represents reasonably well the
typical user of a tracing app (medium to young age, medium to well educated). The mean age (standard
deviation) was 28.4 (8.5) years and the large majority of participants had a high school (46%) or university
(47%) education (secondary school 8%). Additional demographic factors like gender (66% male, 34%
female), net income, and household size did not indicate any noteworthy deviations.

Experimental Design
On the initial screen, participants were briefed on the context and duration of the experiment and informed
that anonymized results would be published. The participants were then subjected to three descriptions of
the tracing app with different levels of TAT disclosure and asked to select the alternative they wished to
install. The order of the treatments was varied randomly to control for order effects. Following their
decision, participants were asked to provide written reasoning on their choice. They were then presented
their selection and were asked to fill in a survey with the following constructs: TAT disclosure was assessed
using a construct developed for this study that considers the three aspects of how, why, and provision of
Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

5

Algorithmic Transparency and Contact-tracing Apps

additional information (Diakopoulos and Koliska 2017; Wang and Benbasat 2007; Zhao et al. 2019); TAT
comprehension was assessed using the seven-item perceived transparency construct by Wang and Benbasat
(2016); trust was assessed using the three-item construct from Cyr et al. (2009). The survey instrument
also included control variables, which we adopted from previous research on contact-tracing apps by Trang
et al. (2020): general privacy concern (Malhotra et al. 2004), coronavirus anxiety, IT self-efficacy (Heinssen
et al. 1987), gender, age, and education. In addition, we controlled for effort expectancy and performance
expectancy (Venkatesh et al. 2003), personal innovativeness in IT (Agarwal and Prasad 1998), benefit
appeal, and use of the German tracing app, as well as for income and household size. All items (except for
demographics, benefit appeal, and tracing app use) were assessed on seven-point Likert scales (ranging
from "fully disagree" to "fully agree"). An overview of the items is available from the authors upon request.
All questions and descriptions were in German, following the practice of using local languages in an app
store. While the features in the description were in line with the official German app (decentral data storage,
use of BLE), the name ("Pandemie-Warn-App") and visual appearance were fictitious to avoid bias from
the real app. Also, given the uncertainty surrounding the app, we considered it our duty to not increase this
uncertainty through exhibits too close to the original. The visualization of the alternatives was intentionally
identical. The description only differed in the provided level of TAT disclosure; the descriptions of input
and output AT remained unchanged. We manipulated TAT disclosure based on three elements mentioned
in extant literature: How does the app work? (Wang and Benbasat 2007), Why is the approach justified?
(Zhao et al. 2019), and provision of additional information (Diakopoulos and Koliska 2017).

Measurement Model Validation
Before testing our hypotheses on the relationships of TAT disclosure (independent, continuous variable)
with app selection (dependent variable with three categorical outcomes), TAT comprehension (dependent,
continuous variable), and trust (dependent, continuous variable), we validated the measurement model. All
constructs show sufficient internal consistency (Cronbach's α Disc= .85, Cronbach's αComp= .84, Cronbach's
αTrust= .92) and construct reliability (all factor loadings exceed the threshold of .6 from prior research (Trang
et al. 2020), except item 3 of TAT comprehension. Multicollinearity checks show no cause for concern (VIF
~1, Tolerance ~1, homogeneous condition index, differing variance proportions on small eigenvalues).
To ensure the intended effect of our three experimental conditions, we conducted a pre-test (including a
manipulation check) with 226 participants on Prolific. Thereby, we randomly presented one description to
the participants and asked them to indicate the level of TAT disclosure. The results confirm TAT disclosure
is significantly different for the three descriptions (F (2,223) = 126.798, p < .001, ω = .73; MLow = 2.45,
MMedium = 3.46, MHigh = 5.35). Also, the experiment confirms our pretest: TAT disclosure was perceived
significantly different (F (2,113) = 78.097, p < .001, ω = .76; MLow = 3.08, MMedium = 4.07, MHigh = 5.99).

Results
To test H1, which suggests that TAT disclosure is positively related to app selection (low, medium , or high),
we conducted multinomial logistic regression. This technique is suitable to analyze dependent variables
with more than two categorical outcomes. The results indicate a significant positive effect of TAT disclosure
on app selection (R²Nagelkerke = .652; χ² (2) = 84.124, p <.001); i.e., increasing the amount of information
disclosed significantly increases the likelihood of the app being selected. A pairwise comparison reveals that
this applies to both low versus medium TAT levels (b = .885, Wald χ² (1) = 4.376, p = .036) and low versus
high TAT levels (b=3.021, Wald χ² (1) = 25.180, p <.001). The effects of control variables are not significant
(p>.1), with two exceptions: Female participants are 1.3 times more likely to select an app with a medium
TAT disclosure level (p= .011) and users emphasizing self-benefit appeal are 1.7 times more likely to select
an app with a medium TAT disclosure level and 17.2 times more likely to select an app with a low TAT
disclosure level than users emphasizing (self)-societal benefit appeal (p= .019). These results confirm H1.
Next, we used linear regression to test H2 and H3. The test results suggest that TAT disclosure is positively
and significantly related to TAT comprehension (β = .337, p < .001), supporting H2. Of the control variables,
only age has a significant (negative) effect (β = -.212, p = .016). Further, the test results suggest that TAT
disclosure is also positively and significantly related to trust (β = .238, p = .010), supporting H3. Again, the
effect of control variables is not significant, except for age (β = -.193, p = .038) and use of the German
contact-tracing app (β = .179, p = .049). Taken together, the results provide support for all three hypotheses.

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

6

Algorithmic Transparency and Contact-tracing Apps

Discussion
In this study, we conducted an online experiment on contact-tracing apps to advance our understanding of
the relationship between TAT disclosure, on the one hand, and app selection, TAT comprehension, and
trust, on the other hand. Our results offer empirical evidence for a positive relationship between TAT
disclosure and the three dependent variables. In the following, we discuss the implications of these findings.

Theoretical Implications
Our study makes important contributions to IS research through a more nuanced conceptual understanding
of AT, through unblackboxing the link between TAT disclosure and adoption behavior (i.e., app selection),
and through quantifying the relationship of TAT disclosure with TAT comprehension and trust. With these
contributions, we (1) add to the discussion of the relationship between algorithmic and human intelligence
that has been emerging in big data research (Markus 2017), and (2) highlight the importance of AT for
technology adoption, i.e., the effect of AT in contexts of societal benefit appeal. We thus combine two central
fields of IS that have increasingly come into the focus of scholars under emblems such as explainable AI
(Goebel et al. 2018), ethics of algorithms (Ananny 2016), and algorithmic accountability (Martin 2019).
In terms of conceptual contributions, our study results add to research on transparency and its role for
algorithms. The rising number of publications on the risks associated with non-transparent algorithms, e.g.,
on algorithm aversion (Dietvorst et al. 2015, 2018), ethics of algorithms (Ananny 2016), and algorithmic
accountability (Kroll et al. 2017), underscores the growing importance of that field. Nonetheless, AT has to
date lacked a nuanced conceptualization and was mainly used to address user-oriented questions (e.g., in
the media). By distinguishing the procedural steps input, transformation, and output and the constructs
disclosure and comprehension, we add richness to the concept of AT. Also, by applying AT to technology
adoption, our study emphasizes the importance and demonstrates the transferability of this concept.
In addition, we make TAT measurable in experiments by adapting existing scales and combining them with
newly developed ones, thereby setting the stage for future research. Using our methodology we are able to
unblackbox the relationship of TAT disclosure and adoption behavior. Our finding that TAT disclosure is
positively related to app selection highlights the role of TAT disclosure in technology adoption and adds an
important aspect to prior literature (e.g., Venkatesh et al. 2003), which has tended to foreground individual
benefits. With this, we contribute to extant research on app adoption (Xu et al. 2016) and mass acceptance
of apps that may have implications far beyond the context of contact-tracing apps (Trang et al. 2020).
On the empirical side, our finding that TAT disclosure increases TAT comprehension and trust adds to the
discussion on the complex relationships between transparency subconstructs and validates prior findings
that transparency is positively related to trust (Cramer et al. 2008; Wang and Benbasat 2007). This has
significant implications for the context of technology adoption, as extant research finds trust to be a key
facilitator in users’ reliance on technology (Lee and See 2004) that plays a central role in algorithm-enabled
technologies from online recommendation agents (Wang and Benbasat 2016) to autonomous vehicles (Choi
and Ji 2015). However, in parts, our findings also question prior findings of a bell-shaped, or even negative,
relationship of transparency and trust (Kizilcec 2016; Lehmann et al. 2020). One possible explanation for
this ‘contradiction’ might relate to the (non-)experience of information overload (Roetzel 2019): Research
suggests that there is a limit to the amount of information received (i.e., TAT disclosure) that an individual
can make sense of (i.e., TAT comprehension). In our study, even a relatively high level of TAT disclosure
did not cause widespread information overload and hence we observed a linear positive relationship of TAT
disclosure with TAT comprehension and trust. Yet, some qualitative comments provided by experiment
participants point toward this risk. For example, one participant, who opted for a medium level of TAT
disclosure, stated: "[…] Ironically, alternative B [high TAT] was too wordy, I lost patience".

Practical Implications
Our research has important implications for policy makers, health authorities, and application developers
aiming for mass acceptance of contact-tracing apps. First, our results indicate that greater TAT disclosure
does indeed lead to increased app adoption, while typical drivers of technology adoption (e.g., performance
expectancy) showed no effect; that is, in principle, the attempt to promote adoption by disclosing a large
amount of information (e.g., in Germany) seems to be the ‘right’ approach. It is important to note, however,

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

7

Algorithmic Transparency and Contact-tracing Apps

that besides TAT disclosure a range of different antecedents may influence app selection. Thus, in addition
to ensuring TAT disclosure, authorities and developers need to take further adoption-promoting measures.
Second, the positive relationship of TAT disclosure and TAT comprehension suggests that users can acquire
an improved understanding of algorithm-based technology when more information is offered. An increase
in TAT disclosure should therefore reduce users’ uncertainty, increase their understanding, and enable
them to make better use of the contact-tracing app. This finding, however, should be treated with some
caution, as there might be an inflection point where the relationship of TAT disclosure and TAT
comprehension becomes negative. Practitioners should determine this inflection point through careful
probing with (test) users such that the ‘right’ level of TAT disclosure can be selected.
Third, our findings on AT have general implications for the providers of algorithm-based technologies and
for the (critical) observers of these technologies. Most importantly, blanket calls for AT as a panacea for the
practical and ethical challenges of algorithms seemingly fall short of the matter's inherent complexity.
Providers should thus closely study the respective technology and user context and design a differentiated
AT approach that answers two key questions: "where in the process (input, transformation output) is AT
most critical for the user?" and "what dimension(s) of AT (disclosure, comprehension) are most critical?".
Based on the answers to these questions (and the overarching objectives), it may be possible to determine
an ‘optimal’ degree of AT. For example, providers of mobile apps that require regular user interaction to
obtain revenues (e.g., in-app purchases) may require both a high level of disclosure (to drive adoption) and
comprehension (to drive future use). Meanwhile, providers of a classification algorithm that requires a onetime user opt-in may want to concentrate on disclosure. In both cases, in-depth user (pre-)testing should
be conducted to confirm that TAT disclosure levels are perceived as desired and yield the expected results.

Limitations and Avenues for Future Research
The results of our study should be interpreted with four key limitations in mind. These limitations also point
toward promising avenues for future research. First, our research focuses on one specific process step and
dimension of AT (TAT disclosure) and does therefore not provide a comprehensive view on all elements.
We deliberately chose this focus since transformation is most intimately associated with the black box
character of the algorithmic process and since disclosure reflects the most common understanding of
transparency. As our results indicate a clear relationship with TAT comprehension, we encourage additional
research on this construct, as well as on input and output AT (e.g., on the comprehension of data sources
for algorithmic decision-making). Second, our research considers a very specific context: the adoption of
contact-tracing apps. Given the current extreme situation of the COVID-19 pandemic with extensive media
coverage, users may possess more knowledge from outside the experiment than in a typical adoption study.
We accepted this limitation given the importance and urgency of investigating this context; still, future
research should be broadened to AT in other contexts, including algorithmic decision-making in business
contexts. Third, we cannot fully exclude the possibility of unexpected side effects of our within-subject
research design. Given that study participants were presented with all three app alternatives, participants
may be more likely to lean toward higher transparency levels. We are therefore currently conducting an
additional between-subject study to explore this possibility. Finally, descriptive statistics indicate that our
sample is leaning towards younger, better educated participants. As such, our sample is in line with typical
demographics of online research platforms (Peer et al. 2017) and the average smartphone user in Germany
(Statista 2020). Even though we have not observed any effects of age on our results, we encourage future
research with other user groups (e.g., the elderly), given the broad societal importance of contact-tracing.

Conclusion
Focusing on TAT disclosure in the context of contact-tracing apps, our study makes several theoretically
and practically relevant findings. Most notably, the study results provide empirical evidence for the positive
relationships between TAT disclosure and app selection, TAT comprehension, and trust. In doing so, our
study contributes to existing literature by deepening and solidifying our conceptual understanding of AT,
as well as by unblackboxing the effects of TAT disclosure. In addition, from a practical perspective, the study
results offer actionable advice on how to maximize user adoption of contact-tracing apps, which can be seen
as one key lever for ‘fighting’ the current COVID-19 pandemic and potential future pandemics.

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

8

Algorithmic Transparency and Contact-tracing Apps

References
Agarwal, R., and Prasad, J. 1998. “A Conceptual and Operational Definition of Personal Innovativeness in
the Domain of Information Technology,” Information Systems Research (9:2), pp. 204-215.
Ananny, M. 2016. “Toward an Ethics of Algorithms,” Science, Technology, & Human Values (41:1), pp.
93-117 (doi: 10.1177/0162243915606523).
Bashir, E. 2020. COVID-19: latest developments on contact tracing apps in Europe. https://www.culleninternational.com/news/2020/11/COVID-19--latest-developments-on-contact-tracing-apps-inEurope.html. Accessed 18 February 2021.
Bernstein, E. S. 2017. “Making Transparency Transparent: The Evolution of Observation in Management
Theory,” Academy of Management Annals (11:1), pp. 217-266 (doi: 10.5465/annals.2014.0076).
Blasimme, A., and Vayena, E. 2020. “What's next for COVID-19 apps? Governance and oversight,” Science
(370:6518), pp. 760-762 (doi: 10.1126/science.abd9006).
Burrell, J. 2016. “How the machine ‘thinks’: Understanding opacity in machine learning algorithms,” Big
Data & Society (3:1) (doi: 10.1177/2053951715622512).
Castelvecchi, D. 2016. “Can we open the black box of AI?” Nature (538:7623), pp. 20-23.
Choi, J. K., and Ji, Y. G. 2015. “Investigating the Importance of Trust on Adopting an Autonomous
Vehicle,” International Journal of Human-Computer Interaction (31:10), pp. 692-702.
Cramer, H., Evers, V., Ramlal, S., van Someren, M., Rutledge, L., Stash, N., Aroyo, L., and Wielinga, B.
2008. “The effects of transparency on trust in and acceptance of a content-based art recommender,”
User Modeling and User-Adapted Interaction (18:5), pp. 455-496 (doi: 10.1007/s11257-008-9051-3).
Cyr, Head, Larios, and Pan 2009. “Exploring Human Images in Website Design: A Multi-Method
Approach,” MIS Quarterly (33:3), p. 539 (doi: 10.2307/20650308).
Davis, F. D., Bagozzi, R. P., and Warshaw, P. R. 1989. “User Acceptance of Computer Technology: A
Comparison of Two Theoretical Models,” Management Science (35:8), pp. 982-1003.
Diakopoulos, N., and Koliska, M. 2017. “Algorithmic Transparency in the News Media,” Digital
Journalism (5:7), pp. 809-828 (doi: 10.1080/21670811.2016.1208053).
Dietvorst, B. J., Simmons, J. P., and Massey, C. 2015. “Algorithm Aversion: People Erroneously Avoid
Algorithms after Seeing Them Err,” Journal of American Psychology: General (144:1), p. 114.
Dietvorst, B. J., Simmons, J. P., and Massey, C. 2018. “Overcoming Algorithm Aversion: People Will Use
Imperfect Algorithms If They Can (Even Slightly) Modify Them,” Management Science (64:3), pp.
1155-1170 (doi: 10.1287/mnsc.2016.2643).
ECDC 2020. COVID-19 situation update worldwide, as of week 52 2020.
https://www.ecdc.europa.eu/en/geographical-distribution-2019-ncov-cases. Accessed 06.01.21.
Eslami, M., Krishna Kumaran, S. R., Sandvig, C., and Karahalios, K. 2018. “Communicating Algorithmic
Process in Online Behavioral Advertising,” in Proceedings of the 2018 Conference on Human Factors
in Computing Systems, R. Mandryk, M. Hancock, M. Perry and A. Cox (eds.), New York, NY, pp. 1-13.
Ferretti, L., Wymant, C., Kendall, M., Zhao, L., Nurtay, A., Abeler-Dörner, L., Parker, M., Bonsall, D., and
Fraser, C. 2020. “Quantifying SARS-CoV-2 transmission suggests epidemic control with digital
contact tracing,” Science (New York, N.Y.) (368:6491) (doi: 10.1126/science.abb6936).
Finch, J. 1987. “The Vignette Technique in Survey Research,” Sociology (21:1), pp. 105-114.
Fraser, C. 2020. Digital contact tracing can slow or even stop coronavirus transmission and ease us out
of lockdown. https://www.research.ox.ac.uk/Article/2020-04-16-digital-contact-tracing-can-slow-oreven-stop-coronavirus-transmission-and-ease-us-out-of-lockdown. Accessed 6 January 2020.
Gillespie, T. 2014. “The relevance of algorithms,” in Media Technologies: Essays on Communication,
Materiality, and Society, T. Gillespie, P. J. Boczkowski and K. A. Foot (eds.), Cambridge: MIT Press,
pp. 167-193.
Goad, D., and Gal, U. 2018. “Understanding the Impact of Transparency on Algorithmic Decision Making
Legitimacy,” in Living with Monsters?: Social Implications of Algorithmic Phenomena, Hybrid
Agency, and the Performativity of Technology, U. Schultze, M. Aanestad, M. Mähring, C. Østerlund
and K. Riemer (eds.), Cham, Switzerland: Springer, pp. 64-79.
Goebel, R., Chander, A., Holzinger, K., Lecue, F., Akata, Z., Stumpf, S., Kieseberg, P., and Holzinger, A.
2018. “Explainable AI: The New 42?” in Machine Learning and Knowledge Extraction, A. Holzinger,
P. Kieseberg, A. M. Tjoa and E. Weippl (eds.), Cham, Switzerland: Springer, pp. 295-303.
Heinssen, R. K., Glass, C. R., and Knight, L. A. 1987. “Assessing computer anxiety: Development and
validation of the Computer Anxiety Rating Scale,” Computers in Human Behavior (3:1), pp. 49-59.

Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

9

Algorithmic Transparency and Contact-tracing Apps

Kizilcec, R. F. 2016. “How much information? Effects of transparency on trust in an algorithmic
interface,” 2016 CHI Conference on Human Factors in Computing Systems, pp. 2390-2395.
Kroll, J. A., Huey, J., Barocas, S., Felten, E. W., Reidenberg, J. R., Robinson, D. G., and Yu, H. 2017.
“Accountable algorithms,” University of Pennsylvania Law Review (165), pp. 633-705.
Lee, J. D., and See, K. A. 2004. “Trust in automation: designing for appropriate reliance,” Human Factors
(46:1), pp. 50-80 (doi: 10.1518/hfes.46.1.50_30392).
Lehmann, C. A., Haubitz, C., Fuegener, A., and Thonemann, U. 2020. “Keep It Mystic? – The Effects of
Algorithm Transparency on the Use of Advice,” in ICIS 2020 Proceedings.
Malhotra, N. K., Sung, S. K., and Agarwal, J. 2004. “Internet Users' Information Privacy Concerns: The
Construct, the Scale, and a Causal Model,” Information Systems Research (15:4), pp. 336-355.
Markus, M. L. 2017. “Datification, Organizational Strategy, and IS Research: What’s the Score?” The
Journal of Strategic Information Systems (26:3), pp. 233-241 (doi: 10.1016/j.jsis.2017.08.003).
Martin, K. 2019. “Ethical Implications and Accountability of Algorithms,” Journal of Business Ethics
(160:4), pp. 835-850 (doi: 10.1007/s10551-018-3921-3).
McKinsey 2020. “The coronavirus effect on global economic sentiment: December 2020,” McKinsey.
Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., and Floridi, L. 2016. “The ethics of algorithms:
Mapping the debate,” Big Data & Society (3:2), 1-21 (doi: 10.1177/2053951716679679).
Palan, S., and Schitter, C. 2018. “Prolific.ac—A subject pool for online experiments,” Journal of
Behavioral and Experimental Finance (17), pp. 22-27 (doi: 10.1016/j.jbef.2017.12.004).
Peer, E., Brandimarte, L., Samat, S., and Acquisti, A. 2017. “Beyond the Turk: Alternative platforms for
crowdsourcing behavioral research,” Journal of Experimental Social Psychology (70), pp. 153-163.
Rader, E., Cotter, K., and Cho, J. 2018. “Explanations as Mechanisms for Supporting Algorithmic
Transparency,” in Proceedings of the 2018 Conference on Human Factors in Computing Systems, R.
Mandryk, M. Hancock, M. Perry and A. Cox (eds.), New York, NY, pp. 1-13.
RKI 2020. Kennzahlen zur Corona-Warn-App.
https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/WarnApp/Archiv_Kennzahlen/
Kennzahlen_18122020.pdf?__blob=publicationFile. Accessed 22 December 2020.
Roetzel, P. G. 2019. “Information overload in the information age: a review of the literature from business
administration, business psychology, and related disciplines with a bibliometric approach and
framework development,” Business Research (12:2), pp. 479-522 (doi: 10.1007/s40685-018-0069-z).
Sinha, R., and Swearingen, K. 2002. “The role of transparency in recommender systems,” in CHI 2002
Extended Abstracts on Human Factors in Computing Systems, L. Terveen (ed.), New York, NY.
Statista 2020. Smartphone users in Germany, by age. https://www.statista.com/statistics/1133174/.
Accessed 14 January 2021.
Statista 2021. Mobile audience reach of leading smartphone apps in the US.
https://www.statista.com/statistics/281605. Accessed 3 April 2021.
The World Bank 2021. “Global Economic Prospects, January 2021,” Washington, D.C.: The World Bank.
Trang, S., Trenz, M., Weiger, W. H., Tarafdar, M., and Cheung, C. M.K. 2020. “One app to trace them all?
Examining app specifications for mass acceptance of contact-tracing apps,” European Journal of
Information Systems (29:4), pp. 1-14 (doi: 10.1080/0960085X.2020.1784046).
Venkatesh, Morris, and Davis 2003. “User Acceptance of Information Technology: Toward a Unified
View,” MIS Quarterly (27:3), p. 425 (doi: 10.2307/30036540).
Wang, W., and Benbasat, I. 2007. “Recommendation Agents for Electronic Commerce: Effects of
Explanation Facilities on Trusting Beliefs,” Journal of Management Information Systems (23:4), pp.
217-246 (doi: 10.2753/MIS0742-1222230410).
Wang, W., and Benbasat, I. 2016. “Empirical Assessment of Alternative Designs for Enhancing Different
Types of Trusting Beliefs in Online Recommendation Agents,” Journal of Management Information
Systems (33:3), pp. 744-775 (doi: 10.1080/07421222.2016.1243949).
Xu, R., Frey, R. M., Fleisch, E., and Ilic, A. 2016. “Understanding the impact of personality traits on
mobile app adoption – Insights from a large-scale field study,” Computers in Human Behavior (62),
pp. 244-256 (doi: 10.1016/j.chb.2016.04.011).
Zhao, R., Benbasat, I., and Cavusoglu, H. 2019. “Do users always want to know more? Investigating the
relationship between system transparency and users' trust in advice-giving systems,” in Proceedings
of the 27th European Conference on Information Systems (ECIS), Stockholm & Uppsala, Sweden.
Zouave, E. T., and Marquenie, T. 2017. “An Inconvenient Truth: Algorithmic Transparency &
Accountability in Criminal Intelligence Profiling,” in 2017 European Intelligence and Security
Informatics Conference (EISIC), Athens, Greece. 11-13 Sep, IEEE, pp. 17-23.
Twenty-Seventh Americas Conference on Information Systems, Montreal, 2021

View publication stats

10

