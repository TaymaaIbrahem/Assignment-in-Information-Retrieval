Explainable Artificial | ntelligence ( XAI )

AA

= ARTIFICIAL ee

 

 

 

_= 7 FY18 FY19 FY20 FY21

David Gunning
DARPA/120
Program Update November 2017

 

Approved for public release: distribution unlimited.
Need for Explainable Al

 

 

 

http://listverse. coms
© 2007-201,7.Listverse Ltd

 

 

 

 

 

http://explainthatstuff.com

 

¢ We are entering a new
age of Al applications

¢ Machine learning is the . Sn

core technology P ~ Security *

 

 

 

 

¢ Machine learning models

 

are opaque, non-intuitive,
and difficult for people to
understand

Mttp://blog:soliant.com/
©2004-2017 Sollanishealth

Medicine

 

 

Military

 

 

EXPLAINABLE ARTIFICIAL INTELLIGENCE

   

 

¢ Why did you do that?
¢ Why not something else?
¢ When do you succeed?

¢ When do you fail?

¢ When can | trust you?

¢ How do | correct an error?

¢ The current generation of Al systems offer tremendous benefits, but their effectiveness will be limited by
the machine’s inability to explain its decisions and actions to users

¢ Explainable Al will be essential if users are to understand, appropriately trust, and effectively manage

this incoming generation of artificially intelligent partners

Approved for public release: distribution unlimited.
XAI In the News AAD

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Ehe New York Eimes Magazine

Can A.l. Be

. Taught to
Explain Itself?
Cliff Kuang
November 21, 2017

MIT THE WALL STREET IOURNL. | ngide DARPA’s Push to
Technology Make Artificial Intelligence

Review Explain Itself
The Dark Secret at Sara Castellanos and Steven

Norton
the Heart of Al
Will Knight August 10, 2017

April 11, 2017
The& Register’ f
Work

FI You better explain
Richard Waters

yourself, mister:
July 11, 2017 INANCIA

   

Intelligent Machines
Are Asked to Explain
How Their Minds

e es
ExecutiveBiz
Charles River Analytics-Led
Team Gets DARPA Contract to §
Support Artificial Intelligence
Program (i
Ramona Adams ®

DARPA's mission to __
make an accountable Al
Dan Robinson

September 29, 2017

      

- Team investigates artificial i June 13, 2017
KSC intelligence, machine learning | Itary
Elon Musk and Mark ~~. in DARPA project FMBENDED SYSTEMS EASTGOMPAN
; Lisa Daigle
Zuckerberg Are Arguing June 14, oe Why The Military Nt

 
  

About Al But They're Corporate America Want Jp
Both Missing the Point To Make Al Explain x=

=
Artur Kiulian = in | Ghosts in the Machine ltself
Christina Couch
July 28, 2017 INOVA\) _— sit u Steven Melendez “™

October 25, 2017
June 22, 2017

Zi COMPUTERWORLD— screxrtiic

How Al detectives are cracking open

  

DARPA’s XAl seeks Oracle quietly "ec \ AMERICAN. the black box of deep learning
explanations from Ex Iainable AD q Demystifying the 5 Paul voosen
autonomous systems P George Nott s Black Box That Is Al Science duly 6, 20

Geotf Fein
November 16, 2017

Ariel Bleicher &
August 9, 2017

RVAAAS

May 5, 2017

  

Approved for public release: distribution unlimited. 3
Deep Learning Neural Networks
Architecture and How They Work EXPLAINABLE ARTIFICIAL INTELLIGENCE

Wan

  

 

 

Deep Learning Neural Network

@ Input Layer

 

@ Hidden Layer

 

 

 

   

Input
(unlabeled image)
Low-level
features to Neurons . , . =
high-level respond to © @® _ ® ») 1s Layer
features

simple shapes

 

Neurons respond
to more complex 2
structures

Neurons canna SS
to highly complex.) (5) @ nth Layer

abstract concepts \
Automatic algorithm
(feature extraction and classification) Cx
i

https://www.xenonstack.com/ . http://fortune.com/
XenonStack © 10% WOLF 90% DOG © 2018 Time Inc.

@ Output Layer

 

 

 

 

Approved for public release: distribution unlimited. 4
What Are We Trying To Do?

 

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Today

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

ZEEE? -o ¢ Why did you do that?
SEeaSee * Why not something else?
aeeeee Learning |, This is a cat * When do you succeed?
(SAN a Process (p = 93) . nen do vou fai? ,
HBsHaeer . en can | trust you”
EDRs * How do | correct an error?
Training Learned Output User with
Data Function a Task
¢ | understand why
se This is a cat: p * | understand why not
New i 6 { fhe «| *Ithas fur, whiskers, * | know when you'll succeed
Learning P and claws. * | know when you'll fail
bi F {: th elt has this feature: y
Process ARR i. i - * | know when to trust you
LLL : ¢ | know why you erred
Training Explainable Explanation User with
Data Model Interface a Task

 

Approved for public release: distribution unlimited.
 

 

 

Challenge Problems

 

 

 

 

 

Learna Explain Use the
model decisions explanation
Data
Analytics leur | inrace
Classification

Learning Task

Multimedia Data

 

 

 

 

Classifies items of
interest in large data set

Explains why/why not
for recommended items

Analyst decides which
items to report, pursue

 

Autonomy

Reinforcement
Learning Task

el OArdiPKatorg
ArduPilot & SITL Simulation

 

 

Explainable
Model

Explanation
Interface

 

 

 

 

 

 

 

 

Learns decision policies
for simulated missions

Explains behavior in an
after-action review

Operator decides which
future tasks to delegate

 

 

Approved for public release: distribution unlimited.

EXPLAINABLE ARTIFICIAL INTELLIGENCE

An analyst is
looking for items of
interest in massive
multimedia data
sets

An operator is
directing
autonomous
systems to
accomplish a
series of missions
Wty Goal: Performance and Explainability

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

¢ XAI will create a suite of machine learning techniques that

¢ Produce more explainable models, while maintaining a high level
of learning performance (e.g., prediction accuracy)

¢ Enable human users to understand, appropriately trust, and
effectively manage the emerging generation of artificially intelligent
partners

Performance vs. Explainability
A

S

c oO @

cS ° @ Tomorrow
O @

© Today

® @

oO. O

oD

< f

Cc

Soe

o

o

— >

 

 

Explainability (notional)

Approved for public release: distribution unlimited. 7
aN Measuring Explanation Effectiveness

 

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Measure of Explanation

Effectiveness

 

User Satisfaction

 

 

Explanation Framework

¢ Clarity of the explanation (user rating)
Task ¢ Utility of the explanation (user rating)
Mental Model

¢ Understanding individual decisions
¢ Understanding the overall model
* Strength/weakness assessment

 

 

Recommendation,
Decision or
Action

 
  
  

 

 

 

 

 

 

 

 

expeainable | Exclanation Decision - ‘What will it do’ prediction
The user * ‘How do | intervene’ prediction

. makes a
XAI System Explanation decision Task Performance
The system takes The system provides based on the * Does the explanation improve the
input from the current = an explanation to the explanation user’s decision, task performance?
task and makes a user that justifies its * Artificial decision tasks introduced to
recommendation, recommendation, diagnose the user’s understanding
decision, or action decision, or action

 

 

 

 

Trust Assessment

 

¢ Appropriate future use and trust

 

Correctability (Extra Credit)

 

¢ Identifying errors
* Correcting errors
* Continuous training

 

 

 

Approved for public release: distribution unlimited.
Yt Performance vs. Explainability

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

  
  
  

  
   
  

   

Learning Techniques (today) Explainability
(notional)
A
Graphical
Models == te
rf Ensemble 20

   
   
 
    

Bayesian
Belief Nets

\

Statistical
Models

 

 

Explainability

Approved for public release: distribution unlimited. 9
Wt Performance vs. Explainability

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

New
Approach

Learning Techniques (today)

  
  
   
 
  

Graphical
Models

Create a suite of
machine learning
techniques that
produce more
explainable models,
while maintaining a
high level of
learning
performance

 

; Ensemble
Bayesian \

Belief Nets

  
   

Explainability
(notional)
4
r@® @ ®@
ES ePpmme Ee ig
r7O O

 

 

 

 

 

sheoagke
bhkk Prep

eo Ee

 

 

 

 

 

 

 

 

Deep Explanation

Modified deep learning
techniques to learn
explainable features

 

 

interpretable Models

Techniques to learn more
structured, interpretable,
causal models

 

 

 

 

    

Model
pes rN

Experiment

 

 

 

 

 

 

 

 

 

Model Induction

Techniques to infer an
explainable model from any
model as a black box

 

 

Approved for public release: distribution unlimited.

10
 

XAI Concept and Technical Approaches DUAL

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

cae aa 4

Fehon cae SLI

 

   

 

New
Learning
Process

  
 
 

 

 

 

Training Data
UC Berkeley

Charles River Analytics
UCLA

Oregon State
PARC

CMU

SRI International
Raytheon BBN
UT Dallas

Texas A&M

Rutgers

Deep Learning

 

Reflexive and Rational

 

Explanation

Fs or Hist

 

Explanation User
Quality Performance
User Satisfaction
User's Mental Better
Model Performance
User
Comprehension
Appropriate r
L_y Trust [PH rvercriat Use]

   
  
    
 

 

 

  

 

 

 

Causal Modeling

Narrative Generation

 

Pattern Theory+

3-Level Explanation

 

Adaptive Programs

Acceptance Testing

 

Cognitive Modeling

Interactive Training

 

Explainable RL (XRL)

XRL Interaction

 

Deep Learning

Show and Tell Explanations

 

Deep Learning

Argumentation and Pedagogy

 

Probabilistic Logic

Decision Diagrams

 

Mimic Learning

Interactive Visualization

 

 

Model Induction

 

Bayesian Teaching

 

 

Approved for public release: distribution unlimited.

IHMC
Psychological Model of
Explanation

11

 
Approaches to Deep Explanation DUAL
(Berkeley, SRI, Raytheon BBN, OSU, CRA, PARC) EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

 

 

 

Attention Mechanisms Modular Networks
(Top-down Caption Saliency > (Neural module networks >)
[Ramanishka et al. CVPR17] [Andreas et al.CVPR16,EMNLP16] [Hu et al. CVPR17]

Caption: A man in a jacket is standing at the slot machine
Q: Can you park here?

man jacket
NO | Prediction
, Neural o
oo module [| at
network », Attention visualization
standing slot machine Me
i) a Decision path

Feature Identification Learn to Explain

  
 

  

 

 

 

 

 

 

 

 
  

) (— Downy Woodpecker Definition: >

This bird has a white breast, black
wings, and a red spot on its head.

| RNN

Generator

 

 

 

    

Image Explanation:

This is a Downy Woodpecker because it
is a black and white bird with a red

Tagger | Seer) \ spot on its crown. yy,

Approved for public release: distribution unlimited. 12

Target network

 

 

 

 

 

 

 

 

 

 

rr
Cap Network Dissection Quantifying Interpretability of DUAL

Dee p Re p r ese n t at O n S ( M | T) EXPLAINABLE ARTIFICIAL INTELLIGENCE

Buildings Furniture
18) billard table

    

   
 

56) building
a Audit trail: for a particular output unit, the
drawing shows the most strongly activated

120) arcade 155) bookcase path
ae ddan, i p 7TYr
Pr ys LITT ” TT nue2cee waquaqquesser SRS eS Pease eee

 

      
 

     
  

   

8) bridge 116) bed LA
| | ge
123), building 38) cabinet

 

 

ee Pd
i |
Indoor objects Interpretation of

 

182) food several units in
pool5 of AlexNet
trained for place
recognition

 

 

c screen

53) staircase

 

 

Approved for public release: distribution unlimited. 13
1 Causal Model Induction (CRA)

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

 

 

     
     

ML Technique

oe Explanatory Concepts
Parameterization

Causal Model Template

Test
Data

 

TRAINING

 

 

Causal Model Induction: Experiment with the learned model (as a grey box) to
learn an explainable, causal, probabilistic programming model

Approved for public release: distribution unlimited. 14
Explanation by Selection of Teaching Examples
( Ru t Q e rs) EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

 

 

 

 

 

 

TRAINING DATA (2 2] a
@AGg2aa| ||o Ale" ,| [ae

brow mouth This face is Angry
lowered nostrils raised
a flared =
aed \@ é because it is similar to these

|@| examples
@ |aBe} “on, is
lips cheekbones 4
thinned/ raised ¢ Pe

pushed EYPLAINABLE

out

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

CLASSI FI CATI ON MODEL and dissimilar to these
c 3) (any
s = 2s

 

 

 

BAYESI AN TEACHING for optimal selection of examples for machine explanation

Approved for public release: distribution unlimited. 15
 

Common Ground Learning and
Explanation (COGLE)
An interactive sensemaking system to explain
the learned performance capabilities of a UAS
flying in an ArduPilot simulation testbed

Wey Autonomy (PARC, OSU)

 

Pp ~ {
: ay

EXPLANATION LAYER

 

  

7 NK oe 5 -
& Re ie \ ‘Explanations for mission
< mance Rre LC I [| performance and for assessing
Interactions b ; .
) ge / skills, risks & coverage.
COGNITIVE LAYER
Cast learned abstractions,
policies & clusters into
/ oe explainable form.
COGLE LEARNING LAYER
| . ZN. Learn policies from the
Common Ground Builder
i . x 7 sensed world.
* Explain ee te
* Train TEST BED LAYER
° Evaluate!
Series 1. Primitives: Navigating with Constraints and Lookahead ........:ssscsese 7

Lesson 1.1: Taking off.
Lesson 1.2: Taking off and Landing.
Lesson 1.3: Reconnaissance Over a Point (3 Months) ......ss:sesn
Lesson 1.4: Looking Ahead to Avoid Crashing into Mountains...
Lesson 1.5: Choosing a Safe Descent Approach fo for Landing
Lesson 1.6: Provisioning a Hiker (6 months) ....

 

 

 

 
 
   
   
 

Series 2. Behaviors: Managing Competing Goals and Foraging...
Lesson 2.1: Provisioning a Hiker in a Box Canyon (opt)...
Lesson 2.2: Taking an Inventory of a Region and Refueling (opt).
Lesson 2.3: Foraging Around a Point for a Hiker (opt)..... asa
Lesson 2.4: Foraging Around a Point with an Interfering Obsta

Series 3. Missions: Harder Missions and Heavy Testing.....
Lesson 3.1: Double Hiker Jeopardy (9 MONtHS) .....sscsscsseseeeen
Lesson 3.2: Bear on the Runway
Lesson 3.3: Auto-Generated Missions with Testing (12 MOMths) ...scssssssssseneeneed 2

 

 

Robotics Curriculum

Deep Adaptive Program

KUAD

EXPLAINABLE ARTIFICIAL INTELLIGENCE

Explanation-I nformed Acceptance Testing
of Deep Adaptive Programs (xACT)
Tools for explaining deep adaptive programs
and discovering best principles for
designing explanation user interfaces

xFSM

 

 

 

Decision Net

= Explanation
Learner

 

 

AdaptiveChoice
strategyChoice(); Saliency
vo Visualizer

 
       
   

Interactive
Naming

 

 

Interface

    
 

Annotation Aware i Visual
Reinforcement Seg Words
Learning :

Game Engine

Approved for public release: distribution unlimited. 16
GD Four Modes of Explanation (Raytheon BBN) UAL

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Analytic (didactic) statements Visualizations
in natural language that describe that directly highlight portions of the
the elements and context that raw data that support a choice and
support a choice allow viewers to form their own

perceptual understanding

Explanation
Modes

 

 

Cases Rejections of alternative choices

that invoke specific examples or (or “common misconceptions” in

stories that support the choice pedagogy) that argue against

less preferred answers based on
analytics, cases, and data

‘ei : J

 

 

 
Way XA Program Structure

 

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Challenge
Problem

Multimedia Data

Autonomy
ArduPilot &
SITL Simulation

TA1:
Explainable
Learners

Teams that provide
prototype systems
with both components
¢ Explainable
Model
¢ Explanation
Interface

2 fics bs
fltk fie

Abb Be bh

 

Experiment

 

Deep
Learning
Teams

Interpretable
Model
Teams

Model
Induction
Teams

Evaluator
Naval Research Laboratory

TA1: Explainable Learners

¢ Multiple TA1 teams will develop prototype explainable learning systems that
include both an explainable model and an explanation interface

TA2: Psychological Model of Explanation

TA2:
Psychological
Model of
Explanation

* Psychological
Theory of
Explanation

* Computational
Model Consulting

Evaluation
Framework

Learning
Performance

Explanation
Effectiveness

Explanation
Measures

¢ User Satisfaction
¢« Mental Model

¢ Task Performance
¢ Trust Assessment
* Correctability

 

¢ At least one TA2 team will summarize current psychological theories of explanation
and develop a computational model of explanation from those theories

Approved for public release: distribution unlimited.

18
GoD Challenge Problem Candidates DUAL

EXPLAINABLE ARTIFICIAL INTELLIGENCE

Analytics Autonomy

Visual Question Answering

Strategy Games

L

STE Lae e182 =e alae ks

 

Activity Recognition Vehicle Control

 

 

Jed SECON Tider Ay
ee || ae 3

 

S meee lil
tit WME PE
laa |i

Household activites § + co =< neon caning = 5 Cleaning windows

hada aaa NC aT Lae

ass eS a 7 7
Yue
Approved for public release: distribution unlimited.

  

 

 

 

 

 

   

 

 

 

19
 

A

i Psychological Model of Explanation (IHMC) )xQ/A\U

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

. XAl
Model of the Explanation
UAL Process and Possible Metrics
XAl
EXPLAINABLE ARTIFICIAL INTELLIGENCE

System

 

 

 

   

 

 

      

 

 

 

 

 

 

 

    

  

         

 

 

receives . revises User’s Mental | enables Better
User > ~T
Model Performance
may initially fi “ by is assessed by is assessed by
‘odes Test of Test of Test of
Criteria ar, | Comprehension Performance
can —l— involves
Trust or | gives way to (mma) enables | Appropriate

     

Mistrust

     

 

 

| Tust J st Use
 

DARPA Schedule and Milestones

KUAD

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Evaluator

TA1

TA2

Meetings

 

 

   

 
    

 

 

 

 

   

 

 

 

  
 
    

 
     

 

 

 

 

 

 

 

 

   

   

   

 

 

 

 

   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

2017 2018 2019 2020 2021
APR | MAY] JUN | JUL | AUG] SEP | OCT | NOV] DEC] JAN | FEB | MAR} APR | MAY] JUN | JUL | AUG] SEP | OCT | NOV] DEC] JAN | FEB | MAR] APR | MAY] JUN | JUL | AUG] SEP | OCT | NOV] DEC] JAN | FEB | MAR] APR | MAY] JUN | JUL | AUG] SEP | OCT | NOV] DEC | JAN | FEB | MAR] APR | MAY
PHASE 1: Technology Demonstrations PHASE 2: Comparative Evaluations
. . Prep for Analyze Analyze ‘acl Analyze Results &
Define Evaluation Framework Prep for Eval 2 Prep for Eval 3 .
Eval1 Results Results Accept Toolkits
Refine & Test Explainable Refine & Test Explainable
Develop & Demonstrate Explainable Models a a Deliver Software
. Learners Learners .
(against proposed problems} . . Toolkits
(against common problems) (against common problems)
LT TTT ?ET tT te ttt tt LTT ttt tt LTT tT TTT [ [Tt |
. . . . Deliver
Summarize Current Psychological Develop Computational Model of Refine & Test Computational
Theories of Explanation Explanation Computational Model .
Model
KickOff Progress Report Tech Demos Eval 1 Results Eval 2 Results Final
May 9-11 Nov 6-8 May 7-9

¢ Technical Area 1 (Explainable Learners) Milestones

Demonstrate the explainable learners against problems proposed by the developers (Phase 1)
Demonstrate the explainable learners against common problems (Phase 2)
Deliver software libraries and toolkits (at the end of Phase 2)

Technical Area 2 (Psychology of Explanation) Milestones

Deliver an interim report on psychological theories (after 6 months during Phase 1)
Deliver a final report on psychological theories (after 12 months, during Phase 1)
Deliver a computational model of explanation (after 24 months, during Phase 2)
Deliver the computational model software (at the end of Phase 2)

Approved for public release: distribution unlimited. 21
EXPLAINABLE ARTIFICIAL INTELLIGENCE

DARPA XAI Developers (TA1)

 

 

Explainable Model Explanation Interface

UC Berkeley Deep Learning Reflexive and Rational
3 Charles River Causal Modeling Narrative Generation
UCLA Pattern Theory+ 3-level Explanation
= Oregon State Adaptive Programs Acceptance Testing
PARC Cognitive Modeling Interactive Training
2 CMU Explainable RL (XRL) XRL Interaction
SRI International Deep Learning Show and Tell Explanation
6 Raytheon BBN Deep Learning Argumentation and Pedagogy
= UT Dallas Probabilistic Logic Decision Diagrams
< Texas A&M Mimic Learning Interactive Visualization
Rutgers Model Induction Bayesian Teaching

Approved for public release: distribution unlimited. 22
Hata Berkeley/BU/U. Amsterdam/Kitware

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Deeply Explainable Artificial | ntelligence

Explainable Model Explanation Interface Challenge Problem

Deep Learning Reflexive & Rational Autonomy

* Explain /mpiicit (latent) * Reflexive explanations ¢ ArduPilot and OpenAl
nodes by training (that arise directly Gym Simulations
additional DL models from the model)

¢ Explain exp/icit nodes ¢ Rational explanations Data Analytics
thru Neural Module (that come from | © Visual QA and
Networks (NMNs) Nalisle) about user’s Multimedia Event QA

elie

 

PI: Trevor Darrell (Berkeley)

Pieter Abbeel (Berkeley) ¢ Dan Klein (Berkeley) ¢ Anthony Hoogs (Kitware)
Tom Griffiths (Berkeley) ¢ John Canny (Berkeley)

Kate Saenko (BU) ¢ Anca Dragan (Berkeley)

Zeynep Akata (U.

Amsterdam)

Approved for public release: distribution unlimited. 23
EXPLAINABLE ARTIFICIAL INTELLIGENCE

3% CRA/U. Mass/Brown

 

CAMEL: Causal Models to Explain Learning

Explainable Model Explanation Interface Challenge Problem

Model | nduction Narrative Generation Autonomy

Causal Models ¢ Interactive visualization ¢ Minecraft, Starcraft
¢ Experiment with the based on the generation ;
learned model (as a of temporal, spatial Data Analytics

grey box) to learn an narratives from the ¢ Pedestrian Detection
explainable, causal, causal, probabilistic (INRIA), Activity
probabilistic models Recognition

programming model (ActivityNet)

 

PI: Brian Ruttenberg (CRA)

Avi Pfeffer (CRA) James Niehaus (CRA)

David Jensen (U. Mass) ¢ Emilie Roth (Roth Cognitive Engineering)
¢ Michael Littman (Brown) ¢ Joe Gorman(CRA)

¢ James Tittle (CRA)

Approved for public release: distribution unlimited. 24
Haya UCLA/OSU/ Michigan State

Learning and Communicating Explainable Representations for
Analytics and Autonomy

Explainable Model Explanation Interface Challenge Problem

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Pattern Theory+ 3-Level Explanation Autonomy

° Integrated ¢ Integrate 3 levels of * Humanoid robot
representation across explanation: behavior and VR

an entropy spectrum: * Concept compositions simulation platform
* Deep Neural Nets * Causal and Data Analytics
¢ Stochastic And-Or- counterfactual ¢ Understanding

Graphs (AOG) reasoning complex multimedia
¢ Predicate Calculus ¢ Utility explanations events

 

¢ PI: Song-Chun Zhu (UCLA)

¢ Ying Nian Wu (UCLA) ¢ Joyce Chai (Michigan State)
¢ Sinisa Todorovic (OSU)

Approved for public release: distribution unlimited. 25
OSU

xACT: Explanation-| nformed Acceptance Testing of Deep

Explainable Model

Adaptive Programs

* Explainable Deep
Adaptive Programs
(xDAPs) — a new
combination of
Adaptive Programs,
Deep Learning and
explainability

¢ PI: Alan Fern (OSU)

Tom Dietterich (OSU)
Fuxin Li (OSU)

Prasad Tadepalli (OSU)
Weng-Keen Wong (OSU)

Adaptive Programs
Explanation Interface

Acceptance Testing

* Provides a visual & NL
explanation interface
for acceptance testing
by test pilots based on
Information Foraging
Theory

¢ Margaret Burnett (OSU)
¢ Martin Erwig (OSU)
¢ Liang Huang (OSU)

Approved for public release: distribution unlimited.

EXPLAINABLE ARTIFICIAL INTELLIGENCE

Challenge Problem

Autonomy

¢ Real-Time Strategy
Games based on
custom designed game
engine designed to
support explanation

¢ Possible use of
Starcraft

 

26
EXPLAINABLE ARTIFICIAL INTELLIGENCE

17.)  PARC/CMU/U. Edinburgh/U. Mich./West Point

 

COGLE: Common Ground Learning and Explanation

Explainable Model Explanation Interface Challenge Problem

Cognitive Model Interactive Training Autonomy

¢ 3-layer architecture: * Interactive visualization * ArduPilot simulation
¢ Learning Layer of states, actions, environment
(DNNs) policies & values * Value of Explanation
* Cognitive Layer ¢ Includes a module for (VoE) framework for
(ACT-R Cog. Model) test pilots to refine and measuring explanation
* Explanation Layer train the system effectiveness
(HCI)

 

* PI: Mark Stefik (PARC)

¢ Honglak Lee (U. Mich.) * Christian Lebiere (CMU) ¢ Michael Youngblood
¢ Subramanian ¢ John Anderson (CMU) (PARC)
Ramamoorthy (U. ¢ Robert Thomson (USMA)
Edinburgh)

Approved for public release: distribution unlimited. 27
Mi) CMU/Stanford Ne

XRL: Explainable Reinforcement Learning for Al Autonomy

Explainable Model Explanation Interface Challenge Problem

XRL Models XRL Interaction Autonomy

Create a new scientific * Interactive Open Al Gym
discipline for Explainable explanations of Autonomy in the

Reinforcement Learning dynamic systems electrical grid
with work on new ¢ Human-machine Mobile service robots
algorithms and interaction to improve Self-improving
representations performance educational software

 

¢ PI: Geoff Gordon (CMU)

¢ Zico Kolter (CMU) ¢ Manuela Veloso (CMU)
¢ Pradeep Ravikumar (CMU) ¢ Emma Brunskill (Stanford)

Approved for public release: distribution unlimited. 28
Wty SRI/U. Toronto/UCSD/U. Guelph

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

DARE: Deep Attention-based Representations for Explanation

Explainable Model Explanation Interface Challenge Problem

Deep Learning Show-and-Tell Data Analytics

¢ Multiple deep learning Explanations Visual Question
techniques: ¢ DNN visualization Answering (VQA) using
¢ Attention-based * Query evidence that Visual Gnome, Flickr30
mechanisms explains DNN decisions MovieQA
* Compositional NMNs ¢ Generate natural
° GANs language justifications

 

PIs: Giedrius Burachas (SRI), Mohamed Amer (SRI)

Shalini Ghosh (SRI) Richard R. Zemel (U. Toronto) ¢ Jurgen Schulze (UCSD)
Avi Ziskind (SRI) Sanja Fidler (U. Toronto)
Michael Wessel (SRI) °¢ David Duvenaud (U. Toronto)

¢ Graham Taylor (U. Guelph)

Approved for public release: distribution unlimited. 29
WEN) Raytheon BBN/GA Tech /UT Austin/MIT

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

EQUAS: Explainable QUestion Answering System

Explainable Model Explanation Interface Challenge Problem

Deep Learning Argumentation Data Analytics

¢ Semantic labelling of Theory ¢ Visual Question
DNN neurons ¢ Comprehensive Answering (VQA),

¢ DNN audit trail strategy based on beginning with images
construction argumentation theory and progressing to

° Gradient-weighted ¢ NL generation video
Class Activation ¢ DNN visualization

Mapping

 

¢ PI: William Ferguson (Raytheon BBN)

¢ Antonio Torralba (MIT) ¢ Devi Parikh (GA Tech)
¢ Ray Mooney (UT Austin) ¢ Dhruv Batra (GA Tech)

Approved for public release: distribution unlimited. 30
NY UT Dallas/UCLA/Texas A&M/IIT-Delhi

Tractable Probabilistic Logic Models: A New, Deep Explainable
Representation

Explainable Model Explanation Interface Challenge Problem

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Probabilistic Logic Probabilistic Data Analytics
Decision Diagrams

¢ Tractable Probabilistic ¢ Infer activities in
Logic Models (TPLMs) * Enables users to multimodal data (video
— an important class of explore and correct and text)
(non-deep learning) the underlying model Using the Wetlab
interpretable models as well as add (biology) and TACoS
background knowledge (cooking) datasets

 

¢ PI: Vibhav Gogate (UT Dallas)

¢ Adnan Darwiche (UCLA) ¢ Eric Ragan (Texas A&M)
¢ Guy Van Den Broeck (UCLA) »¢ Parag Singla (II T-Delhi)
¢ Nicholas Ruozzi (UT Dallas)

Approved for public release: distribution unlimited. 31
DARPA Texas A&M/Wash. State

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Transforming Deep Learning to Harness the I nterpretability of

Shallow Models: An Interactive End-to-End System

Explainable Model Explanation Interface

Mimic Learning Interactive

Develop a mimic Visualization

learning framework * Interactive visualization

that combines deep over multiple views,
learning models for using heat maps & topic

prediction and shallow modeling clusters to
models for show predictive

explanations features

¢ PI: Xia Hu (Texas A&M)

¢ Shuiwang Ji (Wash. State) ¢ Eric Ragan (Texas A&M)

Approved for public release: distribution unlimited.

Challenge Problem

Data Analytics

¢ Multiple tasks using
data from Twitter,
Facebook, ImageNet,
UCI, NIST and Kaggle

¢ Metrics for explanation
effectiveness

 

32
Mate Rutgers AD

Model Explanation by Optimal Selection of Teaching Examples

 

Explainable Model Explanation Interface Challenge Problem

Model I nduction Bayesian Teaching Data Analytics

¢ Select the optimal ¢ Example-based Movie descriptions
training examples to explanation of: Image processing
explain model ¢ the full model Caption data
decisions based on * user-selected sub- Movie events
Bayesian Teaching structure Human motion events
user submitted
examples

 

¢ PI: Patrick Shafto (Rutgers)

¢ Scott Cheng-Hsin Yang (Rutgers)

Approved for public release: distribution unlimited. 33
asta | HMC/MacroCognition/ Michigan Tech

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

Naturalistic Decision Making Foundations of Explainable Al

Literature Review

Naturalistic Theory

¢ Extensive review of
relevant psychological
theories

¢ Extend the theory of
Naturalistic Decision
Making to cover
explanation

Computational Model

Bayesian Framework

¢ Represent reductionist
mental models that
humans develop as
part of the explanatory
process

* Including mental
simulation

¢ PI: Robert R. Hoffman (IHMC)

° Gary Klein
(MacroCognition)

¢ Shane T. Mueller (Michigan
Tech)

¢ William J. Clancey (IHMC)
¢ COL Timothy M. Cullen
(SAASS)

Approved for public release: distribution unlimited.

Model Validation

Experiments

* Conduct interactive
assessment and formal
human experiments

¢ Validate the model

¢ Develop metrics of
explanation
effectiveness

¢ Jordan Litman (IHMC
Psychometrician)

¢ Simon Attfield (Middlesex
University-London)

¢ Peter Pirolli (IHMC)

 

34
1) Naval Research Laboratory

EXPLAINABLE ARTIFICIAL INTELLIGENCE

 

XAI Evaluation

 

 

 

 

Challenge Problems Evaluation Framework Measurement
* Evaluation protocols ®
Analytics * Training environment o|° -
¢ Training data E ° Teena
¢ Simulation 5 | Today -
oO °
environment Oo i
Testing environment =
Autonomy * Subjects ®
* Web infrastructure 7 >
* Baseline systems Explanation Effectiveness

 

 

 

 

PI: David Aha (NRL)

Justin Karneeb (Knexus) ° Mike Pazzani (UC Riverside)
Matt Molineaux (Knexus)
Leslie Smith (NRL)

Approved for public release: distribution unlimited. 35
 

www.darpa.mil

Approved for public release: distribution unlimited.

36
