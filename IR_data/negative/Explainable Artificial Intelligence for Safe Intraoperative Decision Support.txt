Surgical Innovation

Clinical Review & Education

Explainable Artificial Intelligence
for Safe Intraoperative Decision Support

Lauren Gordon, MD, MSc; Teodor Grantcharov, MD, PhD; Frank Rudzicz, PhD

What Is the Innovation?

Intraoperative adverse events are a common and important cause
of surgical morbidity.' Strategies to reduce adverse events and miti-
gate their consequences have traditionally focused on surgical edu-
cation, structured communication, and adverse event manage-
ment. However, until now, little could be done to anticipate these
events in the operating room. Advances in both data capture in the
operating room and explainable artificial intelligence (XAI) tech-
niques to process these data open the way for real-time clinical de-
cision support tools that can help surgical teams anticipate, under-
stand, and prevent intraoperative events.

Ina systematic review, 64% of studies reported improvements
in clinical decisions with automated decision support, especially if
suggestions were provided at the same time as the task.? Machine
learning (ML) techniques can provide this real-time decision sup-
port, estimating risk automatically from patient and intraoperative
data. However, there has been hesitation to adopt ML techniques in
health care* because these systems can have rare catastrophically
incorrect predictions, and high accuracies can be achieved in unex-
pected ways, such as recognizing patterns in the manner of data
recording, rather than in the content of the data themselves.

Explainable artificial intelligence is a collection of algorithms that
improve on traditional ML techniques by providing the evidence be-
hind predictions. For example, while a traditional ML algorithm in
radiology may predict that an image contains evidence of cancer, an
XAl system willindicate what and where that evidence is (eg, 3 cm,
right lower lobe nodule).

In 2018, Lundberg et al? developed an XAI-based warning sys-
tem called Prescience that predicts hypoxemia during surgical pro-
cedures up to 5 minutes before it occurs. This system monitors
vital signs and provides the clinician with a risk score that updates
in real time. It also continuously updates the clinician with reasons
for its predictions, listing risk factors such as vital sign abnormali-
ties and patient comorbidities. This can act like an additional vital
sign, regularly updating information to warn the anesthetist in real
time about upcoming risk.

With XAl, surgeons can receive similar warnings about upcom-
ing intraoperative events to augment their clinical judgement, help-
ing to avoid complications. Our team is currently working in surgi-
cal XAI to use laparoscopic videos to warn surgeons about upcoming
bleeding events in the operating room and explain this risk in terms
of patient and surgical factors. By anticipating and avoiding ad-
verse events, surgical teams may be able to reduce operative times
and improve outcomes for patients.

What Are the Key Advantages Over Existing Approaches?

Currently, risk prediction is done predominantly in the preopera-
tive setting.® Intraoperatively, surgical teams rely almost exclu-

jamasurgery.com

sively on clinical judgement to predict patient risk and physiologic
disturbance. However, many risky situations are unanticipated:
and are managed reactively rather than preventively.?

Machine learning, by making fewer assumptions about param-
eter relationships, can use unstructured data sources such as text,
audio, and video to provide more accurate predictions than tradi-
tional statistical techniques. However, the accuracy of ML often
comes at the cost of explainability.

Predictions by ML systems have traditionally been difficult to
interpret: the prediction itself is output to users, but the logic un-
derlying that output is not. New work in XAI opens this black box.
Both algorithm-specific and broadly applicable techniques have been
developed to understand how different types of ML models make
their predictions. For example, each risk factor can be consecu-
tively removed to see how this absence affects the prediction. This
essentially produces a relative risk calculation for each factor. By pre-
senting both a real-time risk estimate and its underlying reasoning,
XAI willallow surgeons to take advantage of complex ML-based pre-
diction without losing the interpretability of logistical regression.

How Will This Affect Clinical Care?

Explainable artificial intelligence could be a powerful tool for intra-
operative decision support, used in warning systems to help clini-
cians predict and avoid adverse events that may lead to complica-
tions. The overall risk estimates and contributing factors could be
shown to the surgeon and updated with vital signs.

Using multiple data sources, including audio and video, XAI-
based decision support may be able to provide these interpretable
early warnings about intraoperative events suchas bleeding and flag
action points such as hypothermia, aberrant anatomy, or tool use
that may be linked to the risk. With these factors provided to surgi-
cal teams in the operating room, XAl can significantly augment
clinician judgement.

Clinicians’ attention can then be drawn to warnings and they can
decide whether to take action based on the XAl-provided explana-
tions: to modify risk factors by, for instance, reviewing imaging, chang-
ing the surgical approach, or requesting different instruments.

Is There Evidence Supporting the Benefits

of the Innovation?

Explainable artificial intelligence, as an emerging technology, has yet

to be broadly implemented to provide decision support for sur-

geons. Prescience, a clinical decision support tool for anesthesiolo-

gists, is one example of how XAI might be used intraoperatively.
When provided with decision support from Prescience, anes-

thesiologists predicted hypoxemia with greater accuracy than by

clinical judgement alone (area under the curve, 0.78 vs 0.66;

P< .00)1). The authors estimate that anesthesiologists predict ap-

JAMA Surgery Published online September 11,2019

© 2019 American Medical Association. All rights reserved.

Downloaded From: https://jamanetwork.com/ by a University of Toronto Libraries User on 10/31/2019

El
E2

Clinical Review & Education Surgical Innovation

proximately 15% of intraoperative events and may be able to pre-
dict 30% when using Prescience. One-fifth of the time, hypoxemic
risk was potentially related to medications provided intraoperative-
ly-a highly modifiable risk factor.

Our team is currently working to developing applications of XAI
in surgical practice: identifying intraoperative events like bleeding
using patient, team, and surgeon factors. We aim to show that if
surgeons are warned about bleeding risk and associated risk fac-
tors, bleeding events can potentially be avoided.

What Are the Barriers to Implementing

This Innovation More Broadly?

Barriers to implementing XAI include data collection, technical de-
velopment, and clinician trust. Explainable artificial intelligence re-
quires a large volume of high-quality data for algorithm training. It
can be particularly challenging to obtain this volume of data in the
operating room. In response, we developed the OR Black Box re-
cording platform,’ now implemented internationally, that makes this
high-quality, high-volume data collection feasible.

Explainable artificial intelligence is still in its relative infancy, and
no standard approach has yet emerged. The relevance of techno-
logical development to surgeons may depend on whether research-
ers focus on explainablity or interpretability. Explainability of ML
models describes the means of decision-making generally, allow-
ing for high-level oversight and auditing of accuracy. The result can
be mathematically complex and may not always be understand-

ARTICLE INFORMATION

Author Affiliations: International Centre for
Surgical Safety, Li Ka Shing Knowledge Institute of
St Michael's Hospital, Toronto, Ontario, Canada
(Gordon, Grantcharov, Rudzicz); Department of
Surgery, University of Toronto, Toronto, Ontario,
Canada (Gordon, Grantcharov); Department of
Computer Science, University of Toronto,
Toronto, Ontario, Canada (Rudzicz).

Corresponding Author: Teodor Grantcharov, MD, REFERENCES

grants from Medtronic Canada, Ethicon Canada,
Intuitive Surgical, Olympus Surgical, and Baxter
outside the submitted work. Dr Rudzicz reports
personal fees from Surgical Safety Technologies
outside the submitted work.

able to clinicians. By contrast, interpretability provides understand-
able reasons behind individual predictions that clinicians can useto
make judgements. The broader discussion of what qualifies as an
acceptable explanation is the subject of ongoing debate.

Clinicians have been hesitant to trust traditional ML systems be-
cause the internal workings are unclear: while the algorithm may gen-
erally have high accuracy, it can be difficult to evaluate if any indi-
vidual prediction is correct. Clinicians may be more willing to trust
an ML system when its logic is made transparent. Ideally, physi-
cians will use XAI to augment their clinical judgement and evaluate
whether the algorithm's logic makes sense within the clinical con-
text prior to action. Further research on XAl-based decision sup-
port, demonstrating improved clinical judgement and reduced in-
traoperative events, would help build clinician trust and facilitate
adoption of XAI.

In What Time Frame Will This Innovation

Likely Be Applied Routinely?

While we expect XAI to become more widespread within the next
5 years, its adoption in surgery will depend on technological, cultural,
and regulatory factors. Culturally, it will depend on trust, which will
increase if XAl can generate demonstrably clear and actionable inter-
pretations in, for example, intraoperative risk prediction. Similarly, clini-
caltrials using XAl, with increasing regulatory acceptance of artificial
intelligence in health care, will help spread the use of data-driven, real-
time analytics in the operating room within the coming years.

outcomes: a systematic review. JAMA. 2005;293
(10):1223-1238. doi:10.1001/jama.293.10.1223

4. Cabitza F, Rasoini R, Gensini GF. Unintended
consequences of machine learning in medicine.
JAMA, 2017;318(6):517-518. doi:10.1001/jama.2017.

Submissions: Authors should contact Justin B. 7797
Dimick, MD, MPH, at jdimick@med.umich.edu
if they wish to submit Surgical Innovation papers.

5. Lundberg SM, Nair B, Vavilala MS, et al.
Explainable machine-learning predictions for the
prevention of hypoxaemia during surgery. Nat
Biomed Eng. 2018:2(10):749-760. doi:10.1038/

PhD, International Centre for Surgical Safety,

Li Ka Shing Knowledge Institute, 209 Victoria St,
Toronto, ON M5B 1T8 , Canada
(grantcharavt@smh.ca).

Section Editor: Justin B. Dimick, MD, MPH.

Published Online: September 11, 2019.
doi:10.1001/jamasurg.2019.2821

Conflict of Interest Disclosures: Dr Gordon
reports grants from Canadian Institutes of

Health Research during the conduct of the study.
Dr Grantcharov reports IP ownership in SST Inc and

JAMA Surgery Published online September 11, 2019

1. Jung JJ, Jini P, Lebovic G, Grantcharov T.
First-year analysis of the operating roam black box
study [published online June 18, 2018]. Ann Surg.
doi:10.1097/SLA.0000000000002863

2. Ehrenfeld JM, Funk LM, Van Schalkwyk J,

Merry AF, Sandberg WS, Gawande A. The incidence
of hypoxemia during surgery: evidence from two
institutions. Can J Anaesth. 2010:57(10):888-897.
doi:10.1007/s12630-010-9366-5

3. Garg AX, Adhikari NIJ, McDonald H, et al.
Effects of computerized clinical decision support
systems on practitioner performance and patient

$41551-018-0304-0

6. Moonesinghe SR, Mythen MG, Das P, Rowan KM,
Grocott MP. Risk stratification tools for predicting
morbidity and mortality in adult patients
undergoing major surgery: qualitative systematic
review. Anesthesiology. 2013;119(4):959-981. doi:
10.1097/ALN.0b013e3182a4e94d

7. Goldenberg MG, Jung J, Grantcharov TP. Using
data to enhance performance and improve quality
and safety in surgery. JAMA Surg. 2017;152(10):972-
973. doi:10.1001/jamasurg.2017.2888

jamasurgery.com

© 2019 American Medical Association. All rights reserved.

Downloaded From: https://jamanetwork.com/ by a University of Toronto Libraries User on 10/31/2019
